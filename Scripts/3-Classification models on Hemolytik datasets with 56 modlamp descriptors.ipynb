{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements different predictive models to predict the hemolytic activity of peptides based on sequence-based properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fabienplisson/Desktop/MODELS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/fabienplisson/Desktop/MODELS/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import rdkit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import scipy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading HemoPI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HemoPI1_model = pd.read_csv('./Data/HemoPI1_model.csv', index_col=0)\n",
    "HemoPI1_validation = pd.read_csv('./Data/HemoPI1_validation.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HemoPI2_model = pd.read_csv('./Data/HemoPI2_model.csv', index_col=0)\n",
    "HemoPI2_validation = pd.read_csv('./Data/HemoPI2_validation.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HemoPI3_model = pd.read_csv('./Data/HemoPI3_model.csv', index_col=0)\n",
    "HemoPI3_validation = pd.read_csv('./Data/HemoPI3_validation.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Hemolytik datasets as 3 fasta files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HemoPI1 = pd.concat([HemoPI1_model, HemoPI1_validation], axis=0)\n",
    "HemoPI2 = pd.concat([HemoPI2_model, HemoPI2_validation], axis=0)\n",
    "HemoPI3 = pd.concat([HemoPI3_model, HemoPI3_validation], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1104, 60)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HemoPI1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fasta_converter(database):\n",
    "    '''Use the indices of the database and the column 'Sequence' to create a fasta file'''\n",
    "    #ofile = open('/Users/fabienplisson/Desktop/MODELS/Data/HemoPI1.fasta', \"w\")\n",
    "    #ofile = open('/Users/fabienplisson/Desktop/MODELS/Data/HemoPI2.fasta', \"w\")\n",
    "    ofile = open('/Users/fabienplisson/Desktop/MODELS/Data/HemoPI3.fasta', \"w\")\n",
    "\n",
    "    for i in range(len(database.Sequence)):\n",
    "\n",
    "        ofile.write(\">\" + database.index[i] + \"\\n\" +database.Sequence[i] + \"\\n\")\n",
    "        \n",
    "    ofile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fasta_converter(HemoPI3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove columns with NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884, 59)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_HemoPI1_model = HemoPI1_model.dropna(axis='columns')\n",
    "cleaned_HemoPI1_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 59)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_HemoPI1_validation = HemoPI1_validation.dropna(axis='columns')\n",
    "cleaned_HemoPI1_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(812, 59)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_HemoPI2_model = HemoPI2_model.dropna(axis='columns')\n",
    "cleaned_HemoPI2_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 59)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_HemoPI2_validation = HemoPI2_validation.dropna(axis='columns')\n",
    "cleaned_HemoPI2_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1298, 59)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_HemoPI3_model = HemoPI3_model.dropna(axis='columns')\n",
    "cleaned_HemoPI3_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 59)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_HemoPI3_validation = HemoPI3_validation.dropna(axis='columns')\n",
    "cleaned_HemoPI3_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Sequence', u'H_Eisenberg', u'uH_Eisenberg', u'H_GRAVY', u'uH_GRAVY',\n",
       "       u'Z3_1', u'Z3_2', u'Z3_3', u' Z5_1', u'Z5_2', u'Z5_3', u' Z5_4',\n",
       "       u'Z5_5', u'S_AASI', u' uS_AASI', u' modlas_ABHPRK', u' H_argos',\n",
       "       u' uH_argos', u' B_Builkiness', u' uB_Builkiness', u' charge_phys',\n",
       "       u' charge_acid', u' Ez', u' flexibility', u' u_flexibility',\n",
       "       u' Grantham', u' H_HoppWoods', u' uH-HoppWoods', u' ISAECI',\n",
       "       u' H_Janin', u' uH_Janin', u' H_KyteDoolittle', u' uH_KyteDoolittle',\n",
       "       u' F_Levitt', u' uF_Levitt', u' MSS_shape', u' u_MSS_shape', u' MSW',\n",
       "       u' pepArc', u' pepcats', u' polarity', u' u_polarity', u' PPCALI',\n",
       "       u' refractivity', u' u_refractivity', u' t_scale', u' TM_tend',\n",
       "       u' u_TM_tend', u' Sequence', u'Length', u'BomanIndex', u'Aromaticity',\n",
       "       u'AliphaticIndex', u'InstabilityIndex', u' NetCharge', u' MW',\n",
       "       u' IsoelectricPoint', u' HydrophobicRatio', u'y_model_2cl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_HemoPI1_model.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove duplicated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequence and Sequence are identical - remove both columns (Sequence,  Sequence)\n",
    "# Remove class column prior normalization\n",
    "cleaned_HemoPI1_model = cleaned_HemoPI1_model.drop(['Sequence',' Sequence', 'y_model_2cl'], axis=1)\n",
    "cleaned_HemoPI1_validation = cleaned_HemoPI1_validation.drop(['Sequence',' Sequence', 'y_validation_2cl'], axis=1)\n",
    "cleaned_HemoPI2_model = cleaned_HemoPI2_model.drop(['Sequence',' Sequence', 'y_model_2cl'], axis=1)\n",
    "cleaned_HemoPI2_validation = cleaned_HemoPI2_validation.drop(['Sequence',' Sequence', 'y_validation_2cl'], axis=1)\n",
    "cleaned_HemoPI3_model = cleaned_HemoPI3_model.drop(['Sequence',' Sequence', 'y_model_2cl'], axis=1)\n",
    "cleaned_HemoPI3_validation = cleaned_HemoPI3_validation.drop(['Sequence',' Sequence', 'y_validation_2cl'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884, 56)\n",
      "(220, 56)\n",
      "(812, 56)\n",
      "(202, 56)\n",
      "(1298, 56)\n",
      "(325, 56)\n"
     ]
    }
   ],
   "source": [
    "print cleaned_HemoPI1_model.shape\n",
    "print cleaned_HemoPI1_validation.shape\n",
    "print cleaned_HemoPI2_model.shape\n",
    "print cleaned_HemoPI2_validation.shape\n",
    "print cleaned_HemoPI3_model.shape\n",
    "print cleaned_HemoPI3_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_HemoPI1_model = normalize(cleaned_HemoPI1_model)\n",
    "norm_HemoPI1_validation = normalize(cleaned_HemoPI1_validation)\n",
    "norm_HemoPI2_model = normalize(cleaned_HemoPI2_model)\n",
    "norm_HemoPI2_validation = normalize(cleaned_HemoPI2_validation)\n",
    "norm_HemoPI3_model = normalize(cleaned_HemoPI3_model)\n",
    "norm_HemoPI3_validation = normalize(cleaned_HemoPI3_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove descriptors with high collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H_Eisenberg</th>\n",
       "      <th>uH_Eisenberg</th>\n",
       "      <th>H_GRAVY</th>\n",
       "      <th>uH_GRAVY</th>\n",
       "      <th>Z3_1</th>\n",
       "      <th>Z3_2</th>\n",
       "      <th>Z3_3</th>\n",
       "      <th>Z5_1</th>\n",
       "      <th>Z5_2</th>\n",
       "      <th>Z5_3</th>\n",
       "      <th>...</th>\n",
       "      <th>u_TM_tend</th>\n",
       "      <th>Length</th>\n",
       "      <th>BomanIndex</th>\n",
       "      <th>Aromaticity</th>\n",
       "      <th>AliphaticIndex</th>\n",
       "      <th>InstabilityIndex</th>\n",
       "      <th>NetCharge</th>\n",
       "      <th>MW</th>\n",
       "      <th>IsoelectricPoint</th>\n",
       "      <th>HydrophobicRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H_Eisenberg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>0.889938</td>\n",
       "      <td>0.167809</td>\n",
       "      <td>0.217921</td>\n",
       "      <td>0.179892</td>\n",
       "      <td>-0.580800</td>\n",
       "      <td>0.135828</td>\n",
       "      <td>0.157186</td>\n",
       "      <td>-0.520160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091984</td>\n",
       "      <td>-0.016710</td>\n",
       "      <td>-0.922374</td>\n",
       "      <td>-0.090046</td>\n",
       "      <td>0.628723</td>\n",
       "      <td>-0.275935</td>\n",
       "      <td>-0.263243</td>\n",
       "      <td>-0.107942</td>\n",
       "      <td>-0.147791</td>\n",
       "      <td>0.686882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uH_Eisenberg</th>\n",
       "      <td>0.006218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>0.931205</td>\n",
       "      <td>0.607865</td>\n",
       "      <td>-0.135547</td>\n",
       "      <td>0.176180</td>\n",
       "      <td>0.551147</td>\n",
       "      <td>-0.097778</td>\n",
       "      <td>0.168849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933421</td>\n",
       "      <td>-0.320635</td>\n",
       "      <td>-0.173678</td>\n",
       "      <td>0.210791</td>\n",
       "      <td>0.391122</td>\n",
       "      <td>-0.274313</td>\n",
       "      <td>0.401666</td>\n",
       "      <td>-0.266267</td>\n",
       "      <td>0.451366</td>\n",
       "      <td>0.237923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_GRAVY</th>\n",
       "      <td>0.889938</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289916</td>\n",
       "      <td>0.244031</td>\n",
       "      <td>0.117415</td>\n",
       "      <td>-0.268843</td>\n",
       "      <td>0.193465</td>\n",
       "      <td>0.133143</td>\n",
       "      <td>-0.167764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184979</td>\n",
       "      <td>-0.061188</td>\n",
       "      <td>-0.879047</td>\n",
       "      <td>-0.134800</td>\n",
       "      <td>0.751326</td>\n",
       "      <td>-0.285285</td>\n",
       "      <td>-0.032514</td>\n",
       "      <td>-0.138084</td>\n",
       "      <td>0.046363</td>\n",
       "      <td>0.894970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uH_GRAVY</th>\n",
       "      <td>0.167809</td>\n",
       "      <td>0.931205</td>\n",
       "      <td>0.289916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.614002</td>\n",
       "      <td>-0.140773</td>\n",
       "      <td>0.054372</td>\n",
       "      <td>0.544449</td>\n",
       "      <td>-0.140968</td>\n",
       "      <td>0.051239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937580</td>\n",
       "      <td>-0.320605</td>\n",
       "      <td>-0.317191</td>\n",
       "      <td>0.125626</td>\n",
       "      <td>0.493420</td>\n",
       "      <td>-0.317818</td>\n",
       "      <td>0.308046</td>\n",
       "      <td>-0.284901</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.342766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z3_1</th>\n",
       "      <td>0.217921</td>\n",
       "      <td>0.607865</td>\n",
       "      <td>0.244031</td>\n",
       "      <td>0.614002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240783</td>\n",
       "      <td>-0.020873</td>\n",
       "      <td>0.938978</td>\n",
       "      <td>-0.188457</td>\n",
       "      <td>-0.017438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642256</td>\n",
       "      <td>-0.280980</td>\n",
       "      <td>-0.334002</td>\n",
       "      <td>0.439005</td>\n",
       "      <td>0.513779</td>\n",
       "      <td>-0.229134</td>\n",
       "      <td>0.222078</td>\n",
       "      <td>-0.197580</td>\n",
       "      <td>0.290027</td>\n",
       "      <td>0.279503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z3_2</th>\n",
       "      <td>0.179892</td>\n",
       "      <td>-0.135547</td>\n",
       "      <td>0.117415</td>\n",
       "      <td>-0.140773</td>\n",
       "      <td>-0.240783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.050571</td>\n",
       "      <td>-0.242861</td>\n",
       "      <td>0.913045</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210348</td>\n",
       "      <td>0.108802</td>\n",
       "      <td>-0.090337</td>\n",
       "      <td>-0.012739</td>\n",
       "      <td>-0.140135</td>\n",
       "      <td>-0.009469</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.050685</td>\n",
       "      <td>0.075741</td>\n",
       "      <td>-0.109832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z3_3</th>\n",
       "      <td>-0.580800</td>\n",
       "      <td>0.176180</td>\n",
       "      <td>-0.268843</td>\n",
       "      <td>0.054372</td>\n",
       "      <td>-0.020873</td>\n",
       "      <td>-0.050571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022774</td>\n",
       "      <td>0.057258</td>\n",
       "      <td>0.961137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084996</td>\n",
       "      <td>-0.080551</td>\n",
       "      <td>0.397788</td>\n",
       "      <td>0.242039</td>\n",
       "      <td>-0.269008</td>\n",
       "      <td>0.119625</td>\n",
       "      <td>0.476406</td>\n",
       "      <td>-0.004531</td>\n",
       "      <td>0.336028</td>\n",
       "      <td>-0.092128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z5_1</th>\n",
       "      <td>0.135828</td>\n",
       "      <td>0.551147</td>\n",
       "      <td>0.193465</td>\n",
       "      <td>0.544449</td>\n",
       "      <td>0.938978</td>\n",
       "      <td>-0.242861</td>\n",
       "      <td>0.022774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.176918</td>\n",
       "      <td>0.074770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557078</td>\n",
       "      <td>-0.298065</td>\n",
       "      <td>-0.205734</td>\n",
       "      <td>0.395105</td>\n",
       "      <td>0.514510</td>\n",
       "      <td>-0.085314</td>\n",
       "      <td>0.122402</td>\n",
       "      <td>-0.201984</td>\n",
       "      <td>0.190104</td>\n",
       "      <td>0.217145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z5_2</th>\n",
       "      <td>0.157186</td>\n",
       "      <td>-0.097778</td>\n",
       "      <td>0.133143</td>\n",
       "      <td>-0.140968</td>\n",
       "      <td>-0.188457</td>\n",
       "      <td>0.913045</td>\n",
       "      <td>0.057258</td>\n",
       "      <td>-0.176918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.135182</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218445</td>\n",
       "      <td>0.055601</td>\n",
       "      <td>-0.060465</td>\n",
       "      <td>0.229339</td>\n",
       "      <td>-0.181928</td>\n",
       "      <td>0.073655</td>\n",
       "      <td>0.065054</td>\n",
       "      <td>0.028394</td>\n",
       "      <td>0.137252</td>\n",
       "      <td>-0.021883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z5_3</th>\n",
       "      <td>-0.520160</td>\n",
       "      <td>0.168849</td>\n",
       "      <td>-0.167764</td>\n",
       "      <td>0.051239</td>\n",
       "      <td>-0.017438</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.961137</td>\n",
       "      <td>0.074770</td>\n",
       "      <td>0.135182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031994</td>\n",
       "      <td>-0.101044</td>\n",
       "      <td>0.401743</td>\n",
       "      <td>0.229839</td>\n",
       "      <td>-0.201861</td>\n",
       "      <td>0.229777</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>-0.025598</td>\n",
       "      <td>0.315634</td>\n",
       "      <td>-0.015655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z5_4</th>\n",
       "      <td>-0.370287</td>\n",
       "      <td>-0.038524</td>\n",
       "      <td>-0.587155</td>\n",
       "      <td>-0.101176</td>\n",
       "      <td>0.136655</td>\n",
       "      <td>-0.083319</td>\n",
       "      <td>-0.072603</td>\n",
       "      <td>0.203611</td>\n",
       "      <td>0.018465</td>\n",
       "      <td>-0.121205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031791</td>\n",
       "      <td>-0.028063</td>\n",
       "      <td>0.469115</td>\n",
       "      <td>0.258777</td>\n",
       "      <td>-0.381117</td>\n",
       "      <td>0.312249</td>\n",
       "      <td>-0.280417</td>\n",
       "      <td>0.054279</td>\n",
       "      <td>-0.222940</td>\n",
       "      <td>-0.574045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z5_5</th>\n",
       "      <td>-0.054149</td>\n",
       "      <td>-0.337260</td>\n",
       "      <td>-0.003831</td>\n",
       "      <td>-0.359286</td>\n",
       "      <td>-0.381185</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>0.510044</td>\n",
       "      <td>-0.290034</td>\n",
       "      <td>0.241642</td>\n",
       "      <td>0.522670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377926</td>\n",
       "      <td>0.018224</td>\n",
       "      <td>0.080197</td>\n",
       "      <td>0.170050</td>\n",
       "      <td>-0.333393</td>\n",
       "      <td>0.324079</td>\n",
       "      <td>-0.122567</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>-0.181559</td>\n",
       "      <td>-0.013919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_AASI</th>\n",
       "      <td>-0.203291</td>\n",
       "      <td>-0.242298</td>\n",
       "      <td>-0.344153</td>\n",
       "      <td>-0.188891</td>\n",
       "      <td>-0.300015</td>\n",
       "      <td>0.103389</td>\n",
       "      <td>-0.366195</td>\n",
       "      <td>-0.285561</td>\n",
       "      <td>-0.045783</td>\n",
       "      <td>-0.393332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177625</td>\n",
       "      <td>0.156812</td>\n",
       "      <td>0.346242</td>\n",
       "      <td>-0.364756</td>\n",
       "      <td>-0.247029</td>\n",
       "      <td>-0.040892</td>\n",
       "      <td>-0.420485</td>\n",
       "      <td>0.127632</td>\n",
       "      <td>-0.457448</td>\n",
       "      <td>-0.339361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uS_AASI</th>\n",
       "      <td>-0.005805</td>\n",
       "      <td>0.069497</td>\n",
       "      <td>-0.118680</td>\n",
       "      <td>0.065295</td>\n",
       "      <td>0.169216</td>\n",
       "      <td>-0.076289</td>\n",
       "      <td>-0.037223</td>\n",
       "      <td>0.192005</td>\n",
       "      <td>-0.057542</td>\n",
       "      <td>-0.057489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099607</td>\n",
       "      <td>-0.342402</td>\n",
       "      <td>0.016466</td>\n",
       "      <td>0.085153</td>\n",
       "      <td>-0.005026</td>\n",
       "      <td>0.144370</td>\n",
       "      <td>-0.169765</td>\n",
       "      <td>-0.324017</td>\n",
       "      <td>-0.107070</td>\n",
       "      <td>-0.159059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modlas_ABHPRK</th>\n",
       "      <td>-0.398134</td>\n",
       "      <td>0.195568</td>\n",
       "      <td>-0.376210</td>\n",
       "      <td>0.124321</td>\n",
       "      <td>0.313929</td>\n",
       "      <td>-0.352035</td>\n",
       "      <td>0.161069</td>\n",
       "      <td>0.341050</td>\n",
       "      <td>-0.287384</td>\n",
       "      <td>0.142120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169463</td>\n",
       "      <td>-0.100602</td>\n",
       "      <td>0.380519</td>\n",
       "      <td>0.328317</td>\n",
       "      <td>-0.155822</td>\n",
       "      <td>0.097107</td>\n",
       "      <td>0.109245</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.087794</td>\n",
       "      <td>-0.271556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_argos</th>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.362079</td>\n",
       "      <td>0.786382</td>\n",
       "      <td>0.458609</td>\n",
       "      <td>0.545399</td>\n",
       "      <td>-0.181997</td>\n",
       "      <td>-0.208946</td>\n",
       "      <td>0.551796</td>\n",
       "      <td>-0.152853</td>\n",
       "      <td>-0.148174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418434</td>\n",
       "      <td>-0.181603</td>\n",
       "      <td>-0.776060</td>\n",
       "      <td>-0.028776</td>\n",
       "      <td>0.829775</td>\n",
       "      <td>-0.293577</td>\n",
       "      <td>0.129090</td>\n",
       "      <td>-0.201524</td>\n",
       "      <td>0.204548</td>\n",
       "      <td>0.788791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uH_argos</th>\n",
       "      <td>0.210075</td>\n",
       "      <td>0.782877</td>\n",
       "      <td>0.310318</td>\n",
       "      <td>0.867342</td>\n",
       "      <td>0.640725</td>\n",
       "      <td>-0.191575</td>\n",
       "      <td>0.057499</td>\n",
       "      <td>0.599045</td>\n",
       "      <td>-0.222228</td>\n",
       "      <td>0.027569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869681</td>\n",
       "      <td>-0.315560</td>\n",
       "      <td>-0.396774</td>\n",
       "      <td>0.090354</td>\n",
       "      <td>0.540462</td>\n",
       "      <td>-0.341622</td>\n",
       "      <td>0.274414</td>\n",
       "      <td>-0.285344</td>\n",
       "      <td>0.297115</td>\n",
       "      <td>0.342982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_Builkiness</th>\n",
       "      <td>0.178190</td>\n",
       "      <td>0.536160</td>\n",
       "      <td>0.296582</td>\n",
       "      <td>0.525013</td>\n",
       "      <td>0.768413</td>\n",
       "      <td>-0.484696</td>\n",
       "      <td>0.178039</td>\n",
       "      <td>0.743425</td>\n",
       "      <td>-0.320013</td>\n",
       "      <td>0.167266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557752</td>\n",
       "      <td>-0.268599</td>\n",
       "      <td>-0.362920</td>\n",
       "      <td>0.376996</td>\n",
       "      <td>0.575562</td>\n",
       "      <td>-0.181530</td>\n",
       "      <td>0.341505</td>\n",
       "      <td>-0.174674</td>\n",
       "      <td>0.349486</td>\n",
       "      <td>0.372530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uB_Builkiness</th>\n",
       "      <td>0.355225</td>\n",
       "      <td>0.414317</td>\n",
       "      <td>0.385686</td>\n",
       "      <td>0.504414</td>\n",
       "      <td>0.367251</td>\n",
       "      <td>0.137100</td>\n",
       "      <td>-0.114078</td>\n",
       "      <td>0.356455</td>\n",
       "      <td>0.102823</td>\n",
       "      <td>-0.053722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413259</td>\n",
       "      <td>-0.313265</td>\n",
       "      <td>-0.364771</td>\n",
       "      <td>0.081839</td>\n",
       "      <td>0.375939</td>\n",
       "      <td>-0.166250</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>-0.325664</td>\n",
       "      <td>0.118808</td>\n",
       "      <td>0.281366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charge_phys</th>\n",
       "      <td>-0.277306</td>\n",
       "      <td>0.522110</td>\n",
       "      <td>-0.018542</td>\n",
       "      <td>0.414622</td>\n",
       "      <td>0.343895</td>\n",
       "      <td>-0.041833</td>\n",
       "      <td>0.579607</td>\n",
       "      <td>0.237660</td>\n",
       "      <td>0.040345</td>\n",
       "      <td>0.515641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453630</td>\n",
       "      <td>-0.124550</td>\n",
       "      <td>-0.041017</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.151473</td>\n",
       "      <td>-0.268031</td>\n",
       "      <td>0.900922</td>\n",
       "      <td>-0.057543</td>\n",
       "      <td>0.846699</td>\n",
       "      <td>0.137950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charge_acid</th>\n",
       "      <td>-0.270097</td>\n",
       "      <td>0.515862</td>\n",
       "      <td>-0.036438</td>\n",
       "      <td>0.414624</td>\n",
       "      <td>0.331387</td>\n",
       "      <td>-0.037271</td>\n",
       "      <td>0.542808</td>\n",
       "      <td>0.220279</td>\n",
       "      <td>0.046983</td>\n",
       "      <td>0.474391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448328</td>\n",
       "      <td>-0.112097</td>\n",
       "      <td>-0.033625</td>\n",
       "      <td>0.287428</td>\n",
       "      <td>0.133192</td>\n",
       "      <td>-0.263353</td>\n",
       "      <td>0.887785</td>\n",
       "      <td>-0.043282</td>\n",
       "      <td>0.849271</td>\n",
       "      <td>0.117711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ez</th>\n",
       "      <td>0.502005</td>\n",
       "      <td>0.124963</td>\n",
       "      <td>0.434239</td>\n",
       "      <td>0.232078</td>\n",
       "      <td>0.527329</td>\n",
       "      <td>-0.132325</td>\n",
       "      <td>-0.271556</td>\n",
       "      <td>0.594850</td>\n",
       "      <td>-0.258878</td>\n",
       "      <td>-0.193928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199776</td>\n",
       "      <td>-0.145175</td>\n",
       "      <td>-0.402531</td>\n",
       "      <td>0.018806</td>\n",
       "      <td>0.443711</td>\n",
       "      <td>-0.025091</td>\n",
       "      <td>-0.367098</td>\n",
       "      <td>-0.148020</td>\n",
       "      <td>-0.295150</td>\n",
       "      <td>0.254447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flexibility</th>\n",
       "      <td>-0.419694</td>\n",
       "      <td>-0.294940</td>\n",
       "      <td>-0.484301</td>\n",
       "      <td>-0.334721</td>\n",
       "      <td>-0.415478</td>\n",
       "      <td>0.264270</td>\n",
       "      <td>-0.033148</td>\n",
       "      <td>-0.321015</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>0.020139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345919</td>\n",
       "      <td>0.141559</td>\n",
       "      <td>0.558281</td>\n",
       "      <td>-0.421971</td>\n",
       "      <td>-0.344918</td>\n",
       "      <td>0.301031</td>\n",
       "      <td>-0.249963</td>\n",
       "      <td>0.116797</td>\n",
       "      <td>-0.254877</td>\n",
       "      <td>-0.649182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_flexibility</th>\n",
       "      <td>0.035404</td>\n",
       "      <td>0.575574</td>\n",
       "      <td>0.077991</td>\n",
       "      <td>0.562446</td>\n",
       "      <td>0.358703</td>\n",
       "      <td>-0.008406</td>\n",
       "      <td>0.051067</td>\n",
       "      <td>0.343214</td>\n",
       "      <td>0.020230</td>\n",
       "      <td>0.037432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617649</td>\n",
       "      <td>-0.322931</td>\n",
       "      <td>-0.121726</td>\n",
       "      <td>0.184604</td>\n",
       "      <td>0.162859</td>\n",
       "      <td>-0.177951</td>\n",
       "      <td>0.182256</td>\n",
       "      <td>-0.297356</td>\n",
       "      <td>0.200611</td>\n",
       "      <td>0.095059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grantham</th>\n",
       "      <td>-0.262195</td>\n",
       "      <td>0.595494</td>\n",
       "      <td>-0.115128</td>\n",
       "      <td>0.508155</td>\n",
       "      <td>0.759765</td>\n",
       "      <td>-0.381064</td>\n",
       "      <td>0.428483</td>\n",
       "      <td>0.737602</td>\n",
       "      <td>-0.212346</td>\n",
       "      <td>0.385397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574699</td>\n",
       "      <td>-0.266524</td>\n",
       "      <td>0.042116</td>\n",
       "      <td>0.591540</td>\n",
       "      <td>0.209379</td>\n",
       "      <td>-0.110185</td>\n",
       "      <td>0.517968</td>\n",
       "      <td>-0.124180</td>\n",
       "      <td>0.477359</td>\n",
       "      <td>0.063789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_HoppWoods</th>\n",
       "      <td>-0.829401</td>\n",
       "      <td>-0.053962</td>\n",
       "      <td>-0.778060</td>\n",
       "      <td>-0.154063</td>\n",
       "      <td>-0.249366</td>\n",
       "      <td>-0.227556</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>-0.223149</td>\n",
       "      <td>-0.350857</td>\n",
       "      <td>0.196139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050728</td>\n",
       "      <td>0.094585</td>\n",
       "      <td>0.757711</td>\n",
       "      <td>-0.258273</td>\n",
       "      <td>-0.466344</td>\n",
       "      <td>0.100586</td>\n",
       "      <td>0.074411</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>-0.042088</td>\n",
       "      <td>-0.581547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uH-HoppWoods</th>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.920217</td>\n",
       "      <td>0.090474</td>\n",
       "      <td>0.854402</td>\n",
       "      <td>0.628479</td>\n",
       "      <td>-0.192369</td>\n",
       "      <td>0.136567</td>\n",
       "      <td>0.561774</td>\n",
       "      <td>-0.178552</td>\n",
       "      <td>0.080644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960756</td>\n",
       "      <td>-0.318822</td>\n",
       "      <td>-0.192274</td>\n",
       "      <td>0.221801</td>\n",
       "      <td>0.359639</td>\n",
       "      <td>-0.320340</td>\n",
       "      <td>0.344705</td>\n",
       "      <td>-0.264040</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.166681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISAECI</th>\n",
       "      <td>0.295134</td>\n",
       "      <td>0.579954</td>\n",
       "      <td>0.399973</td>\n",
       "      <td>0.570815</td>\n",
       "      <td>0.797493</td>\n",
       "      <td>-0.257751</td>\n",
       "      <td>0.201983</td>\n",
       "      <td>0.703193</td>\n",
       "      <td>-0.121833</td>\n",
       "      <td>0.160520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608272</td>\n",
       "      <td>-0.246597</td>\n",
       "      <td>-0.522152</td>\n",
       "      <td>0.498459</td>\n",
       "      <td>0.532012</td>\n",
       "      <td>-0.299646</td>\n",
       "      <td>0.484210</td>\n",
       "      <td>-0.172044</td>\n",
       "      <td>0.497669</td>\n",
       "      <td>0.470836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_Janin</th>\n",
       "      <td>0.817274</td>\n",
       "      <td>-0.241851</td>\n",
       "      <td>0.762495</td>\n",
       "      <td>-0.102992</td>\n",
       "      <td>-0.126301</td>\n",
       "      <td>0.375422</td>\n",
       "      <td>-0.410825</td>\n",
       "      <td>-0.091311</td>\n",
       "      <td>0.390456</td>\n",
       "      <td>-0.258795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245371</td>\n",
       "      <td>0.038281</td>\n",
       "      <td>-0.591251</td>\n",
       "      <td>-0.146164</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.061117</td>\n",
       "      <td>-0.466917</td>\n",
       "      <td>-0.057706</td>\n",
       "      <td>-0.344046</td>\n",
       "      <td>0.542159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uH_Janin</th>\n",
       "      <td>-0.003101</td>\n",
       "      <td>0.929165</td>\n",
       "      <td>0.148799</td>\n",
       "      <td>0.885624</td>\n",
       "      <td>0.589476</td>\n",
       "      <td>-0.193631</td>\n",
       "      <td>0.229424</td>\n",
       "      <td>0.494559</td>\n",
       "      <td>-0.186736</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937340</td>\n",
       "      <td>-0.299531</td>\n",
       "      <td>-0.240968</td>\n",
       "      <td>0.157662</td>\n",
       "      <td>0.411481</td>\n",
       "      <td>-0.382266</td>\n",
       "      <td>0.470653</td>\n",
       "      <td>-0.253021</td>\n",
       "      <td>0.477896</td>\n",
       "      <td>0.256807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_KyteDoolittle</th>\n",
       "      <td>0.885712</td>\n",
       "      <td>0.157590</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.291064</td>\n",
       "      <td>0.242301</td>\n",
       "      <td>0.120355</td>\n",
       "      <td>-0.261219</td>\n",
       "      <td>0.188756</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>-0.159820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185417</td>\n",
       "      <td>-0.059937</td>\n",
       "      <td>-0.875389</td>\n",
       "      <td>-0.132135</td>\n",
       "      <td>0.747865</td>\n",
       "      <td>-0.285858</td>\n",
       "      <td>-0.024562</td>\n",
       "      <td>-0.136464</td>\n",
       "      <td>0.053087</td>\n",
       "      <td>0.896924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uH_KyteDoolittle</th>\n",
       "      <td>0.178987</td>\n",
       "      <td>0.927099</td>\n",
       "      <td>0.299947</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>0.611608</td>\n",
       "      <td>-0.132017</td>\n",
       "      <td>0.048728</td>\n",
       "      <td>0.542337</td>\n",
       "      <td>-0.131177</td>\n",
       "      <td>0.049781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929739</td>\n",
       "      <td>-0.320886</td>\n",
       "      <td>-0.322038</td>\n",
       "      <td>0.128757</td>\n",
       "      <td>0.493919</td>\n",
       "      <td>-0.311203</td>\n",
       "      <td>0.300554</td>\n",
       "      <td>-0.285996</td>\n",
       "      <td>0.355197</td>\n",
       "      <td>0.347833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F_Levitt</th>\n",
       "      <td>-0.022175</td>\n",
       "      <td>0.348367</td>\n",
       "      <td>0.061202</td>\n",
       "      <td>0.377971</td>\n",
       "      <td>0.428077</td>\n",
       "      <td>-0.621200</td>\n",
       "      <td>-0.052356</td>\n",
       "      <td>0.367643</td>\n",
       "      <td>-0.571243</td>\n",
       "      <td>-0.148768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461630</td>\n",
       "      <td>-0.119717</td>\n",
       "      <td>-0.182009</td>\n",
       "      <td>-0.055010</td>\n",
       "      <td>0.388374</td>\n",
       "      <td>-0.288856</td>\n",
       "      <td>0.171006</td>\n",
       "      <td>-0.085794</td>\n",
       "      <td>0.134944</td>\n",
       "      <td>0.358916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uF_Levitt</th>\n",
       "      <td>0.149977</td>\n",
       "      <td>0.079610</td>\n",
       "      <td>0.120343</td>\n",
       "      <td>0.103410</td>\n",
       "      <td>0.182974</td>\n",
       "      <td>0.021961</td>\n",
       "      <td>-0.047644</td>\n",
       "      <td>0.231528</td>\n",
       "      <td>0.025096</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057742</td>\n",
       "      <td>-0.389381</td>\n",
       "      <td>-0.139638</td>\n",
       "      <td>0.096123</td>\n",
       "      <td>0.149265</td>\n",
       "      <td>0.164122</td>\n",
       "      <td>-0.106017</td>\n",
       "      <td>-0.389137</td>\n",
       "      <td>0.024630</td>\n",
       "      <td>0.054092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSS_shape</th>\n",
       "      <td>-0.292186</td>\n",
       "      <td>0.177741</td>\n",
       "      <td>-0.243178</td>\n",
       "      <td>0.119607</td>\n",
       "      <td>0.375068</td>\n",
       "      <td>-0.650355</td>\n",
       "      <td>0.358402</td>\n",
       "      <td>0.429356</td>\n",
       "      <td>-0.429198</td>\n",
       "      <td>0.345006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162195</td>\n",
       "      <td>-0.184580</td>\n",
       "      <td>0.276851</td>\n",
       "      <td>0.504809</td>\n",
       "      <td>-0.110117</td>\n",
       "      <td>0.202787</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>-0.057288</td>\n",
       "      <td>-0.041961</td>\n",
       "      <td>-0.145086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_MSS_shape</th>\n",
       "      <td>0.204121</td>\n",
       "      <td>0.106229</td>\n",
       "      <td>0.191685</td>\n",
       "      <td>0.138040</td>\n",
       "      <td>0.124226</td>\n",
       "      <td>0.251051</td>\n",
       "      <td>-0.095402</td>\n",
       "      <td>0.139222</td>\n",
       "      <td>0.223207</td>\n",
       "      <td>-0.033603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078198</td>\n",
       "      <td>-0.324924</td>\n",
       "      <td>-0.163936</td>\n",
       "      <td>0.108136</td>\n",
       "      <td>0.102838</td>\n",
       "      <td>-0.019412</td>\n",
       "      <td>-0.072454</td>\n",
       "      <td>-0.345257</td>\n",
       "      <td>0.036631</td>\n",
       "      <td>0.116473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSW</th>\n",
       "      <td>-0.378653</td>\n",
       "      <td>0.409619</td>\n",
       "      <td>-0.276341</td>\n",
       "      <td>0.295290</td>\n",
       "      <td>0.527095</td>\n",
       "      <td>-0.212439</td>\n",
       "      <td>0.475842</td>\n",
       "      <td>0.523194</td>\n",
       "      <td>-0.006729</td>\n",
       "      <td>0.476423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322024</td>\n",
       "      <td>-0.227919</td>\n",
       "      <td>0.240073</td>\n",
       "      <td>0.753200</td>\n",
       "      <td>-0.120624</td>\n",
       "      <td>0.151931</td>\n",
       "      <td>0.477629</td>\n",
       "      <td>-0.078866</td>\n",
       "      <td>0.464691</td>\n",
       "      <td>-0.116111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pepArc</th>\n",
       "      <td>-0.377975</td>\n",
       "      <td>0.100486</td>\n",
       "      <td>-0.330268</td>\n",
       "      <td>0.031797</td>\n",
       "      <td>0.101044</td>\n",
       "      <td>-0.430700</td>\n",
       "      <td>0.145267</td>\n",
       "      <td>0.112730</td>\n",
       "      <td>-0.324384</td>\n",
       "      <td>0.103880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082832</td>\n",
       "      <td>0.033286</td>\n",
       "      <td>0.332538</td>\n",
       "      <td>0.135055</td>\n",
       "      <td>-0.128935</td>\n",
       "      <td>0.034891</td>\n",
       "      <td>0.130380</td>\n",
       "      <td>0.100298</td>\n",
       "      <td>0.102281</td>\n",
       "      <td>-0.141931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pepcats</th>\n",
       "      <td>-0.487192</td>\n",
       "      <td>0.243617</td>\n",
       "      <td>-0.392878</td>\n",
       "      <td>0.138238</td>\n",
       "      <td>0.174418</td>\n",
       "      <td>-0.193767</td>\n",
       "      <td>0.564538</td>\n",
       "      <td>0.199617</td>\n",
       "      <td>-0.035341</td>\n",
       "      <td>0.503634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>-0.175651</td>\n",
       "      <td>0.370401</td>\n",
       "      <td>0.538643</td>\n",
       "      <td>-0.319399</td>\n",
       "      <td>0.096428</td>\n",
       "      <td>0.341105</td>\n",
       "      <td>-0.063081</td>\n",
       "      <td>0.234236</td>\n",
       "      <td>-0.257640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity</th>\n",
       "      <td>-0.679842</td>\n",
       "      <td>-0.279576</td>\n",
       "      <td>-0.827932</td>\n",
       "      <td>-0.340054</td>\n",
       "      <td>-0.408690</td>\n",
       "      <td>-0.130952</td>\n",
       "      <td>-0.074694</td>\n",
       "      <td>-0.403641</td>\n",
       "      <td>-0.257498</td>\n",
       "      <td>-0.177015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253429</td>\n",
       "      <td>0.168262</td>\n",
       "      <td>0.736987</td>\n",
       "      <td>-0.266228</td>\n",
       "      <td>-0.612252</td>\n",
       "      <td>0.133634</td>\n",
       "      <td>-0.200345</td>\n",
       "      <td>0.172749</td>\n",
       "      <td>-0.265736</td>\n",
       "      <td>-0.729403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_polarity</th>\n",
       "      <td>0.080986</td>\n",
       "      <td>0.845182</td>\n",
       "      <td>0.128834</td>\n",
       "      <td>0.871126</td>\n",
       "      <td>0.593675</td>\n",
       "      <td>-0.224169</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>0.529239</td>\n",
       "      <td>-0.236964</td>\n",
       "      <td>-0.038779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935643</td>\n",
       "      <td>-0.312678</td>\n",
       "      <td>-0.238775</td>\n",
       "      <td>0.111141</td>\n",
       "      <td>0.401228</td>\n",
       "      <td>-0.333709</td>\n",
       "      <td>0.231407</td>\n",
       "      <td>-0.272567</td>\n",
       "      <td>0.237420</td>\n",
       "      <td>0.183368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPCALI</th>\n",
       "      <td>0.030021</td>\n",
       "      <td>0.071957</td>\n",
       "      <td>-0.136302</td>\n",
       "      <td>0.052909</td>\n",
       "      <td>0.260662</td>\n",
       "      <td>-0.175164</td>\n",
       "      <td>-0.312933</td>\n",
       "      <td>0.093874</td>\n",
       "      <td>-0.086829</td>\n",
       "      <td>-0.392079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124250</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>0.295970</td>\n",
       "      <td>-0.174316</td>\n",
       "      <td>-0.039703</td>\n",
       "      <td>-0.140053</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>-0.107970</td>\n",
       "      <td>-0.067399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refractivity</th>\n",
       "      <td>-0.343931</td>\n",
       "      <td>0.361976</td>\n",
       "      <td>-0.167594</td>\n",
       "      <td>0.259753</td>\n",
       "      <td>0.479040</td>\n",
       "      <td>-0.205236</td>\n",
       "      <td>0.715677</td>\n",
       "      <td>0.515465</td>\n",
       "      <td>0.026518</td>\n",
       "      <td>0.706539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292230</td>\n",
       "      <td>-0.231151</td>\n",
       "      <td>0.204249</td>\n",
       "      <td>0.712378</td>\n",
       "      <td>-0.108534</td>\n",
       "      <td>0.147567</td>\n",
       "      <td>0.379750</td>\n",
       "      <td>-0.091391</td>\n",
       "      <td>0.312664</td>\n",
       "      <td>-0.017895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_refractivity</th>\n",
       "      <td>0.153059</td>\n",
       "      <td>0.123149</td>\n",
       "      <td>0.117675</td>\n",
       "      <td>0.112857</td>\n",
       "      <td>0.254964</td>\n",
       "      <td>0.112785</td>\n",
       "      <td>-0.009189</td>\n",
       "      <td>0.256747</td>\n",
       "      <td>0.191898</td>\n",
       "      <td>0.024193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081992</td>\n",
       "      <td>-0.330556</td>\n",
       "      <td>-0.147052</td>\n",
       "      <td>0.349198</td>\n",
       "      <td>0.032916</td>\n",
       "      <td>0.037115</td>\n",
       "      <td>-0.001988</td>\n",
       "      <td>-0.313323</td>\n",
       "      <td>0.087187</td>\n",
       "      <td>0.075966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_scale</th>\n",
       "      <td>-0.441691</td>\n",
       "      <td>0.306811</td>\n",
       "      <td>-0.422251</td>\n",
       "      <td>0.243519</td>\n",
       "      <td>0.561289</td>\n",
       "      <td>-0.503650</td>\n",
       "      <td>0.282634</td>\n",
       "      <td>0.608708</td>\n",
       "      <td>-0.362260</td>\n",
       "      <td>0.239356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322240</td>\n",
       "      <td>-0.199414</td>\n",
       "      <td>0.387343</td>\n",
       "      <td>0.506939</td>\n",
       "      <td>-0.110324</td>\n",
       "      <td>0.097901</td>\n",
       "      <td>0.029069</td>\n",
       "      <td>-0.055745</td>\n",
       "      <td>-0.038337</td>\n",
       "      <td>-0.228871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TM_tend</th>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.149825</td>\n",
       "      <td>0.915598</td>\n",
       "      <td>0.258664</td>\n",
       "      <td>0.318656</td>\n",
       "      <td>0.230949</td>\n",
       "      <td>-0.358288</td>\n",
       "      <td>0.299322</td>\n",
       "      <td>0.310758</td>\n",
       "      <td>-0.220829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139411</td>\n",
       "      <td>-0.099143</td>\n",
       "      <td>-0.818634</td>\n",
       "      <td>0.104670</td>\n",
       "      <td>0.648781</td>\n",
       "      <td>-0.163909</td>\n",
       "      <td>-0.045849</td>\n",
       "      <td>-0.147971</td>\n",
       "      <td>0.081990</td>\n",
       "      <td>0.749867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u_TM_tend</th>\n",
       "      <td>0.091984</td>\n",
       "      <td>0.933421</td>\n",
       "      <td>0.184979</td>\n",
       "      <td>0.937580</td>\n",
       "      <td>0.642256</td>\n",
       "      <td>-0.210348</td>\n",
       "      <td>0.084996</td>\n",
       "      <td>0.557078</td>\n",
       "      <td>-0.218445</td>\n",
       "      <td>0.031994</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302192</td>\n",
       "      <td>-0.286076</td>\n",
       "      <td>0.151362</td>\n",
       "      <td>0.447411</td>\n",
       "      <td>-0.370561</td>\n",
       "      <td>0.344801</td>\n",
       "      <td>-0.258455</td>\n",
       "      <td>0.356816</td>\n",
       "      <td>0.256638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length</th>\n",
       "      <td>-0.016710</td>\n",
       "      <td>-0.320635</td>\n",
       "      <td>-0.061188</td>\n",
       "      <td>-0.320605</td>\n",
       "      <td>-0.280980</td>\n",
       "      <td>0.108802</td>\n",
       "      <td>-0.080551</td>\n",
       "      <td>-0.298065</td>\n",
       "      <td>0.055601</td>\n",
       "      <td>-0.101044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051678</td>\n",
       "      <td>-0.169103</td>\n",
       "      <td>-0.140280</td>\n",
       "      <td>-0.002437</td>\n",
       "      <td>0.055251</td>\n",
       "      <td>0.983826</td>\n",
       "      <td>-0.045726</td>\n",
       "      <td>-0.086866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BomanIndex</th>\n",
       "      <td>-0.922374</td>\n",
       "      <td>-0.173678</td>\n",
       "      <td>-0.879047</td>\n",
       "      <td>-0.317191</td>\n",
       "      <td>-0.334002</td>\n",
       "      <td>-0.090337</td>\n",
       "      <td>0.397788</td>\n",
       "      <td>-0.205734</td>\n",
       "      <td>-0.060465</td>\n",
       "      <td>0.401743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286076</td>\n",
       "      <td>0.051678</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>-0.734605</td>\n",
       "      <td>0.440816</td>\n",
       "      <td>-0.017632</td>\n",
       "      <td>0.128973</td>\n",
       "      <td>-0.090545</td>\n",
       "      <td>-0.739589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aromaticity</th>\n",
       "      <td>-0.090046</td>\n",
       "      <td>0.210791</td>\n",
       "      <td>-0.134800</td>\n",
       "      <td>0.125626</td>\n",
       "      <td>0.439005</td>\n",
       "      <td>-0.012739</td>\n",
       "      <td>0.242039</td>\n",
       "      <td>0.395105</td>\n",
       "      <td>0.229339</td>\n",
       "      <td>0.229839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151362</td>\n",
       "      <td>-0.169103</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.315232</td>\n",
       "      <td>0.092726</td>\n",
       "      <td>0.205881</td>\n",
       "      <td>-0.059289</td>\n",
       "      <td>0.186721</td>\n",
       "      <td>-0.070186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliphaticIndex</th>\n",
       "      <td>0.628723</td>\n",
       "      <td>0.391122</td>\n",
       "      <td>0.751326</td>\n",
       "      <td>0.493420</td>\n",
       "      <td>0.513779</td>\n",
       "      <td>-0.140135</td>\n",
       "      <td>-0.269008</td>\n",
       "      <td>0.514510</td>\n",
       "      <td>-0.181928</td>\n",
       "      <td>-0.201861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447411</td>\n",
       "      <td>-0.140280</td>\n",
       "      <td>-0.734605</td>\n",
       "      <td>-0.315232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.363955</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>-0.170756</td>\n",
       "      <td>0.190494</td>\n",
       "      <td>0.695091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InstabilityIndex</th>\n",
       "      <td>-0.275935</td>\n",
       "      <td>-0.274313</td>\n",
       "      <td>-0.285285</td>\n",
       "      <td>-0.317818</td>\n",
       "      <td>-0.229134</td>\n",
       "      <td>-0.009469</td>\n",
       "      <td>0.119625</td>\n",
       "      <td>-0.085314</td>\n",
       "      <td>0.073655</td>\n",
       "      <td>0.229777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370561</td>\n",
       "      <td>-0.002437</td>\n",
       "      <td>0.440816</td>\n",
       "      <td>0.092726</td>\n",
       "      <td>-0.363955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.284332</td>\n",
       "      <td>0.029534</td>\n",
       "      <td>-0.214368</td>\n",
       "      <td>-0.289766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetCharge</th>\n",
       "      <td>-0.263243</td>\n",
       "      <td>0.401666</td>\n",
       "      <td>-0.032514</td>\n",
       "      <td>0.308046</td>\n",
       "      <td>0.222078</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.476406</td>\n",
       "      <td>0.122402</td>\n",
       "      <td>0.065054</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344801</td>\n",
       "      <td>0.055251</td>\n",
       "      <td>-0.017632</td>\n",
       "      <td>0.205881</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>-0.284332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.119604</td>\n",
       "      <td>0.819725</td>\n",
       "      <td>0.104172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MW</th>\n",
       "      <td>-0.107942</td>\n",
       "      <td>-0.266267</td>\n",
       "      <td>-0.138084</td>\n",
       "      <td>-0.284901</td>\n",
       "      <td>-0.197580</td>\n",
       "      <td>0.050685</td>\n",
       "      <td>-0.004531</td>\n",
       "      <td>-0.201984</td>\n",
       "      <td>0.028394</td>\n",
       "      <td>-0.025598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258455</td>\n",
       "      <td>0.983826</td>\n",
       "      <td>0.128973</td>\n",
       "      <td>-0.059289</td>\n",
       "      <td>-0.170756</td>\n",
       "      <td>0.029534</td>\n",
       "      <td>0.119604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004041</td>\n",
       "      <td>-0.136633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsoelectricPoint</th>\n",
       "      <td>-0.147791</td>\n",
       "      <td>0.451366</td>\n",
       "      <td>0.046363</td>\n",
       "      <td>0.358755</td>\n",
       "      <td>0.290027</td>\n",
       "      <td>0.075741</td>\n",
       "      <td>0.336028</td>\n",
       "      <td>0.190104</td>\n",
       "      <td>0.137252</td>\n",
       "      <td>0.315634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356816</td>\n",
       "      <td>-0.045726</td>\n",
       "      <td>-0.090545</td>\n",
       "      <td>0.186721</td>\n",
       "      <td>0.190494</td>\n",
       "      <td>-0.214368</td>\n",
       "      <td>0.819725</td>\n",
       "      <td>-0.004041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HydrophobicRatio</th>\n",
       "      <td>0.686882</td>\n",
       "      <td>0.237923</td>\n",
       "      <td>0.894970</td>\n",
       "      <td>0.342766</td>\n",
       "      <td>0.279503</td>\n",
       "      <td>-0.109832</td>\n",
       "      <td>-0.092128</td>\n",
       "      <td>0.217145</td>\n",
       "      <td>-0.021883</td>\n",
       "      <td>-0.015655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256638</td>\n",
       "      <td>-0.086866</td>\n",
       "      <td>-0.739589</td>\n",
       "      <td>-0.070186</td>\n",
       "      <td>0.695091</td>\n",
       "      <td>-0.289766</td>\n",
       "      <td>0.104172</td>\n",
       "      <td>-0.136633</td>\n",
       "      <td>0.140001</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows  56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   H_Eisenberg  uH_Eisenberg   H_GRAVY  uH_GRAVY      Z3_1  \\\n",
       "H_Eisenberg           1.000000      0.006218  0.889938  0.167809  0.217921   \n",
       "uH_Eisenberg          0.006218      1.000000  0.154846  0.931205  0.607865   \n",
       "H_GRAVY               0.889938      0.154846  1.000000  0.289916  0.244031   \n",
       "uH_GRAVY              0.167809      0.931205  0.289916  1.000000  0.614002   \n",
       "Z3_1                  0.217921      0.607865  0.244031  0.614002  1.000000   \n",
       "Z3_2                  0.179892     -0.135547  0.117415 -0.140773 -0.240783   \n",
       "Z3_3                 -0.580800      0.176180 -0.268843  0.054372 -0.020873   \n",
       " Z5_1                 0.135828      0.551147  0.193465  0.544449  0.938978   \n",
       "Z5_2                  0.157186     -0.097778  0.133143 -0.140968 -0.188457   \n",
       "Z5_3                 -0.520160      0.168849 -0.167764  0.051239 -0.017438   \n",
       " Z5_4                -0.370287     -0.038524 -0.587155 -0.101176  0.136655   \n",
       "Z5_5                 -0.054149     -0.337260 -0.003831 -0.359286 -0.381185   \n",
       "S_AASI               -0.203291     -0.242298 -0.344153 -0.188891 -0.300015   \n",
       " uS_AASI             -0.005805      0.069497 -0.118680  0.065295  0.169216   \n",
       " modlas_ABHPRK       -0.398134      0.195568 -0.376210  0.124321  0.313929   \n",
       " H_argos              0.668277      0.362079  0.786382  0.458609  0.545399   \n",
       " uH_argos             0.210075      0.782877  0.310318  0.867342  0.640725   \n",
       " B_Builkiness         0.178190      0.536160  0.296582  0.525013  0.768413   \n",
       " uB_Builkiness        0.355225      0.414317  0.385686  0.504414  0.367251   \n",
       " charge_phys         -0.277306      0.522110 -0.018542  0.414622  0.343895   \n",
       " charge_acid         -0.270097      0.515862 -0.036438  0.414624  0.331387   \n",
       " Ez                   0.502005      0.124963  0.434239  0.232078  0.527329   \n",
       " flexibility         -0.419694     -0.294940 -0.484301 -0.334721 -0.415478   \n",
       " u_flexibility        0.035404      0.575574  0.077991  0.562446  0.358703   \n",
       " Grantham            -0.262195      0.595494 -0.115128  0.508155  0.759765   \n",
       " H_HoppWoods         -0.829401     -0.053962 -0.778060 -0.154063 -0.249366   \n",
       " uH-HoppWoods         0.003858      0.920217  0.090474  0.854402  0.628479   \n",
       " ISAECI               0.295134      0.579954  0.399973  0.570815  0.797493   \n",
       " H_Janin              0.817274     -0.241851  0.762495 -0.102992 -0.126301   \n",
       " uH_Janin            -0.003101      0.929165  0.148799  0.885624  0.589476   \n",
       " H_KyteDoolittle      0.885712      0.157590  0.999780  0.291064  0.242301   \n",
       " uH_KyteDoolittle     0.178987      0.927099  0.299947  0.999022  0.611608   \n",
       " F_Levitt            -0.022175      0.348367  0.061202  0.377971  0.428077   \n",
       " uF_Levitt            0.149977      0.079610  0.120343  0.103410  0.182974   \n",
       " MSS_shape           -0.292186      0.177741 -0.243178  0.119607  0.375068   \n",
       " u_MSS_shape          0.204121      0.106229  0.191685  0.138040  0.124226   \n",
       " MSW                 -0.378653      0.409619 -0.276341  0.295290  0.527095   \n",
       " pepArc              -0.377975      0.100486 -0.330268  0.031797  0.101044   \n",
       " pepcats             -0.487192      0.243617 -0.392878  0.138238  0.174418   \n",
       " polarity            -0.679842     -0.279576 -0.827932 -0.340054 -0.408690   \n",
       " u_polarity           0.080986      0.845182  0.128834  0.871126  0.593675   \n",
       " PPCALI               0.030021      0.071957 -0.136302  0.052909  0.260662   \n",
       " refractivity        -0.343931      0.361976 -0.167594  0.259753  0.479040   \n",
       " u_refractivity       0.153059      0.123149  0.117675  0.112857  0.254964   \n",
       " t_scale             -0.441691      0.306811 -0.422251  0.243519  0.561289   \n",
       " TM_tend              0.885427      0.149825  0.915598  0.258664  0.318656   \n",
       " u_TM_tend            0.091984      0.933421  0.184979  0.937580  0.642256   \n",
       "Length               -0.016710     -0.320635 -0.061188 -0.320605 -0.280980   \n",
       "BomanIndex           -0.922374     -0.173678 -0.879047 -0.317191 -0.334002   \n",
       "Aromaticity          -0.090046      0.210791 -0.134800  0.125626  0.439005   \n",
       "AliphaticIndex        0.628723      0.391122  0.751326  0.493420  0.513779   \n",
       "InstabilityIndex     -0.275935     -0.274313 -0.285285 -0.317818 -0.229134   \n",
       " NetCharge           -0.263243      0.401666 -0.032514  0.308046  0.222078   \n",
       " MW                  -0.107942     -0.266267 -0.138084 -0.284901 -0.197580   \n",
       " IsoelectricPoint    -0.147791      0.451366  0.046363  0.358755  0.290027   \n",
       " HydrophobicRatio     0.686882      0.237923  0.894970  0.342766  0.279503   \n",
       "\n",
       "                       Z3_2      Z3_3      Z5_1      Z5_2      Z5_3  \\\n",
       "H_Eisenberg        0.179892 -0.580800  0.135828  0.157186 -0.520160   \n",
       "uH_Eisenberg      -0.135547  0.176180  0.551147 -0.097778  0.168849   \n",
       "H_GRAVY            0.117415 -0.268843  0.193465  0.133143 -0.167764   \n",
       "uH_GRAVY          -0.140773  0.054372  0.544449 -0.140968  0.051239   \n",
       "Z3_1              -0.240783 -0.020873  0.938978 -0.188457 -0.017438   \n",
       "Z3_2               1.000000 -0.050571 -0.242861  0.913045  0.009362   \n",
       "Z3_3              -0.050571  1.000000  0.022774  0.057258  0.961137   \n",
       " Z5_1             -0.242861  0.022774  1.000000 -0.176918  0.074770   \n",
       "Z5_2               0.913045  0.057258 -0.176918  1.000000  0.135182   \n",
       "Z5_3               0.009362  0.961137  0.074770  0.135182  1.000000   \n",
       " Z5_4             -0.083319 -0.072603  0.203611  0.018465 -0.121205   \n",
       "Z5_5               0.096093  0.510044 -0.290034  0.241642  0.522670   \n",
       "S_AASI             0.103389 -0.366195 -0.285561 -0.045783 -0.393332   \n",
       " uS_AASI          -0.076289 -0.037223  0.192005 -0.057542 -0.057489   \n",
       " modlas_ABHPRK    -0.352035  0.161069  0.341050 -0.287384  0.142120   \n",
       " H_argos          -0.181997 -0.208946  0.551796 -0.152853 -0.148174   \n",
       " uH_argos         -0.191575  0.057499  0.599045 -0.222228  0.027569   \n",
       " B_Builkiness     -0.484696  0.178039  0.743425 -0.320013  0.167266   \n",
       " uB_Builkiness     0.137100 -0.114078  0.356455  0.102823 -0.053722   \n",
       " charge_phys      -0.041833  0.579607  0.237660  0.040345  0.515641   \n",
       " charge_acid      -0.037271  0.542808  0.220279  0.046983  0.474391   \n",
       " Ez               -0.132325 -0.271556  0.594850 -0.258878 -0.193928   \n",
       " flexibility       0.264270 -0.033148 -0.321015  0.022450  0.020139   \n",
       " u_flexibility    -0.008406  0.051067  0.343214  0.020230  0.037432   \n",
       " Grantham         -0.381064  0.428483  0.737602 -0.212346  0.385397   \n",
       " H_HoppWoods      -0.227556  0.301400 -0.223149 -0.350857  0.196139   \n",
       " uH-HoppWoods     -0.192369  0.136567  0.561774 -0.178552  0.080644   \n",
       " ISAECI           -0.257751  0.201983  0.703193 -0.121833  0.160520   \n",
       " H_Janin           0.375422 -0.410825 -0.091311  0.390456 -0.258795   \n",
       " uH_Janin         -0.193631  0.229424  0.494559 -0.186736  0.164622   \n",
       " H_KyteDoolittle   0.120355 -0.261219  0.188756  0.137600 -0.159820   \n",
       " uH_KyteDoolittle -0.132017  0.048728  0.542337 -0.131177  0.049781   \n",
       " F_Levitt         -0.621200 -0.052356  0.367643 -0.571243 -0.148768   \n",
       " uF_Levitt         0.021961 -0.047644  0.231528  0.025096  0.000396   \n",
       " MSS_shape        -0.650355  0.358402  0.429356 -0.429198  0.345006   \n",
       " u_MSS_shape       0.251051 -0.095402  0.139222  0.223207 -0.033603   \n",
       " MSW              -0.212439  0.475842  0.523194 -0.006729  0.476423   \n",
       " pepArc           -0.430700  0.145267  0.112730 -0.324384  0.103880   \n",
       " pepcats          -0.193767  0.564538  0.199617 -0.035341  0.503634   \n",
       " polarity         -0.130952 -0.074694 -0.403641 -0.257498 -0.177015   \n",
       " u_polarity       -0.224169  0.015854  0.529239 -0.236964 -0.038779   \n",
       " PPCALI           -0.175164 -0.312933  0.093874 -0.086829 -0.392079   \n",
       " refractivity     -0.205236  0.715677  0.515465  0.026518  0.706539   \n",
       " u_refractivity    0.112785 -0.009189  0.256747  0.191898  0.024193   \n",
       " t_scale          -0.503650  0.282634  0.608708 -0.362260  0.239356   \n",
       " TM_tend           0.230949 -0.358288  0.299322  0.310758 -0.220829   \n",
       " u_TM_tend        -0.210348  0.084996  0.557078 -0.218445  0.031994   \n",
       "Length             0.108802 -0.080551 -0.298065  0.055601 -0.101044   \n",
       "BomanIndex        -0.090337  0.397788 -0.205734 -0.060465  0.401743   \n",
       "Aromaticity       -0.012739  0.242039  0.395105  0.229339  0.229839   \n",
       "AliphaticIndex    -0.140135 -0.269008  0.514510 -0.181928 -0.201861   \n",
       "InstabilityIndex  -0.009469  0.119625 -0.085314  0.073655  0.229777   \n",
       " NetCharge         0.010098  0.476406  0.122402  0.065054  0.418700   \n",
       " MW                0.050685 -0.004531 -0.201984  0.028394 -0.025598   \n",
       " IsoelectricPoint  0.075741  0.336028  0.190104  0.137252  0.315634   \n",
       " HydrophobicRatio -0.109832 -0.092128  0.217145 -0.021883 -0.015655   \n",
       "\n",
       "                         ...           u_TM_tend    Length  BomanIndex  \\\n",
       "H_Eisenberg              ...            0.091984 -0.016710   -0.922374   \n",
       "uH_Eisenberg             ...            0.933421 -0.320635   -0.173678   \n",
       "H_GRAVY                  ...            0.184979 -0.061188   -0.879047   \n",
       "uH_GRAVY                 ...            0.937580 -0.320605   -0.317191   \n",
       "Z3_1                     ...            0.642256 -0.280980   -0.334002   \n",
       "Z3_2                     ...           -0.210348  0.108802   -0.090337   \n",
       "Z3_3                     ...            0.084996 -0.080551    0.397788   \n",
       " Z5_1                    ...            0.557078 -0.298065   -0.205734   \n",
       "Z5_2                     ...           -0.218445  0.055601   -0.060465   \n",
       "Z5_3                     ...            0.031994 -0.101044    0.401743   \n",
       " Z5_4                    ...           -0.031791 -0.028063    0.469115   \n",
       "Z5_5                     ...           -0.377926  0.018224    0.080197   \n",
       "S_AASI                   ...           -0.177625  0.156812    0.346242   \n",
       " uS_AASI                 ...            0.099607 -0.342402    0.016466   \n",
       " modlas_ABHPRK           ...            0.169463 -0.100602    0.380519   \n",
       " H_argos                 ...            0.418434 -0.181603   -0.776060   \n",
       " uH_argos                ...            0.869681 -0.315560   -0.396774   \n",
       " B_Builkiness            ...            0.557752 -0.268599   -0.362920   \n",
       " uB_Builkiness           ...            0.413259 -0.313265   -0.364771   \n",
       " charge_phys             ...            0.453630 -0.124550   -0.041017   \n",
       " charge_acid             ...            0.448328 -0.112097   -0.033625   \n",
       " Ez                      ...            0.199776 -0.145175   -0.402531   \n",
       " flexibility             ...           -0.345919  0.141559    0.558281   \n",
       " u_flexibility           ...            0.617649 -0.322931   -0.121726   \n",
       " Grantham                ...            0.574699 -0.266524    0.042116   \n",
       " H_HoppWoods             ...           -0.050728  0.094585    0.757711   \n",
       " uH-HoppWoods            ...            0.960756 -0.318822   -0.192274   \n",
       " ISAECI                  ...            0.608272 -0.246597   -0.522152   \n",
       " H_Janin                 ...           -0.245371  0.038281   -0.591251   \n",
       " uH_Janin                ...            0.937340 -0.299531   -0.240968   \n",
       " H_KyteDoolittle         ...            0.185417 -0.059937   -0.875389   \n",
       " uH_KyteDoolittle        ...            0.929739 -0.320886   -0.322038   \n",
       " F_Levitt                ...            0.461630 -0.119717   -0.182009   \n",
       " uF_Levitt               ...            0.057742 -0.389381   -0.139638   \n",
       " MSS_shape               ...            0.162195 -0.184580    0.276851   \n",
       " u_MSS_shape             ...            0.078198 -0.324924   -0.163936   \n",
       " MSW                     ...            0.322024 -0.227919    0.240073   \n",
       " pepArc                  ...            0.082832  0.033286    0.332538   \n",
       " pepcats                 ...            0.188800 -0.175651    0.370401   \n",
       " polarity                ...           -0.253429  0.168262    0.736987   \n",
       " u_polarity              ...            0.935643 -0.312678   -0.238775   \n",
       " PPCALI                  ...            0.124250 -0.000523    0.013713   \n",
       " refractivity            ...            0.292230 -0.231151    0.204249   \n",
       " u_refractivity          ...            0.081992 -0.330556   -0.147052   \n",
       " t_scale                 ...            0.322240 -0.199414    0.387343   \n",
       " TM_tend                 ...            0.139411 -0.099143   -0.818634   \n",
       " u_TM_tend               ...            1.000000 -0.302192   -0.286076   \n",
       "Length                   ...           -0.302192  1.000000    0.051678   \n",
       "BomanIndex               ...           -0.286076  0.051678    1.000000   \n",
       "Aromaticity              ...            0.151362 -0.169103    0.079700   \n",
       "AliphaticIndex           ...            0.447411 -0.140280   -0.734605   \n",
       "InstabilityIndex         ...           -0.370561 -0.002437    0.440816   \n",
       " NetCharge               ...            0.344801  0.055251   -0.017632   \n",
       " MW                      ...           -0.258455  0.983826    0.128973   \n",
       " IsoelectricPoint        ...            0.356816 -0.045726   -0.090545   \n",
       " HydrophobicRatio        ...            0.256638 -0.086866   -0.739589   \n",
       "\n",
       "                   Aromaticity  AliphaticIndex  InstabilityIndex   NetCharge  \\\n",
       "H_Eisenberg          -0.090046        0.628723         -0.275935   -0.263243   \n",
       "uH_Eisenberg          0.210791        0.391122         -0.274313    0.401666   \n",
       "H_GRAVY              -0.134800        0.751326         -0.285285   -0.032514   \n",
       "uH_GRAVY              0.125626        0.493420         -0.317818    0.308046   \n",
       "Z3_1                  0.439005        0.513779         -0.229134    0.222078   \n",
       "Z3_2                 -0.012739       -0.140135         -0.009469    0.010098   \n",
       "Z3_3                  0.242039       -0.269008          0.119625    0.476406   \n",
       " Z5_1                 0.395105        0.514510         -0.085314    0.122402   \n",
       "Z5_2                  0.229339       -0.181928          0.073655    0.065054   \n",
       "Z5_3                  0.229839       -0.201861          0.229777    0.418700   \n",
       " Z5_4                 0.258777       -0.381117          0.312249   -0.280417   \n",
       "Z5_5                  0.170050       -0.333393          0.324079   -0.122567   \n",
       "S_AASI               -0.364756       -0.247029         -0.040892   -0.420485   \n",
       " uS_AASI              0.085153       -0.005026          0.144370   -0.169765   \n",
       " modlas_ABHPRK        0.328317       -0.155822          0.097107    0.109245   \n",
       " H_argos             -0.028776        0.829775         -0.293577    0.129090   \n",
       " uH_argos             0.090354        0.540462         -0.341622    0.274414   \n",
       " B_Builkiness         0.376996        0.575562         -0.181530    0.341505   \n",
       " uB_Builkiness        0.081839        0.375939         -0.166250    0.017155   \n",
       " charge_phys          0.287514        0.151473         -0.268031    0.900922   \n",
       " charge_acid          0.287428        0.133192         -0.263353    0.887785   \n",
       " Ez                   0.018806        0.443711         -0.025091   -0.367098   \n",
       " flexibility         -0.421971       -0.344918          0.301031   -0.249963   \n",
       " u_flexibility        0.184604        0.162859         -0.177951    0.182256   \n",
       " Grantham             0.591540        0.209379         -0.110185    0.517968   \n",
       " H_HoppWoods         -0.258273       -0.466344          0.100586    0.074411   \n",
       " uH-HoppWoods         0.221801        0.359639         -0.320340    0.344705   \n",
       " ISAECI               0.498459        0.532012         -0.299646    0.484210   \n",
       " H_Janin             -0.146164        0.329147          0.061117   -0.466917   \n",
       " uH_Janin             0.157662        0.411481         -0.382266    0.470653   \n",
       " H_KyteDoolittle     -0.132135        0.747865         -0.285858   -0.024562   \n",
       " uH_KyteDoolittle     0.128757        0.493919         -0.311203    0.300554   \n",
       " F_Levitt            -0.055010        0.388374         -0.288856    0.171006   \n",
       " uF_Levitt            0.096123        0.149265          0.164122   -0.106017   \n",
       " MSS_shape            0.504809       -0.110117          0.202787    0.017561   \n",
       " u_MSS_shape          0.108136        0.102838         -0.019412   -0.072454   \n",
       " MSW                  0.753200       -0.120624          0.151931    0.477629   \n",
       " pepArc               0.135055       -0.128935          0.034891    0.130380   \n",
       " pepcats              0.538643       -0.319399          0.096428    0.341105   \n",
       " polarity            -0.266228       -0.612252          0.133634   -0.200345   \n",
       " u_polarity           0.111141        0.401228         -0.333709    0.231407   \n",
       " PPCALI               0.295970       -0.174316         -0.039703   -0.140053   \n",
       " refractivity         0.712378       -0.108534          0.147567    0.379750   \n",
       " u_refractivity       0.349198        0.032916          0.037115   -0.001988   \n",
       " t_scale              0.506939       -0.110324          0.097901    0.029069   \n",
       " TM_tend              0.104670        0.648781         -0.163909   -0.045849   \n",
       " u_TM_tend            0.151362        0.447411         -0.370561    0.344801   \n",
       "Length               -0.169103       -0.140280         -0.002437    0.055251   \n",
       "BomanIndex            0.079700       -0.734605          0.440816   -0.017632   \n",
       "Aromaticity           1.000000       -0.315232          0.092726    0.205881   \n",
       "AliphaticIndex       -0.315232        1.000000         -0.363955    0.110058   \n",
       "InstabilityIndex      0.092726       -0.363955          1.000000   -0.284332   \n",
       " NetCharge            0.205881        0.110058         -0.284332    1.000000   \n",
       " MW                  -0.059289       -0.170756          0.029534    0.119604   \n",
       " IsoelectricPoint     0.186721        0.190494         -0.214368    0.819725   \n",
       " HydrophobicRatio    -0.070186        0.695091         -0.289766    0.104172   \n",
       "\n",
       "                         MW   IsoelectricPoint   HydrophobicRatio  \n",
       "H_Eisenberg       -0.107942          -0.147791           0.686882  \n",
       "uH_Eisenberg      -0.266267           0.451366           0.237923  \n",
       "H_GRAVY           -0.138084           0.046363           0.894970  \n",
       "uH_GRAVY          -0.284901           0.358755           0.342766  \n",
       "Z3_1              -0.197580           0.290027           0.279503  \n",
       "Z3_2               0.050685           0.075741          -0.109832  \n",
       "Z3_3              -0.004531           0.336028          -0.092128  \n",
       " Z5_1             -0.201984           0.190104           0.217145  \n",
       "Z5_2               0.028394           0.137252          -0.021883  \n",
       "Z5_3              -0.025598           0.315634          -0.015655  \n",
       " Z5_4              0.054279          -0.222940          -0.574045  \n",
       "Z5_5               0.013460          -0.181559          -0.013919  \n",
       "S_AASI             0.127632          -0.457448          -0.339361  \n",
       " uS_AASI          -0.324017          -0.107070          -0.159059  \n",
       " modlas_ABHPRK     0.006294           0.087794          -0.271556  \n",
       " H_argos          -0.201524           0.204548           0.788791  \n",
       " uH_argos         -0.285344           0.297115           0.342982  \n",
       " B_Builkiness     -0.174674           0.349486           0.372530  \n",
       " uB_Builkiness    -0.325664           0.118808           0.281366  \n",
       " charge_phys      -0.057543           0.846699           0.137950  \n",
       " charge_acid      -0.043282           0.849271           0.117711  \n",
       " Ez               -0.148020          -0.295150           0.254447  \n",
       " flexibility       0.116797          -0.254877          -0.649182  \n",
       " u_flexibility    -0.297356           0.200611           0.095059  \n",
       " Grantham         -0.124180           0.477359           0.063789  \n",
       " H_HoppWoods       0.128548          -0.042088          -0.581547  \n",
       " uH-HoppWoods     -0.264040           0.344047           0.166681  \n",
       " ISAECI           -0.172044           0.497669           0.470836  \n",
       " H_Janin          -0.057706          -0.344046           0.542159  \n",
       " uH_Janin         -0.253021           0.477896           0.256807  \n",
       " H_KyteDoolittle  -0.136464           0.053087           0.896924  \n",
       " uH_KyteDoolittle -0.285996           0.355197           0.347833  \n",
       " F_Levitt         -0.085794           0.134944           0.358916  \n",
       " uF_Levitt        -0.389137           0.024630           0.054092  \n",
       " MSS_shape        -0.057288          -0.041961          -0.145086  \n",
       " u_MSS_shape      -0.345257           0.036631           0.116473  \n",
       " MSW              -0.078866           0.464691          -0.116111  \n",
       " pepArc            0.100298           0.102281          -0.141931  \n",
       " pepcats          -0.063081           0.234236          -0.257640  \n",
       " polarity          0.172749          -0.265736          -0.729403  \n",
       " u_polarity       -0.272567           0.237420           0.183368  \n",
       " PPCALI            0.018617          -0.107970          -0.067399  \n",
       " refractivity     -0.091391           0.312664          -0.017895  \n",
       " u_refractivity   -0.313323           0.087187           0.075966  \n",
       " t_scale          -0.055745          -0.038337          -0.228871  \n",
       " TM_tend          -0.147971           0.081990           0.749867  \n",
       " u_TM_tend        -0.258455           0.356816           0.256638  \n",
       "Length             0.983826          -0.045726          -0.086866  \n",
       "BomanIndex         0.128973          -0.090545          -0.739589  \n",
       "Aromaticity       -0.059289           0.186721          -0.070186  \n",
       "AliphaticIndex    -0.170756           0.190494           0.695091  \n",
       "InstabilityIndex   0.029534          -0.214368          -0.289766  \n",
       " NetCharge         0.119604           0.819725           0.104172  \n",
       " MW                1.000000          -0.004041          -0.136633  \n",
       " IsoelectricPoint -0.004041           1.000000           0.140001  \n",
       " HydrophobicRatio -0.136633           0.140001           1.000000  \n",
       "\n",
       "[56 rows x 56 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = norm_HemoPI1_model.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAMNCAYAAADKgdY8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11be555d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "figpath = \"./Figures/HemoPeps/\"\n",
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap=plt.cm.RdYlBu_r, vmax=1.0, vmin=-1.0)\n",
    "plt.title(\"Correlogram 56 modlamp descriptors HemoPI-1 dataset\")\n",
    "#plt.savefig(path.join(figpath, \"Correlogram 56 modlamp descriptors HemoPI-1 dataset.pdf\"))\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H_GRAVY',\n",
       " 'uH_GRAVY',\n",
       " ' Z5_1',\n",
       " 'Z5_2',\n",
       " 'Z5_3',\n",
       " ' H_argos',\n",
       " ' uH_argos',\n",
       " ' B_Builkiness',\n",
       " ' charge_acid',\n",
       " ' Grantham',\n",
       " ' uH-HoppWoods',\n",
       " ' ISAECI',\n",
       " ' H_Janin',\n",
       " ' uH_Janin',\n",
       " ' H_KyteDoolittle',\n",
       " ' uH_KyteDoolittle',\n",
       " ' MSW',\n",
       " ' polarity',\n",
       " ' u_polarity',\n",
       " ' refractivity',\n",
       " ' t_scale',\n",
       " ' TM_tend',\n",
       " ' u_TM_tend',\n",
       " 'BomanIndex',\n",
       " 'Aromaticity',\n",
       " 'AliphaticIndex',\n",
       " ' NetCharge',\n",
       " ' MW',\n",
       " ' IsoelectricPoint',\n",
       " ' HydrophobicRatio']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.75\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884, 26)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop features \n",
    "trim_HemoPI1_model = norm_HemoPI1_model.drop(norm_HemoPI1_model[to_drop], axis=1)\n",
    "trim_HemoPI1_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HemoPI-2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAMNCAYAAADKgdY8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XmYHFW9xvHvm4WsbCEQCPseQDBgBNk0XmQVBQSEiCio\nRFRUEBG9ICLoRdxYRNAom8oqEkRWQYiyw7AlBAJCAgkJW4CQhezzu39UDXSanpn+ZWEmM+/nefpJ\nd9Xbp05XV3f6zKk6RxGBmZmZmZmZLf+6tHUFzMzMzMzMbOlwA8/MzMzMzKyDcAPPzMzMzMysg3AD\nz8zMzMzMrINwA8/MzMzMzKyDcAPPzMzMzMysg3ADz8yWe5Kel/SJtq5HRyVpA0khqVv5eJSkr7R1\nvapJOkLS3e/zNm+W9MX3c5tWv7Y4JszM2pobeGa2xCR9TlKDpJmSXip/9O7S1vVq78ofnwvL/dZ0\nG1qVOVTSU5JmSXpO0q5tVF2rISL2johL68m+nw1jSadK+kuN5SFpk/ejDhXbbPoDQdMx/ryk79dT\nJ0mbSfq7pNckvSHpVkmbL6N61txny+t2zKzzcgPPzJaIpO8AZwP/BwwA1gN+C3x6McrqVs+y94uk\nru/DZu6LiL4Vt1EV298dOBM4ElgR+Cgw/n2ok7VChfft/9D3e3vLyCoR0RcYBpwiaa96ngNcD2xO\n8f3yIPD3ZVdFM7Pl3/L+n4WZtSFJKwOnAd+IiGsjYlZEzI+IGyLie2Wmh6SzJU0pb2dL6lGuGyrp\nRUknSnoZuLjWsjK7r6THJE2TdK+kbZqpU7PbK9d/r+xlnCLpK5W9B5IukXSBpJskzQI+LumTkh6V\nNF3SJEmnVpTV1DNxZLnuTUlHS/qwpNFlXc9bgl38Y+C0iLg/IhojYnJETG7mdR8h6R5JZ5XbHS9p\np3L5JEmvVp5KKGllSX8qe0ZekHRyUwNCUldJv5Q0VdJ44JPNVVDSxpLukPR6mb9M0ioV65+XdEK5\nP2ZJulDSABW9vDMk3S5p1ar9Obx8f16S9N0Wtr2apOvL9+ZBYOOq9YMk3Vb2/Dwt6bMV6/aR9GRZ\nh8mV25G0X3msTVfRa7pXuXyUpJ9Kugd4G9hIFb1yFe/BeZLekjRO0m7lup8CuwLnqejFOq9cvpOk\nh8r8Q5J2qqhHre0dUb63MyRNkHRYc/unNZK6SPp++Rpfl3S1pH5V70Vdx3ZZ1snlsfRqeWytXGu7\nEXEfMBb4QGt1jIgHI+LCiHgjIuYDZwGbS1qtmdfU2jFxTvl6pkt6WGWPePke/y9wSPn+PF4uP1JF\nD/qMcr9/taKs/pJuKPfFG5LuqvgMDZT0t/LzNUHSt1rajpnZUhURvvnmm2+LdQP2AhYA3VrInAbc\nD6wBrA7cC5xerhtaPv9MoAfQq5ll2wKvAjsAXYEvAs8DPcpyngc+Ucf29gJeBrYCegN/AQLYpFx/\nCfAWsDPFH8B6lvXZuny8DfAKsH+Z36B8/u/K7B7AHOC6cvtrl/X+WDP75ghgFjAVeAb4YdO+LF/n\nPOD7wLPAi8B5QK8WylpA0dvXFfgJMJGiN7VHWbcZQN8y/yeKnpAVy9fxDPDlct3RwDhgXaAfcGf5\nOpvqNgr4Snl/E2D3churA/8Bzq6o1/Pl+zGgYn88Ur6nPYE7gB9V7c8rgD7lfn+t6b2t8ZqvBK4u\nsx8AJgN3l+v6AJPK/dGt3N5UYMty/UvAruX9VYHtyvvbl8fA7uV7vjYwqOJ1T6Q4froB3av2RdN7\ncFy57pCyrH7V+6183A94Ezi8LG9Y+Xi1Zra3MjAd2LxcvxawVTP75lTgLzWWVx7v3y7fm3XK9+/3\nwBWLc2wDX6I4TjcC+gLXAn+uKqsbIIrP19vAbtV1quM7Z3/gpRbWN3tMlOs/D6xW1uV4iu+Dns3t\nM4o/bmxc1vtjZb2bjpUzyv3TvbztWua6AA8DpwArlPtkPLBnS++Nb7755tvSurV5BXzzzbfl9wYc\nBrzcSuY5YJ+Kx3sCz5f3h1I0YnpWrK+17ALKRlrFsqcrflw+z7sNvJa2dxFwRsW6TXhvA+9Prbye\ns4GzyvtNP1zXrlj/OnBIxeO/Acc2U9ZGwIblD8KtgSeBH5TrBpZlN1D8kO8P3AP8tJmyjgD+W/F4\n6/L5A6rqNph3G49bVqz7KjCqvH8HcHTFuj1opoFXox77A49WPH4eOKxqf1xQ8fibwHVV+3NQxfqf\nAxfW2E5XYH5V9v94t4F3CHBX1XN+z7uNyYnla16pRuasZl7bKIoe1epllQ28KYAq1j8IHF5rv1E0\n7B6sKu8+4Iha26NotEwDDqSZhn5F9tTyPZ5Wdas83p+ibGSVj9cq92k3ksc28C/g6xXrNq9R1jSK\nBuxTwLcqsnU18CgaopOBYc2sb/GYaOY5bwIfrNhnLTa8KBq43y7vn0bxR5JNqjI7ABOrlv0AuLje\n7fjmm2++LcnNp2ia2ZJ4Heivlq+TGwi8UPH4hXJZk9ciYk7Vc6qXrQ8cX54KNU3SNIrepYG8V0vb\nG0jRq9Ok8n7NZZJ2kHRnearVWxS9W/2rnvNKxf3ZNR73rbEdImJ8REyI4vTLMRQ/GA+qeB7AbyLi\npYiYCvwa2KdWWc3Ug4ioVZf+FD0O1ftp7fJ+9X6qzC2iPN3yyvI0x+kUvaJLun+qt13rfV6dovHQ\nXD3XB3aoOmYOA9Ys1x9IsS9fkPRvSTuWy9el+CNBc2odM5UmR0TUUX9477HalF+74vE724uIWRQN\n16OBlyTdKGlQC3W5OiJWqbxVrV8fGFmxf54CFlL0tjap972r9bnrVlVW/4hYNSK2iIhza1VYiw44\ntF7F8tWBfwLnR8QVzbze1o4JJH23POXyrfI1r8x7j9fK/N6S7i9PwZxGccw05X9B0Wv5z/L0zaaB\nY9YHBlYde/9btS/MzJYZN/DMbEncB8yl6LVpzhSKHzxN1iuXNQneq3rZJIqeq8ofq72b+aHX0vZe\nougFaLJuHdu+nGKQh3UjYmWKU7JU43lLQzSVHRFvUpyWGVXrl4apFD0d1fup6fq+l1h036xH8/6v\nrNfWEbESxSlwS7p/qrc9pUbmNYrTIZur5yTg31XHTN+I+BpARDwUEftRnG54HcVpfU3PW+S6rSqt\nvQdrS6p8/ZX1r35u9bHalK+8znKR50TErRGxO0Vv2zjgD63UpyWTgL2r9lHPaOY6z1bU+twtYNEG\nYati0QGHJgKouEbzn8D1EfHTFp7e4jFRXm/3PeCzwKplg/ct3j1eF9nXKq7d/RvwS4qe8FWAm3j3\nMzojIo6PiI0oBpX6TnnN5SRgQtV+XTEi9qm1HTOzpc0NPDNbbBHxFsV1Jr+VtL+k3pK6l3/1/nkZ\nuwI4WdLqkvqX+ewQ4X8Aji570ySpj4rBT1askW1pe1cDR0raQlJvimveWrMi8EZEzJG0PfC5ZN2b\nVe6nAeX9QWV9KkcIvBj4pqQ1yh+5xwE3LOl2I2Ihxb74qaQVJa0PfIdF99O3JK1Tbvf7zRQFxf6Z\nCbwlaW3ghCWtH/DD8ljaiuIauquaeQ3XAqeW2S0prs1scgOwmaTDy2Oyu4oBQraQtIKkwyStHMXA\nHdOBxvJ5F1IcI7upGDhk7VZ6yaqtQbHvuks6GNiColEARWNno4rsTWUdPyepm6RDgC1p5j0ue0v3\nk9SH4g8rMyvqvTh+R3EMrF+Wv7qk/RazrCuA4yRtKKkvRcP/qohYsAT1Q9JKwK3APRHR0nFYzzGx\nIkUD8DWgm6RTgJUq1r8CbKB3RytdgeLaxNeABZL2pjhdualu+0rapGzQv0XR+9lIcVruDBUDRfVS\nMWjRByR9uJntmJktVf5yMbMlEhG/omgcnEzxQ2gScAxFrwgUg300AKOBMRQDbPwkuY0G4CiKQUbe\npDgt6ohm4s1uLyJuBs6lGDTkWYoBJqD4sdycrwOnSZpB0Vi8uoVs1m7AaBUjdt5E8eP0/yrWnw48\nRDEAylPAo0BLPRgZ36QY4GU8cDdFT+VF5bo/UPyofpxi/13bQjk/Braj+IF7YyvZev2b4v35F/DL\niPhnM7ljKE4RfJni+smLm1ZExAyKH+OHUvQuvcy7A/dAcf3b8+VppUdTnL5JRDxI0ag8q3xN/+a9\nvWwteQDYlKKX9KfAQRHxernuHOAgFSNSnlsu35disI/XKXqX9i1Px62lC8VnbQrwBsWgH19L1K3a\nORS90/8sj+/7Ka4fWxwXAX+mGGRnAsWALN9cgro1OQD4MEWju+bpm1WaPSYojulbKD5PL5R1rDyd\n86/lv69LeqQ8hr5F8Zl/k+KPO9dX5DcFbqdoaN9HcfronWVDc1+K610nUBwLf6Q4HfQ926l3R5iZ\n1UuLXipgZtZ5SNoCeIJiNM4l6mmwJSdpA4ofxN2Xx/dD0hEUg6js0tZ1MTOzzss9eGbWqUg6QMVc\neatS9Oj8Y3lsTJiZmZnV4gaemXU2X6WYv+s5imtmluQUNzMzM7N2xadompmZmZmZdRDuwTMzMzMz\nM+sgWpqc2NqRy7V5qqt1zzm3p8p/cpPdU/ldHq9ndPkKs6fXn12hV6roYZdskMpf+c2ZqTzJkay/\nfPGqqfy3D94mld98ladS+a7KXV7Wbe6rqfyNL++cyn/05wen8n1/+NlUXqu1NGXbezXemZt1YPjE\nL6TyXbrkpoQ7a/RJqfwdx16Zyn9ozdzX/h3jZ7ceqnDJHx9K5a/9RWYGAljxtTtS+f/uV3M+7ZrW\nuvdvqbJHb3JAKr/Tw/+bysdqG6byeu2/qfxd8z+Tyu86c0Qq/+Pxn0rlh269Vir/j/ur54hv2YL5\nuRklzjl0WiofL+f2/7nPfSKV//Y2D6fyl0zYKZXf4jO7pfI7PPnrVJ7G3P9FHznojVT+umv2TeVX\n/knuu/z6z1/ceqj03OS3UmUfO7SlgZzf694pa6fyQ07LfdYBVvnjqGU13+tSlf19vLR9Lp5ul/vJ\nPXhmZmZmZmYdhBt4ZmZmZmZmHYQbeGZmZmZmZh1Eu23gSZpZ9fgISee1kD9V0mRJj1XcVpE0RFL9\nF2HUV7dRkoYszTLNzMzMzKx+Xbq07a296miDrJwVEb+sWtZQ3toFSd08qbKZmZmZmS0L7bjtuXRI\nGirphvL+xyp69x6VtGK5/ARJD0kaLenH5bINJD0l6Q+Sxkr6p6TK4R0PL8t5QtL25XP6SLpI0oNl\n+fuVy4+QdL2kO4B/Seoi6XxJ4yTdJukmSQfVqPtwSQ2SGu4gN5qXmZmZmVlH5h682tpx1ehVebol\ncFodzzmu4jl31lj/XeAbETEY2BWYLWkPYFNge2Aw8CFJHy3zmwK/jYitgGnAgRVl9S7L+TpwUbns\nJOCOiNge+DjwC0l9ynXbAQdFxMeAzwAbAFsChwM71noxETEiIoZExJD/YZU6Xr6ZmZmZmXVm7fkU\nzdllAwooesGA1q57q3WKZqV7gF9Lugy4NiJeLBt4ewCPlpm+FA27icCEiHisXP4wRaOsyRUAEfEf\nSStJWqUs59OSvltmegJNk3LdFhFNk7rsAvw1IhqBl5tpjJqZmZmZmaW05wbeUhcRP5N0I7APcI+k\nPQEBZ0TE7yuzkjYAKmeeXAhUnqJZPbFilGUdGBFPV5W1AzBrabwGMzMzMzNr36dJtqVOtVskbRwR\nYyLiTOAhYBBwK/AlSX3LzNqS1qijuEPK/C7AWxHxVlnWNyWpXLdtM8+9BziwvBZvADB0SV6XmZmZ\nmZkZdLwevOMkfb7i8f5V64+V9HGgERgL3BwRcyVtAdxXtstmAp+n6LFryRxJjwLdgS+Vy04HzgZG\nS+oCTAD2rfHcvwG7AU8Ck4BHgLfqe4lmZmZmZuYevNoUUX2mob0fJPWNiJmSVgMeBHaOiJeby78+\nd1Lqjbq15ydS9fnMgitT+f8MODSV3+UrG9WdHXf8X1NlD+7/aOuhCnO+e3oqP+Gkkan8Vqs+mMoz\nY2oqPuLpHVL5QwfPSeVXmvtEKt/4xEOpvLqvkMo/d8zfUvn1Prt5Kt9t2/VT+ZiSe7+yunys5phL\nzZq++u6pfLfvHp3Kd+nXM5Xv+c1DUvnbNv9JKj/01A+m8nfv9/vWQ6XGD30kVfYuL+W+N+9eK/e9\n+T9/2i2V1/Y7p/K8NjlX/pq5z0rjXXfkyt+uuZNemjF3di6+3tBU/tFNhqXyH2k4KZVn6ku5/IB1\nU/HGW29J5bsc8qXWQxVu6z88lX/zrv+k8odskvu/PaZOzOWfHpfKT9vxW3VnV33lH6myb2n8XCq/\n57gfpvJddvt0Kg9A972Uf9L779pem7dpQ+Yzs59ul/upo/XgLU9uKAdmWQE4vaXGnZmZmZmZWT2W\nuwaepJOAg6sW/zUiftoW9VlcETG0retgZmZmZra86tIu+8/a3nLXwCsbcstVY87MzMzMzOz90C4v\nTZR0iaSDqpbNbCG/gaTZlROjS/pCue6m8lTIpVW3IySdt7TKMzMzMzOzvC5d2vbWXi13PXgteK5y\nYvQmEbFPW1SmOZK6RkRrI3SamZmZmZmltWnbs+x5e6Li8XclnbqUt/G8pP6S+ki6UdLjkp6Q1DSP\n3Yck/VvSw5JulbRWuXyUpDMlPSjpGUm7VhS7brn+v5J+VLGtz5f5xyT9XlLXcvlMSb+S9Diwo6R9\nJI0rt3mupBuaqftwSQ2SGi7942VLc7eYmZmZmVkH1J578H4h6eREfmNJj1U8/mZE3FXxeC9gSkR8\nEkDSypK6A78B9ouI18pG3095d167bhGxvaR9gB8BTXMPbA98AHgbeEjSjcAsisnPd46I+ZLOBw4D\n/gT0AR6IiOMl9QT+C3w0IiZIuqK5FxQRI4ARkJ8mwczMzMysI2vPp0m2pfbcwDshIq5petDSNXil\nmqdoVhgD/ErSmcANEXGXpA9QNNRuKyc57wpUTkxzbfnvw8AGFctvi4jXy3pdC+wCLAA+RNHgA+gF\nvFrmF1JMbg4wCBgfERPKx1cAuclkzMzMzMzMamjrBt4CFj1NNDejbkJEPCNpO2Af4CeS/gWMBMZG\nRHMzC88t/13IovuqujctAAGXRsQPapQzx9fdmZmZmZktPe7Bq62td8srwBqSVpPUA9h3WW1I0kDg\n7Yj4C/ALYDvgaWB1STuWme6StqqjuN0l9ZPUC9gfuAf4F3CQpDXKsvpJWr/Gc58GNpK0Qfn4kCV4\nWWZmZmZmZu9o0x688lq104AHgcnAuCUorvoavIsi4tyKx1tTXNfXCMwHvhYR88rpGM6VtDLF/jgb\nGNvKth6kOOVyHeAvEdEAUF4z+E9JXcptfAN4ofKJETFb0teBWyTNAh6q58U9ucnu9cTe8ZkFV6by\n13Y7NJUfNvm4VF6rDqw7ux13wAq96s6PaNg8VZfhPz8hld8wxqfyN7+wTSr/0LjXUvlTdnsylX91\nwbapPD0+kIr/q/+urYcqDDlmz1R+478cmcprnS1S+cYH7kjlz1wjc2kwzJm7IJU/8cxvpfJP/e9h\nqfwGZ+a+G/7533mp/G1/eS6V/82Um1P57m8/kMqv/T871Z3d6OU/p8r+a9fk9+bE3HurdbZM5WPq\nC62HKvy7T+7qgI+9fXUqf6q+ncrv02WdVP6vD09oPVThhSteT+WvHv+HVP7Neeum8tdNzP0E++LK\nE1P5s9f8YSq/04a5v7Hv8dI5qfyCrrn36xPfyX33nHLCZ1P5QefvncqPH3Rq3dlxb34mVfZem+WG\nWXisz89T+dmbDEnlAXZ+YUl+kltba+tTNCkbYefWkevbwrrnKa55q7Vug/LureWtev1jwEdrLB9a\ncX8q5TV4EXEJcEkz27oKuKqOut8ZEYNUXKz3W6ChVnmdVqJxZ2ZmZmadk0/RrM27pW0cVfY2jgVW\nBn7fxvUxMzMzM7MOoM178DIkbQ1Un0MzNyJ2aIv6LK6IOAs4q63rYWZmZma2vHIPXm3L1W6JiDER\nMbjq9p7GXfWUCpKOkHReS2WXk5SPljS2nAz9j5JWKdeNkvR0ufwhSYOrnjtYUkjaq2LZnZL2rMod\nK+nicpLzrSuWnyDJvXhmZmZmZrZElqsG3rJSNsyOA/aOiK0oRti8FxhQETssIj4InE8xCmelYcDd\n5b9NrgCqr8A/FLgYOBY4X4W1gaOB7y+ll2NmZmZmZp3UcnWK5jJ0EvDdiJgMUM5Zd1Ez2fuAd4Zh\nLAdKORjYHbhLUs+ImANcQzHf3grlaJ0bAAOBuyIiJH0J+ALwSeDUiHhz2bw0MzMzM7OOx6do1tZR\nd0svSY813YDTWslvBTxSZ9l7AddVPN4JmBARzwGjKBpsRMQbFNMpNI3DeyhwdUQ0jYV7LPBTYPWI\nqDk2t6ThkhokNVw/c1qd1TMzMzMzs86qozbwZldepwecUu8TJW1dNgyfk1Q5CfllkiZQ9Pb9tmL5\nMKBpYqkraf40zUPLxwBExBTgDuCC5uoSESMiYkhEDPl031XqfQlmZmZmZtZJddQGXtZYiuvu3hnI\nBbiZRefWOwzYCLgU+A2ApK7AgcApkp4vl+8lacXyOX8HdpO0HdA7Ih6u2m5jeTMzMzMzs4QuXdr2\n1l6146q9r84AfilpnYpl75ltuzy98ofARyQNAnYDRkfEuhGxQUSsD/wNOKDMzwTupLie74rq8szM\nzMzMzJYmD7ICRMRNklYHbi575aYBTwC31sjOlvQrioFWugAjqyJ/A74G/Kl8fEWZqR5R08zMzMzM\nFlMx1qFV07tjflh7Fm9clnqjbtustXFlFrX76ONS+SvWzs3Tvt831607++j3/5Yqe6NVcsfwqj/9\nXCo/6qiaY+A0a/AauS+b/j2fTeXPu2e1VP6bO7+Wyneb/0YqHxPHpvKND41J5e898cFUfofvbJXK\nd+n3ns76FnXdZpNUPitez+3/V3Y6NZXvd96XU/lu66+UyuuzX0nlH9/yqFR+y69smcpPPfqSurPj\nB22fKnuXB45N5bPfm4dc+ZFUvsvue6TyLJiby3frkcvPzB3LrNQ/FVevlVP5lxtz7+/Tm+ySyn90\n7I9SeWX3Z/eeqXjjo3el8tpg41T+5kHVM0a1bG7D3an84AErth6qsGHPUan8vPP+kMo/9rlL6s5u\n3/ufqbJvnDo0ld9n+m9bD1Xq2yeXB7Tx8ctFy+nOtQa1aUPm4y+Na5f7yadompmZmZmZdRCd6hRN\nSSdRzFlX6a8R8dO2qI+ZmZmZmS2e9jzQSVvqVA28siHnxpyZmZmZmXVIHbLdK+kSSQdVLZvZynM2\nlXRDOf/dw5LulPTRct0Rkl4r58cbJ+k9F6yV666sePxFSVdUZfqX5Zwh6cyK5etLGi/Jk92ZmZmZ\nmdXB0yTU1o6r9v6R1BO4ERgRERtHxIeAb1LMe9fkqnJ+vJ2BkyStW/H8LYCuwK6Smq5kHQnsLql3\nRRkHAf8ATgP2L58HcA7ww4iYtgxenpmZmZmZdRLLdQNP0gaSnqh4/F1Jpy5GUYcB90XE9U0LIuKJ\niLikOhgRrwPPAmtVLB4G/Bn4J7BfmZsO/Bv4VEXuUOCKiJgNHAf8VtI+wIoRcVmN1zdcUoOkhhGX\n3rEYL8vMzMzMzDqTjnwN3i8knVxndivgkXqCktYDegKjKxYfAuwODKLo+bu8XH4FRePxKkkDgc2A\nO+Cdufe+DFwK1ByLOSJGACMgP02CmZmZmVlH1p5Pk2xLHXm3nBARg5tumSdKGinpCUnXViw+RNJo\nit678yNiTpkdAkyNiInAv4BtJfUrn3MjsLOklYDPAn+LiIUVZf4WeCginl68l2hmZmZmZvau5b2B\nt4BFX0NuFtB3jQW2a3oQEQcARwD9KjJXRcQ2wE7AzyStWS4fBgyS9DzwHLAScGBZzmzgFuAAytMz\nq7bbWN7MzMzMzCzBg6zU1o6rVpdXgDUkrSapB7DvYpZzOUVP26crlvWuFYyIBorr7b4tqQtFz9zW\nEbFBRGxAcQ3esIqnXAF8BxgA3LeY9TMzMzMzM2vVcn0NXkTMl3Qa8CAwGRi3mOXMlrQv8GtJZ1M0\nHGcAP2nmKWdSXLN3CzA5IqZUrPsPsKWktSLiJeA24E/AhRHh6+jMzMzMzGyZWa4beAARcS5wbh25\nvq2sHwfs08y6S4BLKh5PAZpO0fxIVXZhxToiYgGwejPljgJGtVL1wuzpdcWa7PKVjVoPVdCqA1P5\n/b65buuhCn//zaS6s5udnOtYnjEvdxiPvuC5VH6zE/u0Hqrw2uyFrYcqDGi4OpXv0+tbqfykWalL\nUNngmTNS+YVPjU/lmZfbP9vut3YqP+HPT6byG39nSCqfljyHY8GYyan8Y5vk/m60506bpPIv/vj2\nVH72nrn9ueHOa7YeqjD6d7n3t99RK9SdHfKF5Pdmv3VS+ez3Jl2Uy0/KfbctHPPfVL7rtlu0Hqow\n75aGVH6Fw3Mn4cSMN1L58d12TuU/dEDuu2fhDTel8l1WqXmiULM0YI1Uftrv7k7lVz1x5VR+x8/k\nPrs3zlmQyr+ZzK996UWpfNd1VkzlV+vVvf5wz9zvhu7Zz3q33O8ebZj7HbA8ac+nSbYl7xYzMzMz\nM7MOYrnvwcuQtDXF9XOV5kbEDm1RHzMzMzMzWzzuwautUzXwImIM0HH7qc3MzMzMrFNzuzdB0gGS\nHqu6NUr6oqRHysdjJR3dSjnHSHpWUkjq/37V38zMzMzMOrZO1YO3pCJiJDCy6bGk4cBhFFMhXBkR\ncyX1BZ6QdH3V6JqV7gFuoN4BVszMzMzMbBE+RbM275bFJGkz4BTg8IiYFxFzy1U9aGW/RsSjEfF8\nHdsYLqlBUsOIv+RGwzIzMzMzs87HPXiLQVJ3isnRj4+IieWydYEbgU2AE1rovatbRIwARgDE5As8\nh56ZmZmZWck9eLV5tyye04GxEXFV04KImBQR21A08L4oaUCb1c7MzMzMzDolN/CSJA0FDgSOqbW+\n7Ll7Atj1fayWmZmZmZmZT9HMkLQqcDHwuYiYUbF8HeD1iJhdZnYBzmqjapqZmZmZdXhd1NY1aJ8U\n4Uu76iXpB8DJwH+rVp0BnAQEIOC88vq55sr5FvA9YE3gVeCmiPhKS9uO1y5JvVGPclAmznb97kvl\n735l+1REjbKQAAAgAElEQVS+Z7f6O4ufGTAkVfaec25P5d+Yk5uZYsqW26byO036Uyrf7dXRqXz2\nhPN49ulUvvEjB6TyL8zMTS05afqcVH72goWp/MPPTE3lT97hsVT+jul7pPIrdM29Xx/o/3oqv9J/\nzk7lZ3z0W6n87S+slMoPWq1PKj97QWMq/8RL01P5Lzx3ct3ZW7f7Zarsvdd5OJW/97UdUvk/jHwi\nlb/4qBmthyr85qHNU/ljVr4ilZ+4/vGp/H/fmJXKb7hK71R+YO/cd+F9L62Xyn9oQO6z+/aCfqn8\nmm9dk8rfNi/3O2D3BRfnyu925DItX+ttlcrTpWsqPvatnVL5LRdc1XqoNKVPbt8PnH5lKv/6qp9M\n5afMWiWVB9hmtT7LRdPp8S0HtWlD5oNPjmuX+8k9eAkRcQZFY66Wuj/5EXEucO5SqZSZmZmZmVnJ\nDTwzMzMzM1vueBTN2tzAW4YkjQQ2rFp8YkTc2hb1MTMzMzOzjs0NvARJBwA/qlq8DXAk8G2KUUm7\nA7+JiN9FRM2LmSRdBgwB5gMPAl+NiPnLrOJmZmZmZh3M8tCDJ2kv4BygK/DHiPhZ1fqVgb8A61G0\nzX4ZEbmLVqssB7ul/YiIkRExuOkGnA/cBVwB7Fgu2wH4vqSBLRR1GTAI2BroBbQ4wIqZmZmZmS1f\nJHUFfgvsDWwJDJO0ZVXsG8CTEfFBYCjwK0krLMl23YO3mCRtBpwC7BQR8ypW9aCVhnNE3FRRzoPA\nOsukkmZmZmZm1la2B56NiPEAkq4E9gOerMgEsKIkAX2BN4AFS7JR9+AtBkndgcuB4yNiYrlsXUmj\ngUnAmeWE5/WUczhwSzPrh0tqkNQw4k+jllr9zczMzMyWd126tO2tDmtTtA2avFguq3QesAUwBRgD\nfDsicnMIVe+XJXlyJ3Y6MDYi3pkaISImRcQ2wCbAFyUNqKOc84H/RMRdtVZGxIiIGBIRQ4Z/YejS\nqLeZmZmZmS0FlZ0x5W34YhSzJ/AYMBAYDJwnKTcJbRWfopkkaShwILBdrfURMUXSE8CuQLOzkkr6\nEbA68NVlUE0zMzMzsw6tS5e2nWc8IkYAI1qITAbWrXi8Trms0pHAzyIigGclTaAYq+PBxa2Xe/AS\nJK0KXAx8ISJmVCxfR1KviswuwNMtlPMVitb6sCXtgjUzMzMzs3bpIWBTSRuWA6ccClxflZkI7AZQ\nngG4OTB+STbqHryco4E1gAuK6yDfcQZwkqQARDG86ZgWyvkd8AJwX1nOtRFx2rKpspmZmZmZvd8i\nYoGkY4BbKaZJuCgixko6ulz/O4pLvy6RNIaiHXFiRExdku2q6A209u7QX4xKvVGXf7drqvw/Nqyf\nyu+7Ve7U4BnzetSd7d8rd0zf2vMTqfw+c29O5Vfp/kIqf12fo1P5T8/6Yyo/98dnpvKPfvWyVP7D\nA5rtfK6p2wv3pPLXzDssld91vdyJBmtybyr/yMz/SeW3uvjwVL5Lv56p/L/3+G0qv1u3q1N5Ddg4\nlW+859ZUfuHYSa2HKssffkIqH+S+2/7xbPW17M07eNOW/i73Xn98dLNUfu9BK6fyPbrOaD1UYcXu\nL6XyXa84J5V/86Cfp/Kr/OU7qXy3T348lZ991rWpfO+TjkzlX11haCr/wEu5Y3OH738qle97eUtn\ngb1Xz7tz02idNvuoVP7rQ/ul8o3Jz2734fun8v1+cUQqf+kre6fyX5hwSv3h/rl9M+cjX0jle897\nLpUfO2f3VB5gq3592vbcxzo98+Et27Qhs9lDT7bL/eRTNM3MzMzMzDoIn6K5DEkaCWxYtfjEiMj9\nSdzMzMzMzBahNh5kpb1yA28ZiogD2roOZmZmZmbWefgUzQRJB0h6rOrWKOmLkh4pH79z4WQL5Vwo\n6XFJoyVdI6nv+/UazMzMzMys43IPXkJEjARGNj0uJzM8DLgCuDIi5paNtSckXR8RU5op6riImF6W\n8WvgGOBny7b2ZmZmZmYdh0/RrM09eItJ0mbAKcDhETEvIuaWq3rQyn6taNwJ6AXUHAFI0nBJDZIa\nnrv/H0uv8mZmZmZm1iG5gbcYJHUHLgeOj4iJ5bJ1JY0GJgFnttB711TGxcDLFDPV/6ZWJiJGRMSQ\niBiy8UdywymbmZmZmXVk6qo2vbVXbuAtntOBsRFxVdOCiJgUEdsAmwBfLGeib1ZEHAkMBJ4CDlmW\nlTUzMzMzs87BDbwkSUOBAymum3uPsufuCWDX1sqKiIXAlWV5ZmZmZmZmS8QNvARJqwIXA1+IiBkV\ny9eR1KsiswvwdDNlSNImTfeBTwPjlnXdzczMzMw6EnVRm97aK4+imXM0sAZwQdE2e8cZwEmSAhDw\ny4gY00wZAi6VtFJ5/3Hga8uuymZmZmZm1lkoouYAjtbezLkh9Ua9fdK5qeJ7//yEVH72KWel8v++\n4Lm6sxtPeCxV9uq9Xkrlb+qxdyq/55zbU/k+3aam8iv8+9JU/vaNT0nlV+qR+zvODpN/lco3Pj0h\nlV/4xpxUfv4zb6TyL949OZXf+DtDUvmuW2+aytMtt//n3fhQKv/0l/+Syn/gnmNT+ed/+UAqP//6\nXH6dU3IDSL300MupfK/b7607u/qII1Nlr/Dtr6fys3+Y+2z1+NQHU3nenp2KL3h8UirffY8PpfKz\nLxqVyvf6/udSeV5tcSyz97i+51Gp/B6XHJHK9zxqr1R+/nX/TuW7Ddk4lX/93LtS+f4/yNV/9mX1\nf7YA/nTQ71P5YYPnp/K9Lz45le+y4gqpfNdhie+HaEyV/Y/nc5/1fSP3u6Fxox1TeYCu2qn9dk9V\nGP/Rbdq0IbPRf0a3y/3kHjwzMzMzM1vutOeRLNuSG3jLkKSRwIZVi0+MiFvboj5mZmZmZtaxuYFX\nJ0k7ANXnFwwCjouICyQ9D8wAFgILyvnrDmimrIOBU4EtgO0jomGZVdzMzMzMrAPq0o4HOmlLbuDV\nKSIeAAY3PZa0J3A2UHki9Mcjop4LsJ4APsN7G4xmZmZmZmaLzQ28xSCpPzAC+ExEvJ19fkQ8VZaz\ntKtmZmZmZmadmOfBWzwXAudHxMMVywK4XdLDkoYvjY1IGi6pQVLDiAtvWRpFmpmZmZl1CJ4Hrzb3\n4CVJOhpYCfhF1apdImKypDWA2ySNi4j/LMm2ImIERU9hepoEMzMzMzPrfNzAS5A0CDgZ+EjEopOc\nRMTk8t9Xy9EztweWqIFnZmZmZma1eZqE2nyKZp0krQBcTjFq5otV6/pIWrHpPrAHxUAqZmZmZmZm\n7xs38Op3ILA1cJKkxypuxwEDgLslPQ48CNwYEc1eNCfpAEkvAjsCN0ryvHhmZmZmZrbEFOFLu5YL\nc29KvVFjZ30sVfyGK41P5f/94sBUfrN+ferOvrjF4NZDFT724gWp/OvzNknlb+35iVR+2JunpvJx\n/12pPH3r35cAGrR1Lt+zbyr/1grbpPIPvdwvlX9t5rxUfqVe3VP5T652Ryo/ev4+qXz35EXYcxc2\nth6qMLhH7u9Dc3pvlMq/NmezVP6pqXNT+TX79kjlZ85bkMp/5NET687+Y/PTU2Xvvv7LqXz2e/Pm\ne55P5c/Zc2wq/2KvA1P5tR8/LZXvsu3OqfwLC/dM5dfvc28qP2X2tqn8wy/njrVPrZub0jam5Y6f\neCp3YtC0HY5J5Vd99vJU/vqeR6Xy+w28L5WPt17N5Z8Zl8r/Y+36vxsAPjXpjLqzLw75aars9brf\nmcq/wZap/IszV0/lAbZZrc9yce7ji/sMadOGzDo3NbTL/eQePDMzMzMzsw7Cg6wsQ5J+C1T/CfOc\niLi4LepjZmZmZtZReJCV2tzAW4Yi4httXQczMzMzM+s8fIpmQjk4ymNVt0ZJe0taWLHs+lbKuUzS\n05KekHSRpNxFQ2ZmZmZmZjW4By8hIkYCI5seSxoOHAbcCsyOiHpHB7kM+Hx5/3LgK0BupBAzMzMz\ns05MyYHMOgv34C0mSZsBpwCHV0963pqIuClKFNMqrNPMNoZLapDUMOKPNy95pc3MzMzMrENzD95i\nKE+pvBw4PiImlot7SnoEmAf8LCKuq7Ocw4Fv11ofESOAEUB6mgQzMzMzs47MPXi1uYG3eE4HxkbE\nVRXL1o+IyZI2Au6QNCYinmulnPOB/0REciI0MzMzMzOz93IDL0nSUOBAYLvK5RExufx3vKRRwLZA\nsw08ST8CVge+uqzqamZmZmZmnYsbeAmSVgUuBj4XETOqlr8dEXMl9aeY++7nLZTzFWBPYLfs9Xtm\nZmZmZuZ58JrjBl7O0cAawAXSIgfUSOAgSY0UA9f8LCKebKGc3wEvAPeV5VwbEactmyqbmZmZmVln\noWIgR2vvvvy7+1Jv1IVfnZMq/+YXtknlB6+R+4vJa7N71J3dYtWxqbJv7Ht4Kr/XjCtT+R4zxqXy\nV6x6aiq///xrUnn95Aep/D1f+lMqv/PASal8z1fvS+X/teCzqfyW/XOD/Q7s+XAq/8Lbu6Ty69w4\nPJXXqium8k8NOTOV33LSr1J5DRqSysczj+Tyk6ek8jN3OzaVn7ewTyr/ytur1J3daKVnU2XfNXnd\nVP4Dq+eO5Zdn5f4Gu92q96byjTf9NZWftfd3Uvlefz49le+6/ydT+fmXXpsr/9jjU/nJs7ZN5f/x\nxCup/LDf5f7vWvGi3Ge925hbUvlrex+dyn94rdx3W1fNz+W/uEcqP+CCXP2vn5473vb485F1Z3sO\n+2iq7Bkb7Z/Kr7Qg97tkSuTqAzCw9yrLRdfYq5/dsU0bMmtcfV+73E+eJsHMzMzMzKyD8Cmay5Ck\nkcCGVYtPjIhb26I+ZmZmZmbWsbmBtwxFxAFtXQczMzMzs47I8+DV5lM0EyQdIOmxqlujpL0lLaxY\ndn0r5Vwo6XFJoyVdI6nv+/UazMzMzMys43IPXkJEjKQYMRMAScOBw4BbgdkRMbjOoo6LiOllGb8G\njgF+tpSra2ZmZmZmnYx78BaTpM2AU4DDs3PZVTTuBPQCao4AJGm4pAZJDePuum5Jq2xmZmZm1mGo\nq9r01l65gbcYJHUHLgeOj4iJ5eKekh6RdL+kVse7lXQx8DIwCPhNrUxEjIiIIRExZNCuuSF0zczM\nzMys8/EpmovndGBsRFxVsWz9iJgsaSPgDkljIuK55gqIiCMldaVo3B0CXLxsq2xmZmZm1nF4kJXa\n3IOXJGkocCDFdXPviIjJ5b/jgVFAqzOkRsRC4MqyPDMzMzMzsyXiBl6CpFUpetq+EBEzKpdL6lHe\n7w/sDDzZTBmStEnTfeDTwLhlXXczMzMzM+v4fIpmztHAGsAFRdvsHSOBgyQ1UjSafxYRNRt4gIBL\nJa1U3n8c+FprG/72wdvkajrjplT8oXGvpfKfWG96Kj+g4epUXpsNqju73/gTiAGbJ0qfCXf+re50\nzJuXKBv2n39NKn9d94NS+c8suDKV3+353Nm/ce9Lufy0t1L5WVvlOqxXWiFZn+ceSeXXX2dWKs9+\nB6fi8doLufKTxm/4vVR+oxm5z+KCu8ek8vrqcan8ipNvS+VZkPs8vrLy8Lqz46dvwlar3F93fo91\np3LqrQPrzn9sj9yxNrDXjNZDFeKt11P5BRNzn92+0x5I5edNnZ3Kd33z5VReK66Qynd59p5Ufr0B\nk1P5oyfdmMo37lD/sQPQ9e7cZ3faJQ+l8tudk/suWa/rP1P5V9khle//nY+l8nMvqP//dYAVvvCp\nVL7nl/ZM5WcPHFp3thtz6aIFdecX9uyfqsv//eXZVB7gvMOHpJ/TFtrzQCdtyQ28hIg4AzijmdU/\nrrOMRooePmtGpnEHJBt3pBp3ZtZ5ZBp3QKpxZ2adR6ZxB6Qad2b1cAPPzMzMzMyWO+riq81qcQNv\nGZI0EtiwavGJEXFrW9THzMzMzMw6Njfw6iRpB+D3VYsHAcdFxAWSngdmAAuBBeX8dQe0UubxwC+B\n1SNi6jKotpmZmZmZdSJu4NUpIh4ABjc9lrQncDZwaUXs4/U21CStC+wBTGwta2ZmZmZmi/I8eLX5\nxNXFUE6FMAL4fES8vZjFnAV8D4ilVjEzMzMzM+vU3MBbPBcC50fEwxXLArhd0sOSWhyXW9J+wOSI\neLyV3HBJDZIarrn0oiWvtZmZmZlZB9Glq9r01l75FM0kSUcDKwG/qFq1S0RMlrQGcJukcRHxnxrP\n7w38L8XpmS2KiBEUPYWMfn2We/rMzMzMzKxF7sFLkDQIOBk4vJzP7h0RMbn891WKic+3b6aYjSlG\n1ny8HJhlHeARSWsuq3qbmZmZmVnn4B68OklaAbicYtTMF6vW9QG6RMSM8v4ewGm1yomIMcAaFc99\nHhjiUTTNzMzMzOrnQVZqcwOvfgcCWwMnSTqpYvmlwN+BkZKg2KeXR8Qt738VzczMzMysM1OEL+1a\nHsxd2JB6oy59ZI3WQxWGD34ylT/r/k1T+T49u9edPWr921Nlzzn/2lT+riP/lMp/YtIZqfzc259K\n5fXD01P5a7sdmsp3ffI9l4K26JC1c/lH5u6dyg/o3dh6qMKDL81N5bdbc6VUvne3N1L5l2blyp8+\nd0EqP3iNF1sPVVjY2COVnzpnnVR+3sLc+zW/Mfd/yiMvTkvld1y/Xyq/acOJdWcvWe17qbK/tHXy\ne/O+jVP5NVfrk8ofuua/Unlen5KKa90tUvnouWIqP2XWtqn8wDf+nMrfyedS+cefz303DFp3lVR+\nz2d+lMpryI6p/Bt9PprKr8aYVP5X92+Wyh+/w7hUPt5+K5WncWEqfs3re6XyBz59Uuuh0v0f/mWq\n7J363ZPKX/TkNqn8l7bJ/S4BoOvuy0XX2MxjdmvThkzf8/7VLveTr8EzMzMzMzPrIHyK5jIk6bfA\nzlWLz4mIi9uiPmZmZmZm1rG5gbcMRcQ32roOZmZmZmYdkQdZqc2naCZIOkDSY1W3Rkl7S1pYsez6\nVsq5RNKEivzg9+s1mJmZmZlZx+UevISIGEkxxx0AkoYDhwG3ArMjItNQOyEirlnKVTQzMzMz6xy6\nugevFvfgLSZJmwGnUGPS86W4jeGSGiQ1/PEPuZEizczMzMys83EP3mKQ1J1i0vPjI2JiubinpEeA\necDPIuK6Voo5Q9IpwL+A70fEe8aCj4gRwAjIT5NgZmZmZmadjxt4i+d0YGxEXFWxbP2ImCxpI+AO\nSWMi4rlmnv8D4GVgBYoG3InAacu0xmZmZmZmHYgHWanNp2gmSRoKHAgcU7k8IiaX/44HRgHNztga\nES9FYS5wMbD9sqqvmZmZmZl1Hm7gJUhalaJB9oWImFG5XFKP8n5/irnvnmyhnLXKfwXsDzyxLOtt\nZmZmZmadg0/RzDkaWAO4oGibvWMkcJCkRopG888iotkGHnCZpNUBAY+V5ZqZmZmZWb26uq+qFkV4\n7I7lwYLG+1Nv1NsL+6XKn7Ng5VS+X48JqfykWfXPILH+mB+lyr5/w/9N5bsod772Dt1aGy9nUf96\ne99Ufrf5F6fyV8/7fCq/cMuPpvIfevOxVH7TlRtS+X+MH5TK77LOnFR+ZLI//OCt3zO+UYsmTF8z\nlR/Qe14qP2lG91T+wzNHpPKz198jlR/35oap/LZTfp3Kz9lqv1T+oobcd9VXt3+57uy8xj6psmfO\nXyOVz35vdps3NZX/++QdUvk+3bum8tsOmJXK3zu5Vyr/qTXvTuUnNu6Zyq9+xoGpfK9Tv5XKx7T6\njzWAa6ftk8oPWSt37A/s/XgqP3761qn8Jis/msrrrtxo4F222ymV/89b/5PKb7vGS6n8w6+sVXd2\nhzVfSJXd89HcrFkTtzg5lW9cjN/6G67Yc7m4uO3t7+3Vpg2Z3j+/pV3uJ/fgmZmZmZnZ8seDrNTk\nBt4yJGkkUP3n7xMj4ta2qI+ZmZmZmXVsbuAtQxFxQFvXwczMzMzMOg9fmVhB0kmSxkoaLekxSc1e\n0CCpv6T5kt4zQIqkwZJC0l71lC9plKQhS/8VmZmZmZl1TOqqNr21V+7BK0naEdgX2C4i5pbTHazQ\nwlMOBu4HhgG/q1o3DLi7/PeWxSzfzMzMzMwsxT1471oLmFpOPk5ETI2IKS3khwHHA2tLWqdpYTm3\n3cHAEcDuknouZvlIGi6pQVLDH0bkRnI0MzMzM+vQuqhtb+2UG3jv+iewrqRnJJ0v6WPNBSWtC6wV\nEQ8CVwOHVKzeCZgQEc8Bo4BPZstvEhEjImJIRAw5avj+i/myzMzMzMyss3ADrxQRM4EPAcOB14Cr\nJB3RTPwQioYdwJUUvXlNhpXLFlmXLN/MzMzMzCzN1+BViIiFFL1uoySNAb4IXFIjOgxYU9Jh5eOB\nkjYFxgMHAvtJOgkQsJqkFSNiRqJ8MzMzMzNrSTse6KQtuYFXkrQ50BgR/y0XDQZeqJHbDOgbEWtX\nLPsxRaPvfmB0ROxZse5S4ABJD9RTvpmZmZmZ2eJSRLR1HdoFSR8CfgOsAiwAngWGR8TUqtyPgF4R\n8f2KZdsAV1E08B6IiN9VrPs08DXg5ObKlzQK+G5ENDRbwdnX596ohQtS8ek9PpDKr9T4bCofTzyQ\nyi/cdu/6y06eadzt0RtTeW3+wVR+ds+NU/ke9/45le8yuNnZO2p6unHfVP7hVQen8sNeOTGV10pr\npPIsmJeKN47OHWvqmvs718IPfyqVz+o67blU/vXeQ1P51d7MHf9MeyMVn7Le11P5gdOvbD1UaWLu\n72KN23+y9VCFrnOmth4qTe82KFX2SoxP5aN7r1R+9vE/TeV7fX6nVD4mv5TKa9Pcd+GsjXPvVZ/p\nj6Xyr/X6RCq/+hvXpvLMm5PMz0/FGx8bm8p32WaLVF7r545nFuTqf/Mb/5PKD13nxVS+59PJ/9u3\nyP1fyqxpqfhTC+r/HTNpeu7Y+cjA+r+nAGbOT/6/Cwzsvcpy0TU257RPtWlDpucp/2iX+8k9eKWI\neJhigJTWcj+usWw0UPObNCKuB64vH9YsPyKG1l3RTiDTuDMzW1oyjTszs+ZkGndmy4IHWTEzMzMz\nM+sg3IPXAkkjgQ2rFp8YEbe2RX3MzMzMzKzU1X1VtbiBVyoHWfk9xTVyPYC7IuKAVp5zNsWk5utG\nRGPVuuuANSPiI61sY7ikoRTX4OUuljIzMzMzM6vgBt67zgXOioi/A0jauqWwpC7AAcAk4GPAnRXr\nVqGY826mpI0iounK+tQ2zMzMzMysNnVpl2OctLlO168paWbF/YMkXVI+XAt4Z8imiBjTSlFDgbHA\nBSw60TnAZ4B/UEx0fmjF8uw2zMzMzMzM6tbpGngtOAu4Q9LNko4re+FaMgy4AhgJfFJS9xrrrmDR\nxl9qG5KGS2qQ1DDiQl/2Z2ZmZmZmLXMDrxQRF1NMdfBXit65+yX1qJWVtAKwD3BdREwHHgD2LNcN\nADYF7o6IZ4D5kj6Q3UaZHxERQyJiyPAv79lczMzMzMys8+mqtr21U52xgVc5IWLPRVZETImIiyJi\nP4rJyJub/XtPioFSxkh6HtiFd3vqPgusCkwo121QsS6zDTMzMzMzs5TO2MB7RdIWFYOkACBpr6bT\nLCWtCawGTG6mjGHAVyJig4jYgGIqhd0l9S7X7VWx7kOU1+Elt2FmZmZmZpbSGUfR/D5wA/Aa0AD0\nLZfvAZwjaU75+ISIeLn6yWUjbi/g6KZlETFL0t3AN4H1gfsr1k2Q9JakHZrbhqRBS/UVmpmZmZl1\ndO34NMm21OkaeBFxDXBNjeXfAb5Tx/PfBvrVWP6Z8u6ZNdZtV959oNY2ImIUMKql7d748s6tVW0R\ne7/yy1T+X/13TeX3j7Gp/MKnxrceKr2w6eBU2Ru9fkEq3/j0hFR+5taHp/IrvXp7Kh/T3krlH5m7\ndyo/uH9DKr/ZKyem8lcMeM8h36Khsx5I5dead2Mq3/jfXKd4t8OPTOW5/LepeMyan8pPP/InqXzP\nLtNSebr3bD1T4a1f3ZLKD/xB99ZDFeK1qak8U97zd7cWXdiwTt3Zo7g5Vfad/XZM5T9N7nuT3ivm\n4qd/PZWfe8GfUvkex34tlZ/13Z/nyt/q0VQ++uWO5dV3zX0WmfZmLj9zVio+/4GnU/kVvnhwKj/t\n+Nz/jc//7JhU/oMvnZ3Kr7VW7v+uHvf/JZVf+NxLqfy0jb+YyvfvXv/xufmYH6fKXn27b6XyfR+6\nMJV/cqOTUnmAgb3TT7F2pNM18MzMzMzMbPnnefBqcwOvBZL25L09chMi4oBaeTMzMzMzs7bkBl4L\nIuJWwBPQmZmZmZnZcqFdjqIpaZSkIeX95yX1X4pld5P0mqSf1djm05Iek/SUpOEV6xapg6Shkm4o\n7x9RlveYpCclHVVj+ThJx1U8/1RJ3y3v95R0m6RTl9ZrNDMzMzPr8DwPXk3tsoG3jO0OPAMcLKn6\nnTksIgYDOwNnlhOa1+Oq8nlDgf8rJzuvXL4zcJKkdSufVJb/N+DhiDh1sV6NmZmZmZlZaak18CTN\nlPQLSWMl3S5p+7JXbLykT5eZnpIuljRG0qOSPl4u7yXpyrLnbCTQq5ltXCfp4XIbw8tlXSVdIumJ\nstzjaj23wjDgHGAi0NwQaH2BWcDCzD6IiFeB5yimSqhc/jrwLLBWxeJuwFXAfyPi+7XKkzRcUoOk\nhluuuDRTFTMzMzOzjq1Ll7a9tVNL8xq8PsAdEXFC2Uj7CUVv2ZbApcD1wDeAiIity7nf/ilpM+Br\nwNsRsYWkbYBHmtnGlyLiDUm9gIck/Q3YAFg7Ij4AIGmV5iooqSfwCeCrwCoUjb17KyKXSZoLbAoc\nGxGVDbw7JTU97guMq1H+RsBGFI25LSuWrwf0BEZXxL8H3BYRxzZX34gYAYwAuHHC69FczszMzMzM\nDJbuKZrzgKYJk8YA/46I+eX9Df6fvTuPs3O++z/+ek8WCSFIUGKJndhCg9qTWoqqXW2trYRSVMtN\n7/q16c5dvZVShBJF7YrbviW1L0HEGktCLUFiD9nn8/vjXFOXcWbO+WQxk8z7+XicR865zvv6Xt9z\nZhbTxKQAACAASURBVOZMPvO9ru+32L45cClARLwAvAasBmxZ2j6aLxZCZcdIeorKQuLLUSnExgIr\nSfqLpO2Bj1vp407A8IiYTOXUyF0ldSo9v39ErAssDxwvqTwSNygi+henXB7arN29JY0CLgcOj4j3\nS9tHUyn4/hoRU0r73A9sWhS4ZmZmZmZms21OFnjTI6JplKkRmAoQEY3MgZFCSQOpjL5tEhHrAU8C\n3SLiA2A9KguFHwFc0Eoz+wLbSHoVeBzoBXyzeSgiJlAZRdy4zu5dWRR/G0fEP5ttXxfYFDhF0tdK\nz90L/Bi4VVL51E0zMzMzM6tBndSmt/bqqz559D5gf4Bi5Gp5YAyVYme/YvvawLpV9u0JfBARnxWn\nd36jyPcGGiLiWuBkYINqB5a0CLAFsHxE9I2IvlROGd23SnZBYH0q19PNtogYCVwCHNts+7XAacBt\nrZ1aamZmZmZmVo+veh28vwLnSHoamAEcFBFTJZ0DXCTpeeB5KqNrzd0GHFFkxlA5TROgT7FvU7H6\nsxaOvRuVawSnlrbdAPyPpAWKx5dJmgwsAAyLiGr9mFWnAk9I+n15Y0ScU8y6eaOk7ZqdxmlmZmZm\nZtU0tN9RtLakz8+qtPbskx9+M/WF6nHoFqn23/j5/6XyyxywdiofU2bUnb1/u7+m2p7w6bRUfpc7\nf5TK37vzual81qfTU5O1MuBrC9QOlYx8e2rtUMkufR5J5d9q3DyVH7FQvWc+V+z6kxVqh0q6rpVb\nNrNhmdzg+YeD/iuVnzpzkVS+y2HfSeWv+/HlqfxhK45I5bVgrv9/eiz32fCTRf+Ryk+7a1Qq32W9\nZesP91go1fZbv74zlf/afmum8vHp9FS+84DVU/mP1jkwle/53l2p/DuL7p7Kd1Lu9T75Tu6z8Mpb\nx6Ty5699XSr//oAW50yraurMhVP5PjNvT+UndM19Ns/83m6p/JKH9E/lR290Wip/xlVPpfKnHrxK\nKv/eJlul8lPvGll3tlf3XNHx2kf1/x8JYPPF70vlX9/1F6k8wHK3PTFPVE7Tz9unTQuZLodf0S7f\np/Y7v6eZmZmZmZmlfNWnaH4lJJ1NZXHxsjMi4qK26I+ZmZmZmc1h7Xiik7Y0XxZ4EXFUW/fBzMzM\nzMzsq9bhTtGU9Gox82bT44GSbmrLPpmZmZmZWY4a1Ka39qrDFXhzg6T5ciTUzMzMzMzmLS7wapC0\nkaSHJD0p6UFJqxfbD5J0o6R7gLslNUj6q6QXJN0p6RZJexbZrYv9n5Z0YdOyDJJOkfScpNGSvjS9\nlKTBkkZKGnnRc299pa/bzMzMzMzmPR115Gm4pKa56XsAL7SSfQHYIiJmSNoG+D2wR/HcBsC6EfF+\nUcz1BfoBS1JZz+9CSd2AYcDWEfGipL8DP5R0CZW1+daIiKi20HlEDAWGQn6ZBDMzMzOz+Vonj1VV\n01HflUER0T8i+gOH1sj2BK6W9AxwOrBW6bk7I+L94v7mwNUR0RgRbwPDi+2rA+Mi4sXi8cXAlsBH\nwBTgb5J2Bz6b7VdlZmZmZmYdWkct8DJ+AwyPiLWB7wDdSs99OquNRsQMYCPgGmAn4LbZ6aSZmZmZ\nWYfSSW17a6dc4NXWE3izuH9QK7kHgD2Ka/GWAgYW28cAfSWtUjz+PvAvST2AnhFxC3AcsN6c7riZ\nmZmZmXUsHfUavIz/AS6WdDJwcyu5a4GtgeeA14EngI8iYoqkg6mc5tkZeAw4F1gcuKG4Rk/AT1rr\nRI//991Up1/Z46xUfuVLD07l7x94fiq//i596s4OeGIP7jv+qrrzWyyf+zvF9Bffrx0qmTBpWiq/\nVd9utUMli3Qdn8rf+eqSqfyWy01J5Zmee71LT2vtx+LLdv3JCqn89f/7Wiq/+2+7p/Kdps6sHSpZ\nbIUrUnk6d0rFZwxaPpXfbOVeqfy0C/6ZyndesWcqf+RuK6byr2xR/886QJ9tct8/7272i7qzH222\nRart1a4dnMrfv+V5qfxGR6+ZyrNk7rOh5ycP5NrvmvvZWuqTG1N5LZH73tluqdxJNCvss3Uq/9Qm\nud+L/Z/fKZXXJxNTeTp3ScV7P5/7fuOMA1PxBzc9I5V/9+7JqfwPdl07le/dbXQqv/C3V0rlH5s6\no+5s/54Pp9oeNWVAKh/vvZ7KL3t67v+QNu/rcAVeRPRt9ngEMKKV/EPAaqVNJxfbh1GZPKUp1yjp\n+IiYJKkX8CjwdPHc3cD6zZoeT+UUTWsmU9yZmZmZWcfUnteia0sdrsCby24qZsPsCvymmGzFzMzM\nzMzsK+ECr1CcRnlss80PRMRR9bYREQPnaKfMzMzMzMwSOlSBJ2kIMCkiTittexUYEBEXARe1UdfM\nzMzMzCyjHc9k2ZY8i+YcICk3i4KZmZmZmdlcMF8WeJImle7vKWnYbLR1vaTHJT0raXBp+yRJf5L0\nFLCJpB0lvVBkz5R0U5FbvGhjtKSHJa1bbN9K0qji9qSkhWf9FZuZmZmZdTANattbOzVfFng1HFcq\nrEYBy9TIHxIRXwcGAMcUM2QCLAQ8EhHrASOB84AdiuwSpf1/BTwZEesC/w38vdh+PHBURPQHtgC+\nNH+wpMGSRkoaOfTS+2bt1ZqZmZmZWZuQtL2kMZJelnRSK7kNJc2QtOfsHrMjFninR0T/phvwVo38\nMcUo3cPAcsCqxfaZVNa+A1gDGBsR44rHl5f23xy4BCAi7gF6SVqEysLo/yvpGGDRiPjSAisRMTQi\nBkTEgMHfy63PZGZmZmZmbae4jOtsYAegH7CvpH4t5E4F7pgTx51fC7wo3c+tOl0iaSCwDbBJMVL3\nZKm9KRGRWyG53MGIU4BDge7AA5LWmNW2zMzMzMw6GnVSm97qsBHwckSMjYhpwBXALlVyR1MZOHp3\nTrwv82uB946kNSU1ALvNRjs9gQ8i4rOiAPtGC7kxwEqS+haP9y49dx+wP/ynYJwYER9LWjkino6I\nU4HHqIwCmpmZmZnZPKB8OVVxG9ws0gd4vfT4jWJbuY0+VOqVc+ZUv+bXZRJOAm4CJlC5Pq7HLLZz\nG3CEpOepFHEPVwtFxGRJRwK3SfqUSsHWZAhwoaTRwGfAgcX2H0saBDQCzwK3zmIfzczMzMw6noa2\nHauKiKHA0Nls5s/AiRHRKM2ZiVvmywIvIq4BrqmyfUiVbX1baWcqlXNmqz3XvGgcHhFrqPKVOZtK\nYUlEvA/sWmX/o1t+BV+mXstn4iz/3dVTeS27Ziq/8U/WSuXHXfJc3dnHX5yYanuHpcak8mPufzOV\nX+S4Lqn8Mt0eT+XjlSdS+Q2WPiaV/+czU1L5Q6Y+kso3vpR7P7uu1TuV3/233VP5605+IZXfd/T3\nU/nGZ3Ltq/sCqXynfrmf9cde/zCV7/edjVP5Z/YalsovvuOKqXyfbVZI5e875+VUvseR9f/8brDr\nKqm2tUzuc3bjE9bOtb9g7rOHt9/OxX//99qhkqUvPj6V/+zUy1L57t/fPJWPTz5J5Uf32iiV3/nQ\nL10m07onh6fik697rHaopNsRO6XyE0/NXcrT+8xDU/kNDlg5lR/6du7rtUH/PrVDZf+8MBXvvGLP\nVH6t3vX3Pz7KnWU3ZXpjKs+n76Xi6pv7P57NUW9SmcOjybLFtrIBwBVFcdcb2FHSjIi4flYPOl8W\neG3kMEkHAl2pXKt3Xhv3x8zMzMzM2s5jwKqSVqRS2O0D7FcORMR//jJaLO120+wUd+ACD4Bi6YO7\nqzy1dUTU9WeSiDgdOH2OdszMzMzMzKpr41M0a4mIGZJ+BNwOdAIujIhnJR1RPH/u3DiuCzygKOL6\nt3U/zMzMzMxs/hERtwC3NNtWtbCLiIPmxDHbbdkr6VVJTxcLkj8tqdqUouX8zCL7lKQnJG1axzEu\naFqLojheb0l9JT1TJTtA0pmz/orMzMzMzGyOaWho21s71d5H8AZFxERJq1NZ+O+GVrKTi4XLkfQt\n4A/AVq01HhF1X1EcESMpJk4xMzMzMzNrj9pv6flFiwAfzEpe0kBJNzU9IeksSQcV90dIGtBSI5JW\nkvSkpA3L7UgaIunCYv+xko4p7fM9SY8Wo4nnSepU3IZJeqYYjTyuyB4j6TlJoyVdUeX4/1lbY+gF\nXkXBzMzMzMxa195H8IYXyw6sBHy3Rra7pFFAN2Bp4Juzc+Bi1PAK4KCIeKpYpLxsDWAQsDAwRtI5\nwCpUFjnfLCKmS/orlUXOnwX6RMTaRduLFm2cBKwYEVNL2/7jC2trTL0lZuf1mJmZmZnNVxrmzLpx\n85v2PoI3qCiK1gHOktTaguWTI6J/RKwBbA/8XbO+WuASVE4H3T8inmohc3NETI2IicC7wFLA1sDX\ngceKYnNrKsXpWGAlSX+RtD3wcdHGaOAySd8DZsxiX83MzMzMzID2X+ABEBGvAO8Ada06GhEPUVko\ncAkqhVP5dXaro4mPgH8Dra26OrV0fyaV0VABFxeFZv+IWD0ihkTEB8B6wAjgCOCCYr9vU1kUfQMq\nRWF7H1E1MzMzM2sfPMlKVe23ZyWSlgRWBF6rM78GlbUm3iv26SdpgeI0yK3raGIasBtwgKT9aoVL\n7gb2LPqLpMUlrSCpN9AQEdcCJwMbSGoAlouI4cCJQE+gtRFKMzMzMzOzVrX3EaPhkmYCXYCTIuKd\nVrJN1+BBZSTtwIiYCbwu6SrgGWAc8GQ9B46ITyXtBNwpaRKfn1bZ2j7PSToZuKMo4KYDRwGTgYuK\nbQA/o1KAXiqpZ9HfMyPiw3r6ZmZmZmZmVo0iPHfHvKDxtiNzX6hu9ZyJWpIcZm4c93au/U71Xw7Z\n+Ts7pZp+Ytq3U/l1b/9hKt95551T+dcacvkVOt2eyk/Qhql814ZPU/lFnrwoldeGufmMGu+4NpWf\nOe69VL7z5uuk8peve0kqv81n96byM6NLKr/k9T9O5T/Y/Q+pfK/XLkvl6fW1VPyqCd9K5fd67Vep\nPIv2TMXVvXv94QUTWSDGt/Y3xy9rfPmtVL7TIYen8lN+fmoq3/3kI1L5sd86OZVf6c5TUvlnP211\nZaMvt7/Iy6n89S8ulcrvPfG0VF5rrZfLL7RYKj/p+NNT+R6/G5zKT7/6+lS+07K5/t+82q9T+YW7\n5sYgtup0VSofY15I5T/b/Ad1Z194f/lU269/PCWVH7T8J6l8z4l3pPIAWuaIeWL2ksY7ftSmhUzD\ndme1y/dpnjhF08zMzMzMzGpr76dofoGkXlSuc2tu64jI/ZnfzMzMzMzmXe14opO2NE8VeEUR17+t\n+2FmZmZmZtYetcuyV9IQSW9KGiXpBUnnlCYoqZYfJmlcKf/LOo6xs6STSsc7vrg/QtKAKvlbqi1G\nbmZmZmZm1l605xG80yPitKKwuxfYChjeSv6EiLhGUjfgOUl/j4hxLYUj4kbgxno7ExE71ps1MzMz\nM7O5zKdoVtWm70qx/EDT/T0lDasS60plcfIP6my2afrIT4t2Xy3WoUPSAEkjivsHSTqrlb41FCOD\nvy23I6mvpOclnS/pWUl3SOpeZFaWdJukxyXdV6zHh6S9JD0j6SlJ9xbb1pL0aDHqOFrSqlX6MFjS\nSEkjh97yXJ0v38zMzMzMOqr2XPYeV6xrNx54MSJG1cj/sci/AVwREe/OxrE7A5cBL0VEtXmhVwXO\njoi1gA+BPYrtQ4GjI+LrwPHAX4vtvwC+FRHrAU1z6B8BnBER/YEBRb+/ICKGRsSAiBgweMd+s/Fy\nzMzMzMysI2jPBd7pRfGzJLCQpH1q5E8o8l8Dtpa06Wwc+zzgmYj4XQvPjysVnI8DfSX1ADYFri4K\nzfOApYvMA8AwSYdRWeAc4CHgvyWdCKwQEZNno79mZmZmZh1LQ0Pb3tqptu5ZeXHCqitzR8R04DZg\ny7oajJgEjAA2LzbN4PPXWe/q3w8Cg4rr+aqZWro/k8qIXwPwYUT0L93WLPp0BHAysBzwuKReEfEP\nKqN5k4FbJOVWizYzMzMzM2umrQu8dyStWUykslu1gCQBmwGv1NOgpM7AxqX8q8DXi/t7VNunir8B\ntwBXFe3VFBEfA+Mk7dXUb0nrFfdXjohHIuIXwARgOUkrAWMj4kzgBmDdOvtmZmZmZmYewauqrWfR\nPAm4iUrRMxLoUXruOEnfA7oAo/n8eraW/FHSyVQmZbkbuK7Y/ivgb5J+Q2Vkry4R8b+SegKXSNq/\nzt32B84p+tEFuAJ4qujbqoCKvj0FnAh8X9J04G3g9601PPjfB9TbdQDO61Hr7fqiU5esdqlhy362\n7j9S+YwY+zzDex9bd36zy7+far/Tt9ZP5UdPz02gutZdg1N5dtkrFR//6SKpfGMsnMqvveF3Unn+\ncXYq/vFev0nlF1vhilS+8ZkXUvltPrs3lb9rwbpOJviPbvWeN1CI0fel8rt3ez53gAal4uN/0OJc\nVFXttNIlqXx8Y5lUnvcn1c6UbHPvrnVnb1v9slTbp63zh1T+Zxtfk8rH9X9P5bv97sRc+4/fk8r3\nvjvX//cP+0Eqv+Z+t6TyM54dn8rvM3CdVD46d6odKtGiX0vlp51zfirf/S+5z87pf/tLKv+7Pr9I\n5X/RkPvsX7hr7r+cm484OpVnw9zXd9JmR6Tyi8x8ue7sYrvXuqroi3re/Ggq//G3t0vlx/4j93sF\nYIP0HtaetGmBFxHXAF/6jRERQ4AhiXYOauW5+4DVqmwfBgwrHa9p+8DS/fJ6en2LfycCa5cyp5Xu\njwO2r3Ks3at07ZTiZs1kijszMzMzM/tcW4/gmZmZmZmZ5SXPSuko5qkCT9LZVK7HKzsjIi5qi/6Y\nmZmZmZm1J/NMgSdpCJXlCY5q675UI6kvcFNErF0jamZmZmZms6sdT3TSljrMuyIpd7W0mZmZmZnZ\nPKZdFniStpf0hKSnJN1deqqfpBGSxko6ppS/XtLjkp6VNLi0fZKkP0l6CthE0o6SXiiyZ0q6qcgt\nJOlCSY9KelLSLq307SBJNxT9eElSeSKWTpLOL/pxh6TuklaW9ERp/1WbHks6RdJzkkZLOu1LBzMz\nMzMzM0tod6doSloCOB/YMiLGSVq89PQawCBgYWCMpHOKhdAPiYj3JXUHHpN0bUS8BywEPBIRPy0W\nLX+p1O7lpXZ/DtwTEYdIWhR4VNJdEfFpC93ciMpMmp8Vx7uZyuyaqwL7RsRhkq4C9oiISyV9JKl/\nRIwCDgYuktSLytp/a0REFMdt/l4MBgYDbLb/iayxZf3TfZuZmZmZzdd8imZV7fFd+QZwb7HkABHx\nfum5myNiakRMBN4Fliq2H1OM0j0MLEel0AKYCVxb3F+DysLi44rH5QJvO+AkSaOorJXXDVi+lT7e\nGRHvRcRkKuvtbV5sH1cUcQCP8/nSChcABxenie4N/AP4CJhCZY2+3akUi18QEUMjYkBEDHBxZ2Zm\nZmZmtbS7EbwappbuzwQ6SxoIbANsEhGfSRpBpUADmBIRM+toV1RG28bU2Y9o4XHz/nUv7l8L/BK4\nB3i8GF1E0kbA1sCewI+Ab9Z5fDMzMzOzDk1qj2NVba89visPA1tKWhGg2Sma1fQEPiiKuzWojABW\nMwZYqZjtEiojaU1uB46WpOKY69c45raSFi9OCd0VeKC1cERMKY5xDnBRcYweQM+IuAU4DlivxjHN\nzMzMzMxa1e4KvIiYQOW6s+uK0y6vrLHLbVRG8p4HTqFSIFZrdzJwJHCbpMeBT6icJgnwG6ALMFrS\ns8Xj1jxKZVRuNHBtRIys+cLgMqARuKN4vDBwk6TRwP3AT+pow8zMzMzMrEXt8hTNiLgVuLXZtiHN\nHpfXm9uhhXZ6NNs0PCLWKEbqzgZGFrnJwOGJLr4REV+4KC4iXqUy8UrT4+azYm4OXNR0ymhEjKcy\nWUtdGhqU6F7elKkz5mr7mYtgu3bK/d2hYfFutUNlnXPf9l2S770WWziVjwmvpfIfd8p9rVZetJ6z\nlGddfDo9lZ86c5HcATrnVjhR9wVS+ZnRJZXvlvx2mzIll9f0xlz7M740P1OrunVbMJVX9vt/gdzP\nl7rkft6jofkZ8q1r6JboT5fc91r6c7Mx97XN5mc25r73OyXbj8h9rRqT38tMy32WxJTcZ1t8MimV\nJ/t7N3mqWPZ7vzGS/2VLvv+NjbmfLZKLT6X/GzMt+bsr+f08vbF77VBZp/rf/4bk17Zz8v89WVNm\nzN3/B7QpT7JSVbss8OaiwyQdCHQFngTO+yoOKumfwMr4GjszMzMzM5uLOlSBFxGnA6fXk5X0LeDU\nZpvHRcRuwLDkcXfL5M3MzMzMrAaP4FXVoQq8jIi4ncrEKGZmZmZmZvOEebLslTRE0vFt3Y8sSb+W\ntE2V7QMl3dQWfTIzMzMzs/lHhxzBk9SpzvXx5qiI+MVXfUwzMzMzs/nSXJ6EcF7V7kfwJG0v6QlJ\nT0m6u/RUP0kjJI2VdEwpf72kxyU9K2lwafskSX8qll7YRNKOkl4osmc2jaBJWkjShZIelfSkpF1a\n6VtfSfcV/XtC0qal506U9HTR71OKbcMk7Vl6XS9IegLYvYX2B0saKWnk8/deP4vvoJmZmZmZdRTt\negRP0hLA+cCWETGu2aLnawCDqKwnN0bSORExHTgkIt4vFiF/TNK1EfEesBDwSET8VFI34KVSu5eX\n2v05cE9EHCJpUeBRSXdFxKdVuvgusG1ETJG0KnA5MEDSDsAuwMbFAuxfWKy9OP75VGbVfJkW1vqL\niKHAUIDBFzySnL/YzMzMzMw6mvY+gvcN4N6IGAcQEe+Xnrs5IqZGxEQqhdZSxfZjilG6h4HlgFWL\n7TOpLE4OleJwbFO7VAqzJtsBJ0kaBYwAugHLt9C/LsD5kp4Grgb6Fdu3obLm3WdV+t10/HER8VJE\nBHBp62+DmZmZmZl9QUND297aqXY9glfD1NL9mUBnSQOpFFebFCNnI6gUaABT6rzuTsAeETGmjuxx\nwDvAelSK5eSSxmZmZmZmZnNO+y09Kx4GtpS0IkDzUx2r6Al8UBR3a1AZAaxmDLCSpL7F471Lz90O\nHC1JxTHXr3G88RHRCHwf6FRsvxM4WNKCLfT7BaCvpJWLx/vWeF1mZmZmZlbmEbyq2m/PgIiYAAwG\nritOu6x6rVrJbVRG8p4HTqFSIFZrdzJwJHCbpMeBT4CPiqd/Q+XUy9GSni0et+SvwIFF39YAPi3a\nvw24ERhZnOr5hSUdImJK8bpuLiZZebfG6zIzMzMzM6tJlUvAOh5JPSJiUjFSdzbwUkSc3tb9asmn\nx2yT+kIteOIeqfY/O/Xa2qGS7jv3qx0qmfH0m/X35ag/ptoe+faiqfwWV/wglX/+kEtS+S5zecre\nFRZ5NZV/7r2WLiGtbsMuN6byH/fYOJWffvCBqXzPQbn+d+qXy8er41P56zc8LZWfNr0xlY+1tkrl\nd5t+VSrf/bMXU/npPVZI5f94T+7n8Wf97knl45lnUvmZr0yoO9t5j2+l2v7sD5fXDpV0/9aqtUMl\n07Y9LJVf4IVbU3mtvG4qH++/kcpPXLzFSairev697qn8gl061Q6VXH7v2FT+tFVvSOXfWe3IVL57\npw9T+Z56OZWfrKVT+RlHH5fK9xi8ZSr/0VoHpPJnjZieyp+w9SepfOOQX6byH/zssrqz9702tXao\nZOsVZ6Ty//6kZyrf/6Hc1xagYefz54n1B+Lp37ZpIaN1Tm6X79O8fA3e7DpM0oFAV+BJ4Lw27o+Z\nmZmZmdWrHZ8m2ZY6bIFXjNbVNWIn6VvAqc02j4uI3eZ4x8zMzMzMzGZRhy3wMiLidiqTr8wSSa9S\nuc6vaRbPeyPimJb3MDMzMzOzVnkEryoXeF+dQcWafWZmZmZmZnOFC7w2ImkZ4JbSpnWAlSLitTbq\nkpmZmZmZzeNc4H11hktqOkXz4uIawP4Ako4Ctmpe3EkaTGU5Bc4ctAaHrN3nq+yvmZmZmVn75VM0\nq3KB99WpeoqmpM2Aw4DNmz8XEUOBoZBfJsHMzMzMzDoeF3htSNLSwN+AnSNiUlv3x8zMzMxsnjGX\n1x6eV3lcs41I6gJcDZwYEbmVh83MzMzMzKrwCN5Xp3wN3mgqI3cDgF9J+lWxfceIeKtNemdmZmZm\nZvM8RfjSrnnB/42dmPpCbbnsh6n2n39/yVR+hUVmpPKj3q2/+996+Ve1QyXq1y+Vf3qB76fy63a9\nLZWPsc+m8mNX/K9Uvne3N1L5RV6/IZV/r88+qXy3zrnvtX88uXAqv9nKvVL5x17P9Wen1VNxenV7\nOZWfMmPR3AGS/tnlu6n83o0XpfKPvL1WKj/g2sNS+QkHX5DKn3lnbqLh47fvXXd2ysxFUm2Pn9SY\nyi+/yNRU/twRE1L5owblvteendg9lV9t8VSc6Y259rs2fJrKd2mYnMov9n8/T+Un7HRaKv/kO7lT\nxfos3C2V75I8Fe2TaTNrh0omfDYtle/Xe6FUvu+Lf0jlZz71Uir/jwG5r9eOq+X+/9vrpcRn59LL\np9rm9bGpuNb+Rip/6Zj1UnmA76299Dxx7mO88qc2LWS08k/b5fvkUzTNzMzMzMzmEz5F08zMzMzM\n5j1eJqGq+fZdkbSXpOclDZc0UNJNs9jOzpJOKu4Pk7RnlcwASWcW9w+SdFZx/whJB5S2LzPrr8jM\nzMzMzKx18/MI3g+AwyLifkkDZ7WRiLgRuLFGZiQwssr2c0sPDwKeATyJipmZmZmZzRXz5QiepF9Q\nWTj8b5L+2Oy5hSRdKOlRSU9K2qXYfpykC4v760h6RtKC5RG5wjaSRkp6UdJORb7qCKGkIZKOL0b9\nBgCXSRol6duSri/ltpX0zzn+RpiZmZmZza8aGtr21k61357Nhoj4NZURtf0j4oRmT/8cuCciNgIG\nAX+UtBBwBrCKpN2Ai4DDI+KzKs33BTYCvg2cK6nmNFgRcU2pP/2BW4A1JC1RRA4GLky+TDMzMzMz\nsy+YLwu8GrYDTpI0ChgBdAOWj4hGKqdRXgL8KyIeaGH/qyKiMSJeAsYCa2Q7EJW1KS4Bvidp6nbe\nSwAAIABJREFUUWAT4NbmOUmDi9HCkbdd/vfsYczMzMzM5l9qaNtbOzU/X4PXEgF7RMSYKs+tCkwC\nWpsMpfl6G7O6/sZFwP8BU4CrI+JLC8tFxFBgKOTXwTMzMzMzs46n/Zaec8/twNGSBCBp/eLfnsCZ\nwJZAr2qzZRb2ktQgaWVgJaBaoVjNJ8B/VniOiLeoTLhyMpViz8zMzMzMbLZ0xBG83wB/BkZLagDG\nATsBpwNnR8SLkn4ADJd0b5X9/w08CiwCHBERU4pasZZhVK7ZmwxsEhGTgcuAJSLi+dl9UWZmZmZm\nHUo7Pk2yLc23BV5EDCzdH0HlejuKwurwKvlDSvdfB1YpHg4rbkTEQS0cq9x+OT+klLkWuLbZrpsD\n59fxcszMzMzMzGpSZb4P+6pJehz4FNg2IqbWyr/12YepL1TPk1o6w7S6T069IpVf7C+HpfJdNl2l\ndqipLxt9qf5uVc9O41L5xpuvSuWnffvIVL7bjPGpfHwyMZUf2/W7qfzSC76Uynef8FAqT5eaE8nO\nlmkX5lYQ6fqdjXMHyE5z3FDXiP3nui2Yiqvnkqn8zIX7pPJXNhycyu9z9w6pvDbIvf/vH312Kr/4\nkN1S+RcW/2Hd2ZXO3S/V9vvH5iY/7nVe8nNzn2+l8iywUC4/9dNUPPu9GWNG5dpfc0Cu/fG5zzat\nsG4q/8Ghv07lFzvjmFQ+3n8jlaf7wrUz5fbH5t6f6RvukcrP/NnJqfyo465M5Tfp1Pxv4jVM/iQV\n15Ir5trP6No9FR/1wSap/Hozcv9ne3+x5GcJ0GuB5ZK/7NpGvH52mxYyWu6odvk+zbcjeO1dRHy9\nrftgZmZmZjbPasdr0bUlvytmZmZmZmbzCY/gmZmZmZnZvKe+iQ47nPl2BE/SEpIekfSkpC0kvSqp\n9yy29WDx70BJN7WQuaVYtBxJk4p/l5F0TXG/v6QdZ+3VmJmZmZmZ1TbfFnjA1sDTEbF+RNw3Ow1F\nxKZ1ZHaMiA+bbXsrIppmO+kPuMAzMzMzM7O5Zp4q8JpGxor7e0oa1kKuP/A/wC6SRknq3uz570l6\ntHjuPEmdJK0g6SVJvYuFzO+TtF3z4wKLSLpZ0hhJ5xZr6VFthFBSX0nPSOoK/BrYuzjm3sWxlihy\nDZJebnpc2n+wpJGSRl56YdWXamZmZmbWMamhbW/t1Hx5DV5EjJL0C2BARPwIoGkxcklrAnsDm0XE\ndEl/BfaPiL9LOhU4h8pC5s9FxB1Vmt8I6Ae8BtwG7A5cU6M/06r0Zw1gfyqLrm8DPBURE5rtNxQY\nCvllEszMzMzMrOOZLwu8GrYGvg48VhR93YF3ASLiAkl7AUdQOaWymkcjYiyApMupLFbeaoHXgguB\nG6gUeIcAF81CG2ZmZmZmHVM7HkVrS/NagVcexZrV1ZUFXBwRP/vSE9KCwLLFwx5AtVUzm4+kzdLI\nWkS8LukdSd+kMiq4/6y0Y2ZmZmZm1mReK3vfkbRmcd3bbrPYxt3AnpKWBJC0uKQViudOBS4DfgGc\n38L+G0lasejD3sD9dR73E2DhZtsuAC4Fro6ImYnXYGZmZmZm9iXzWoF3EnAT8CAwflYaiIjngJOB\nOySNBu4Elpa0FbAhcGpEXAZMk3RwlSYeA84CngfGAf+s89DDgX5Nk6wU226kMlLo0zPNzMzMzDIa\nGtr21k7NU6doRsQ11Hm9W0QMA4aVHvct3b8SuLLKbt8oZXYv3e9R/DsC2LKF4/Wtkn8VWLu4/z6V\nArJsPSqTq7xQ6/XcM3ZyrcgX7LF47gzWO16alsrvv8Iiqfwbv7qr7uxjfz0h1fZu429P5V897ZFU\nvsvWf07llx17cyo/4/6nU/lp++xZO1TywgcrpvLrf5jr/0d/ui2VX/TMH6fynVfsmco/s9ewVH7t\nEf+dyo//wVmpvBpyi7D2vvYvqfxjb6+eyu9z9w6p/BVb35rK7/tGrj/denevHSp5eb8LU/m/HFn1\nI7uqP02dkWr79pdyn8sHJD83G4fXe4JIRcPmzX/FtO6Nwbm/LS531ZeubGjV/Ttfkcpvdvabqfyk\nm19O5bufs1kqv9AGS6Xy8eLoVP6lI65O5Vf9R7W/Obfsnp2vS+WXfuHkVH6V5M/u4+PeT+U36f7v\nVP6Tc/+Vyi9ydu77mZn1fz403pqbmuHD/rmf3caHcp8NYzbfK5UH2HTp9C7WjsxTBd78RNJJwA/x\ntXdmZmZmZnmeZKWqeb7Ak/RzoPmfJq6OiN+1RX/qFRGnAKe0dT/MzMzMzGz+Mc+XvRHxu4joT2W5\ngoeoTGSyh6THJR02p44jaVdJ/UqPR0gaMKfaNzMzMzMzm13z/AheyQXAWGDViGiUtASV9eW+QFLn\niMhdaFGxK5UJXp6bvW6amZmZmdls8ymaVc0X74qklamsJXdyRDQCRMSEiDi1eH6gpPsk3UhRoEm6\nvhjle1bS4FJbkyT9TtJTkh6WtJSkTYGdgT8Ws2CuXMT3kvSopBclbVHs37c41hPFbdNSH/4l6QZJ\nYyWdImn/Yv+nS22amZmZmZnNkvmiwAPWojIbZWMrmQ2AYyNiteLxIRHxdWAAcIykXsX2hYCHI2I9\n4F7gsIh4kMqSBidERP+IeKXIdo6IjYAfA78str0LbBsRG1BZJ+/MUh/WA44A1gS+D6xW7H8BcHTz\nDksaLGmkpJH3XH1p/e+GmZmZmdn8TmrbWzs1P52i+R+liVeWjIhlis2PRsS4UuwYSU2LpS8HrAq8\nB0yjciomwOPAtq0c6rpSrm9xvwtwlqT+wExgtVL+sYgYX/TxFeCOYvvTwKDmjUfEUGAowKXPjI9W\n+mFmZmZmZjbfjOA9B6wnVU7ELU28Ul506NOmO5IGAtsAmxQjdU8CTQvHTY+IpmJqJq0XwVOr5I4D\n3qEyWjcA6FolD9BYetxY4zhmZmZmZmY1zRcFXkS8DIwEfiupE4CkbkBLY6c9gQ8i4jNJa1Ba4LwV\nn1CZobOWnsD44nTR7wOd6tjHzMzMzMwy1NC2t3aq/fYs71CgF/CypJHAncB/tZC9Degs6Xkqa9E9\nXEf7VwAnSHqyxoQofwUOlPQUsAalkUMzMzMzM7O5SZ+fjWjt2TY/vjH1hbrz/32Uav+AS/um8hcf\nk4rz0kf1Lxk4o7G1uXK+bLUrv7QaRqvG7jsslX/to8mp/DbPn5zKN253QCr/3AfrpPLrvPGnVP6t\nVX6cyi/z9vmp/P++sUsqf+Rmub+RvD91xVT+/n/nvr47Df1eKq8Fcmdf/3mbM1L541/Ifb91+d5u\ntUNln36Yil++7J9T+X0/GJLKPzXjO6n8Cb8fXnf2juP+nWr7oBvWS+X/dmTue6HTmBGp/PAeh6fy\nmy3zSu1QyR2v9U3ld1r4ptqhsrEv5fJJow66NpXv/9Ava4dKJvdYO5VfMN5M5e+fsEkqv1n8I5c/\naqFU/sF/LFI7VBJTcp/lE488O5V/86w7aodKPp6aWzFry1731539bEiu792Pyf1ejJdfTuX/3vO4\nVB7goPX6tN8ZREriw8vbtJDRovu2y/dpfhrBMzMzMzMz69Bc4JmZmZmZmc0nPHOjmZmZmZnNc9SO\nJzppS1/5uyLpVUm9S48HSmrxRH1JB0k6q9m2EZLqv6irdp8kaaKkxYrHS0sKSZuXMhNKi6HPzrEm\nzW4bZmZmZmZm1bjsBYp17x4Gmq5g3pTK2nibAkhaHXgvIt5rmx6amZmZmZnVNs8XeJL2lfS0pGck\nnVraPknS6ZKelXS3pCWK7SMknSFpVLHPRsUuD1IUdMW/p/PFgu+BYv++ku6RNLpod/ka21eU9FDR\nx9+W+re0pHtL/dhiLr5NZmZmZmbzF6+DV1Vb9Wx4UdiMAi6oI793U77YZwCApGWAU4FvAv2BDSXt\nWuyzEDAyItYC/gWU5zteMCL6A0cCFxbbHuDzAm8j4J/AcsXjTakUgAB/AS6OiHWBy4Aza2w/Azgn\nItYBxpf6sB9we9GP9YBRzV+0pMGSRkoa+ebTt9fxNpmZmZmZWUfWVgXeoIjoXxQ3h9aRv7IpX+wz\nsti+ITAiIiZExAwqhdWWxXONwJXF/UuBzUvtXQ4QEfcCi0haFHgMWF/SQkCXiJgEjJW0CqURPCqj\nek2Ly1xSarel7Zs1Ha/Y3uQx4GBJQ4B1IuKT5i86IoZGxICIGNBnnW+1/g6ZmZmZmXUkHsGrqv32\nbM6LFu5D5TK8z4CXgEOAJ4rtDwM7AksCY+bQsZsOeC+VYvRNYJik3GrXZmZmZmZmzczrBd6jwFaS\nekvqBOxL5XRMqLy2PYv7+wH3l/bbG6CYJfOjiPio2P4g8GPgoeLxQ8CxwMPFRCxNmX2K+/sD99XY\n/kCz7RTHXgF4JyLOp3Ka6gapV25mZmZmZtbMPL0OXkSMl3QSMBwQcHNE3FA8/SmwkaSTgXcpirrC\nFElPAl2ojNg1eYBKQddU4D0BLMsXrxM8GrhI0gnABODgGtuPBf4h6UTghlI7A4ETJE0HJgEewTMz\nMzMzq5fU1j1ol/T5wNT8RdKkiOhRZfsI4PiIGPnlvdqvj6e/mPpCPbz0d1Ltb/TWran8uPV2TOVX\n3OxrdWdf/v3/pdpep1fu7NkZx52Uyr/yyxtqh0r6LvJmKr/w23em8he/v2vtUMnea01M5btNeCSV\nj9fGpfLq3j2Vf+WIq1L5PtuskMovsFkuHx99msqrS+5ECX1j41T+rZ77pfLdjsj97Hbrnft6LfjL\nQ2qHSi5fbEgqv+uJK6Xyt/7g4rqzC2+Sm8w4+7n5+ga5937NkzZM5TvtuH0qz2sv5fLL5d77ePTB\n2qESDdiodqjsvXdT8ZmrD0zl7+tzUCo/8K7k32lnzMjll6z/9yjA9KvvSOXjqNzvxtt77l87VDJz\n1P21QyU7rPhGKr/A2LtS+Xjv/VR+XL9f1g4VVvrkolTbwxv3qR0qGfT2/6byU9bfs3aome6d15s3\nKqdJ17VtIdNj93b5Ps3TI3hmZmZmZtZBNczrV5vNHe2mwJN0MJXTGcseiIijZqW9aqN3xfaBs9Ke\nmZmZmZlZe9cmZa+kIZKOb7b5l8A25eUQIuIoSQdJOqvZ/iMkDZiD/ZGkiZIWKx4vLSmKSViaMhMk\n9ZoDx5o0u22YmZmZmZlV43FNKmskUFkSYZNi06bAk8W/SFodeC8i3mubHpqZmZmZ2Rd4Hbyq5mrP\nyqNVkvaUNGwuHGNfSU9LekbSqeVjSzpd0rOS7pa0RLF9hKQzJI0q9mm6qvtBioKu+Pd0vljwPVDs\n31fSPZJGF+0uX2P7ipIeKvr421L/lpZ0b6kfuav7zczMzMzMmmnL0vO4orgZJWkUsEwr2b2bZQcA\nSFoGOBX4JtAf2FBS0xSDCwEjI2ItKmvjlac/WjAi+gNHAhcW2x7g8wJvI+CfwHLF402pFIAAfwEu\njoh1gcuAM2tsPwM4JyLWAcaX+rAfcHvRj/WAUc1ftKTBkkZKGnnRBVe28vaYmZmZmXUwHsGrqi17\ndnr5ejvgrVayVzbLNi1xsCEwIiImRMQMKoXVlsVzjUBTVXQpsHmpvcsBIuJeYBFJiwKPAetLWgjo\nEhGTgLGSVqE0gkdlVO8fxf1LSu22tH2zpuMV25s8BhwsaQiwTkR80vxFR8TQiBgQEQMOPnTv5k+b\nmZmZmZl9wdwu8MprU3SrZwdJR5VG61ob1ZudvjRfMyMi4jPgJSoLnz9RbH8Y2BFYEsgtttbysZsO\neC+VYvRNYJgkL3RuZmZmZmazZW4XeO9IWlNSA7BbPTtExNml0brWRvUAHgW2ktRbUidgXyqnY0Ll\ntTWt7LgfUF5hc2+AYpbMjyLio2L7g8CPgYeKxw9RWbrh4fh8RfgHgaYVKfcH7qux/YFm2ymOvQLw\nTkScD1wAbFDjtZqZmZmZWROfolnV3O7ZScBNVIqf8TWyaRExvjjGcOAp4PGIuKF4+lNgI0nPULlG\n79elXadIehI4F/hBafsDwEp8XuA9ASzL59ffARxN5dTK0cD3+Xztvpa2HwscJelpoE+pnYHAU0U/\n9qZyrZ6ZmZmZmdks0+cDU/MXSZOqLXYuaQRwfESM/PJe7Ve8dW7qCzX9untS7Xf5Xl0DrP8x7W9X\np/Kjz30ulX/2mrtT+X3WfjeVf2Pz76fy7173QO1QyWqL5ZY77DX+qlT+xcWOSOXveuGdVP5InZ/K\nx5u1Btu/aPq4j2qHSho/nFp39r5zXk61vc1Nu6fyMfbNVJ4uub+jqeeXPrZa9bPPDk/lT1nnjlT+\n5f0urB0q+fTmR1L51U7bK5W//tSxqXy/CY+n8quf/t1Uvvt/HZjKT7sw97Mejbnf0V03XzOVn3rX\nM6n8Agdsl8pPOffmVL7b4Tuk8kyYmIpf0qX+n5e97/xRqu0ua30tlZ/xYu73Vpdtc8v/fjY093t0\nwR9tn8pPPu/OVP6i3c9N5Vf62sKp/DevOjSV77La4qn8M1ucWTtUss7US2qHSq75JPe7aI/3/pTK\na9XcZ4OWOEipHdrK9NvatpDpsn27fJ/a79iidVgu7lrn4s5s7nBx17qOVNyZzY55vbizeV/ntu7A\n3FJt9K7YPvAr7oqZmZmZmdlXYr4t8MzMzMzMbD7Wjic6aUt+V5qR9Kqk3sX9n0t6VtLoYtmGjUu5\n3pKmSzqiyv5Pl5Z6OLP03PGSXii2P9a0NIKkEZJyJ9ebmZmZmZk14xG8FkjaBNgJ2CAiphZFX9dS\nZC8q6+TtS2U2zrJBEfGFiwOKQnBbYKOI+FjSItS5dISZmZmZmTWjdjnHSZvzCF7LlgYmRsRUgIiY\n2Gxdvn2BnwJ9JC1bR3v/DfwwIj4u2vs4Ii6e0502MzMzM7OOywVey+4AlpP0oqS/Stqq6QlJywFL\nR8SjwFUUC6eXDC+donlcMVq3cESk5veWNFjSSEkjh156X+0dzMzMzMysQ/Mpmi2IiEmSvg5sAQwC\nrpR0UkQMo1LQNc13fQVwIVCes/YLp2gWBd6s9GEoMBTy6+CZmZmZmc3XPMlKVX5XWhERMyNiRET8\nEvgRsEfx1L7AQZJeBW4E1pW0aivtfAxMkrTS3O6zmZmZmZm1D5K2lzRG0suSTqryvCSdWTw/WtIG\ns3tMF3gtkLR6s6KtP/CapNWAHhHRJyL6RkRf4A9Uir7W/AE4u2k0T1KPplk0zczMzMxs/iKpE3A2\nsAPQD9hXUr9msR2AVYvbYOCc2T2uT9FsWQ/gL5IWBWYAL1N5048C/tksey1wJfDr4vFwSTOL+6Mj\n4gAqX6wewGOSpgPT+eJpnWZmZmZmVq/2f4rmRsDLTfNwSLoC2AV4rpTZBfh7RATwsKRFJS0dEeNn\n9aCqtGXt3Ysb9kt9od647oFU+3122TSV73HfI6n8lJlda4cKK971w1Tb1651aiq/6bLdUvml//Vf\nqfzz35i7dfuaT/wslW/85n6pvNSYyv9tZD2TyH7u0I9OS+Xf3ewXqfzYD7uk8pu8e0Yqv/U5a6fy\nDd1yf0e7dfXLUvkPD/5zKj9xcs9U/i83PpvKv/TU26n8ET/cuHaoZOXFFkzln1vi63Vn9ey/Um1v\n8L1BqXzPB3KTZd324tRU/sClbk3lH4q9UvlNPj4vlf/NuJ1T+TVXXDyVf/Wtj1L5V179IJXfZ9vV\nUvmVF8t99ox6Z3Iq/51ed6fyQx5cN5Xf5Se5lZs+uvPhVH6rbjem8r8ZuVEqf+iWX0vllx7311Re\nq9e/XPEPLlg41fbfBn+Wyp8yYrlU/ti7f5zKA3T/3S3zxvoDMbxtCxkNavV9krQnsH1EHFo8/j6w\ncUT8qJS5CTglIu4vHt8NnBgRI2e1Wx7BMzMzMzOzeU608QhegzSYyhl+TYYWkyS2KRd4ZmZmZmZm\nSeUZ71vwJlAecl222JbNpLT7E1fNzMzMzMzmQY8Bq0paUVJXYB8qM/CX3QgcUMym+Q3go9m5/g46\neIEn6VVJvUuPBxbnwbaUP0jSWbNxvAdndV8zMzMzM/tcREOb3mr3L2ZQWWrtduB54KqIeFbSEZKO\nKGK3AGOpTOh4PnDk7L4vPkXzKxQRuZlMzMzMzMxsnhURt1Ap4srbzi3dDyqz9M8xHXoEb3ZI+o6k\nRyQ9KekuSUsV24dIulDSCEljJR1T2mdS8e/A4vlrJL0g6TJJX5qFR9JgSSMljbxyQm72LzMzMzOz\n+VnQqU1v7ZVH8L64Zl0P4IU697sf+EZEhKRDgf8Cflo8twYwCFgYGCPpnIiY3mz/9YG1gLeAB4DN\nijb/o3zhZnaZBDMzMzMz63hc4MGgiJgIlZE14Pg691sWuFLS0kBXYFzpuZsjYiowVdK7wFLAG832\nfzQi3iiOOwroS7MCz8zMzMzMLMOnaM66vwBnRcQ6wOFAefXs8uq0M6leSNeTMTMzMzOzKtr7JCtt\npf32rP3ryedrVBzYlh0xMzMzMzMDjxpldebzkbchwNWSPgDuAVZsq06ZmZmZmXU04bGqqlSZmdPq\nIel04KWI+OtXfexPpj+f+kI90mfXVPtbvX1JKv/wCgek8gMOWKnu7IjDcn3ZYflRqfy0M3Jfvlt3\nPrd2qGS7Fd5K5bs3TEzlL3xq9VR+n3VyM7AuOH1c7VBJPPNYLj9zRir/0pHXp/Ir7LpKKr/Avlum\n8tNvejiVp0tulq0u390+lX9job1T+SXP3D+Vb5ya+3p1+8EOqfyd65+Zym9x+Mqp/PX7X1h3Ntba\nKtX2XjNzn1UjV859bm4weI1UfoETcksnxVtjUnn1yfUnRo5I5Vn6a7l8p+TfqPv0S8UfXOHwVH7T\nh36cyjNzZu1MiZbN9b/xhktT+UnfPjGVv7fXd1J5PZVbCnizPh+l8otOy/1foPHeO1L5B/ufWnd2\ns3dOT7X9ryVy3ztbjsp9rRq+mftcBmDBXb80u3t7NL3x0TYtZLo0bNQu3yeP4NVJ0q1UJlMZ0sZd\nMTMzMzMzq8oFXhWSDgaObbb5gYiYo4sQmpmZmZnZrGlsxxOdtCUXeFVExEXARW3dDzMzMzMzs4wO\nXfZKGiLp+GbbXpXUu5V9Js3G8X4taZtZ3d/MzMzMzCqCTm16a688gvcViohftHUfzMzMzMxs/tUh\nRvDKo26S9pQ0bA602UPS3ZKekPS0pF2K7X0lPS/pfEnPSrpDUvfiuWGS9izuvyrpV6X9vzQ9maTB\nkkZKGnnRBVfNbpfNzMzMzGw+5xE8OE7S90qPl6lzvynAbhHxcXFK58OSbiyeWxXYNyIOk3QVsAdQ\nbb7iiRGxgaQjgeOBQ8tPRsRQYCjkl0kwMzMzM5ufhSdZqcoFHpweEac1PZD0ap37Cfi9pC2BRqAP\nsFTx3LiIaFqQ5XGgbwttXFfK7J7os5mZmZmZ2Zd0lAKvPPrVbQ61uT+wBPD1iJheFIZNbU8t5WYC\n3VtoY2op01G+FmZmZmZmNpd0lKLiHUlrAmOA3YBP5kCbPYF3i+JuELDCHGjTzMzMzMzqEB1jOpG0\njlLgnQTcBEwARgI9ZqURSZ35fNTtMuD/JD1dtPnCHOhni0avslsqv/n4K1L5qzvtk8rv++ZxqbwW\nX7bu7A48BJ271t94I1zw1Jp1xw899sj62wa2bXw7lb/vzeVS+QefS7xWYMi2z6Xy705fL5Wf0XmB\nVH744puk8l8/eodUfrVrB6fyWmb1VL7xkXtS+dPW+UMqP2XqjFT+xD8cm8qPP2mvVL7zsRem8re/\nNDmVH37DuFT+jLduTeW7T34sld9g0KD6w+s3sNLIi+uOX93p+6m+7PvvY1J5lls7FY+Jr6Xy/2rI\n9X+rd3OTff1y4v6p/I4r1P97AuDq+3Pfa6+/8n4qf8Wr56fyH0zLffZf/1zuv2AHLvvvVP7Pi/0s\nld90tZ1S+Z3eOyOVn9HppVR+h+MnpPL/76ffTOXX/PtptUMlnTdQ3dlHlv4JL75b/6pa2/XK/Z4Y\n/Y0/pfKfrjkglQfY7LVd0/tY+9EhCryIuAa4psr2IVW29W2lqbWAV4rcRKCl/9n+57dy+fq+iDio\n2nEiYiQwsJXjdiyZ4o5ccWdm1pJMcWdm1pJMcWezp9EjeFX5XamTpCOAy4GT27ovZmZmZmZm1XSI\nEbwsSb2Au6s8tUVEvPdV98fMzMzMzKwec3UEr1jMu3fp8UBJN7WSP0jSWcX9BkkXS7pQUtUTnyUt\nWqwhV09fZkoaVSw+/pSkn0qq+voj4r2I6F/l9l7z1yFpZ0knFfd3ldSv2etZpvR4hKT8idBmZmZm\nZvYFEQ1temuv2mXPioLuXKALcGhEtLTI96JAvTNmTC6KtLWAbYEdgF/Obl8j4saIOKV4uCvQr/T0\nQdS/cLqZmZmZmdlsaZcFHnAm0As4ICIaJR0i6c9NT0o6TNLpwCnAysXI3B+L506Q9Jik0ZJ+Va3x\niHgXGAz8SBXdJF0k6WlJTxbLHtDS9rKmUUdJmwI7A38s+nMiMAC4rHjcvdl+20l6SNITkq6WNEsz\ne5qZmZmZdURBpza9tVdfxTV4wyXNLO73oPZyAvsBzwMDI6Jp3tirgJ9LOiEipgMHA4dTWc9u7Yjo\nD5WiCVgV2AgQcKOkLSPi/7N35/F2Tff/x1/vRCYZjDEPITVPQczzUFqiaGOuCq3QFqUTxQ9VfKn6\nqlI0fCs1xUxJzSSmqCSIxBQx1kxIIonIdD+/P86+ddyce+/5ROJO7+fjcR45e+33Xnufc+89N+uu\ntdd6tO5JIuJ1Se2BZYAflopiA0lrA/dLWhP4eT3l84iIEZLuBIYWs3Yi6bvAr4tZMqkdaVoMWz0V\n2DUipheNwV8CZ5bXKWkgpYYov1lyWfbutngjb52ZmZmZmbVl30QP3k6197ABP6ki/wylRcM3ry2I\niGnAw0C/oqHVISLGVTh2t+LxbFHP2pQafI3ZFri2ONfLwFvAmg2Uf11bUhrK+YSkMcBhVFgoPSIG\nRUTfiOjrxp2ZmZmZmTWmOc6i+TJwGnCTpN0j4oWi/Erg5GL/VfUcK+B/IuJvjZ1E0urX98/rAAAg\nAElEQVTAXOCjr3/JaQIeiIiDmuDcZmZmZmYtXnOe6KQpNct3JSJGAD8FhkpapSh7CliZ0hDOIUV0\nKtC97ND7gCNq72eTtKKkZerWL6knpUlcLikmcHkMOKTYtyawCjC+gfL61L2eutu1/g1sI+lbRd1d\n6xv6aWZmZmZmVq3m2IMHQETcVdyrdq+k2vXnbgL6RMSkIvOJpCckPQ/cExG/kbQO8GRxv9s0SvfX\nfQR0KYZDdgDmANcA/1uc7lLgMknjin0DImKmpPrK67vsG4ArJB0H9AcGA5dLmgFsVfbaPpY0ABgi\nqVNRfCrwytd608zMzMzM2ohonn1VTU71r0DQ/BRrz10YEZUWIW/VYuLVqS/UQ+uenap/l6ePS+WH\nrPKXVH7vY1euOvvc725N1b1qj3ob3BUtec6BqfzwI69J5TdaJjer0lKdXk3lLx2xRCp/7DYfp/KL\nzJ2cysd/Xmg8VGbuk2NS+Sd/NyqV3+I366fy7bp1TOXbb5Grn5qaVDzefS+V/2iHMxsPlVny8qNS\n+UVW7ZHK1+yTq/+lDQek8mv9eL1U/tOjGx2x/19vrLttqu4tHz02lc9+bh5469apvHbcNZVn7uxc\nvn2HXH567rNEPZZuPFSua+6z8P1ZuWVoX18n9/5v/Vxu5SV16prKs0jusyqeeSxX/8rV/54GuG/9\nC1P5GSMfT+U3XKbSAKj69V50nvn0GjTzostT+XGH/qPqbN9FH0jV/a+Pd0jl95h2WSpP506NZ+rQ\nGr/J/eeqiUye9XqTNmQW77h6s3yfWkSzt1jQ/BVKa9m1ucadmZmZmZlZNZpkiKakw4Ff1Cl+IiJ+\nXikfEZNZMLNXmpmZmZlZK1DjSVYqapIGXkRcRf0zYZqZmZmZmdl8WKjNXklnSPp1nbI3i8lT6jtm\nWtnzPSS9ImmeNeLKMgMkrVDFtQyW9Iak54o6r5a0UrWvpUJ9/30dkkYU//aSdHBZpo+kPepc6yXz\ne04zMzMzMysJ2jfpo7lqtv2aknYB/gJ8NyLeaiA6AGi0gVf4TURsBKxFaTH0hyXl7lquICJq78Tu\nRWkZh1p9gD3mOcDMzMzMzGwhWCANvDq9bv0lDf6a9W0PXAH0i4jXJHUvet86FPt7FNv7AX2B6ySN\nkdRF0qaSHpH0tKT7JC1ft/4ouRD4APhuUedBksZJel7SeWXXUrG8ntd/LrBdcS0nAmcCBxTbB9Q5\npqekWyWNKh7bVKh3oKTRkkYPunpY/o00MzMzM7M25Zu4B+8EST8s226st60TcAewY0S8DBARUyUN\nB/Ys9h0I3BYRN0v6OfDriBhdNAAvBvYu1po7ADgbOKKecz0DrC1pFHAesCkwCbhf0j7AyErlEXFH\nPfWdVFxLPwBJHwJ9I+KYYntAWfYiSks+PF4s5n4fsE55ZRExCBgE+WUSzMzMzMxas/AkKxV9Ew28\nCyPiT7Ubkt5sJD8bGAH8mK/OtHkl8FtKDbzDgSMrHLsWsD7wQLEYeXvg/QbOVbt2xWbA8Ij4uLjG\n64DtgainvL4GXsauwLpli6b3kNQtIqY1cIyZmZmZmVm9FlQDr7x3qfPXrKsG2B94SNLJEXEOQEQ8\nUUxisiPQPiKer3CsgBciYqsqz7Ux8BBfNvS+Se2ALSPiiyY4t5mZmZlZixbNdzqRJrWg3pUPJa0j\nqR2w79etLCI+pzQc8xBJPy7bdTVwPV9dYmEq0L14Ph7oKWkrAEkdJK1Xt36VHAcsD9xLaSjmDpKW\nltQeOAh4pIHy+pRfS6XtcvcDx5ZdU58G6jUzMzMzM2vUgmrgnQQMpTS0sqEhkVWLiE+B7wCnSvpe\nUXwdsAQwpCw6GLhc0hhKQzL7A+dJeg4YA2xdlj2/KH+F0rDMnSJiVkS8X7yGYcBzwNMR8c/6yhu4\n7LHA3GIphhOK49atNMkKcBzQV9JYSS8CR1f/7piZmZmZmc1rgQzRjIhbgFsqlJ9RoaxXI3V1K3v+\nNrBa2e5tgVsiYnJZ5lbg1rLMGEr3ydWtd0Aj5x3CVxuOjZX3qnvNETEb2LlOdLM624OL7ESgbqOv\n/utbarXGQ2V2vnqXVF4rrZvKH3DDlqk87aofBXvF7ZVG39bv/CN6pfKd9toolb/niTdT+WV3WyuV\nX6HL1FR+uaVyyzcuMuulVD4619fpXI9Fc/mYPjuV3/zYdRoPldGiHVL59kcclcrHHVen8tTUpOKz\n9j4ulb/8/o9T+dMP3D2Vrxn2eCrffvzwVH6dk+p+RDZs7ofTU/l7X5lZdfaggWun6mbl9VPxA2/d\nuvFQmRt+MCKV33f28al852kvpvJTu26ayndnVCpf8/STqXy7zef5Vd+g5T7P3T6/9Em53xW8+0Yu\nv84WqfjMWCyV7zA997Py0RL9U/mdTrk/lX9nmdzvillzc5+dM1g2le+0xlKp/ISJ1b+fm87O/T9m\ng97fTeX5NPd7lM9n5PItiCdZqeybmGRlgZB0MaUlDbyunJmZmZmZWQVN0sCTtBSlyU3q2iUiPql0\nTEQcW6nczMzMzMzMSpqkgVc04jypiJmZmZmZzZca2jf1JTRLbXLgqqQ3JY0rJj8ZI6nijRHFsgy5\ngdSV6zlT0q7F8+MlLVq27+SvW7+ZmZmZmRm0oHvwFoKdiolOFrqIOK1s83jgWuDzYvtk4Jxv4jrM\nzMzMzFoLT7JSmd+V+SCpt6R7JT0t6TFJa0taTNJbxVqASOoq6e1iLb7BkvoXa++tAAyTNEzSuUCX\nohfxugrnGShptKTRgwbd+Q2/SjMzMzMza2nacg/eMElzgZkRkZurGAYBR0fEBElbAJdGxM7FWnw7\nUFr/rh9wX0TMlkpLBETEXyT9krLeQ0nHRETF+xEjYlBxLmrisZiP12hmZmZmZm1IW27gzdcQTUnd\nKC2efnNtww3oVPx7I6W17YYBBwKXLoDrNDMzMzOzOsKDEStqyw28+dUOmFxPr9udwDmSlgQ2BR7+\nRq/MzMzMzMzaNDd7kyLiM+ANSfsBqGSjYt80YBRwETA0IuZWqGIq0L1se7akDgv5ss3MzMzMWpWI\ndk36aK4U0fZu7ZL0JtC3sSGaknoBE4APy4pPAEYDlwHLAx2AGyLizOKY/sDNwI4R8UhRNphSg+8W\nSccCxwDvRcROks4Dvgc8ExGH1Hct8dHfc1+oRTo1nik3d3Yu3z7ZJn37tVRc625edXZmu6VTdXd4\n5NrctWy4SS6/+HKpfEz7JJWnpiYVv3PSbqn8ty+t99uwokX/8LNUPl56NpVnmWVy+Q8+SMW/uOPp\nVL7z2Sem8nNrcj+L7V/KdfxP7H14Kr/058mBBdM+TcWH6Yep/E5d707lmfBiLr/qalVHtfQqqapj\ncu57jXa59Zq+6LF+Kn97h/1T+YPe+1UqP/mUeeYCa9Div+uXyn+6yoGp/FKzRqbyN7+3XSq/X6/R\nqfzcjoun8u1efzKVn3HFg6l8l5N+lMrHi2NS+XYbb5PKX/vaZqn8d9eYk8ov+Z8bUnm6L5HLR+53\n7ytdDq06O+qdyam6f7hG8vdoTe69BKDL99R4qOm9O/2zJm3IrNi1R7N8n9rkEM2I6FVl7k1KDbhK\nvlPPMbcAqlM2oOz5xcDFZdsnArn/MbZymcadmZmZWXOSadyZLQxtsoFnZmZmZmYtWw25kRFthRt4\ngKQNgGvqFM/P8glmZmZmZmZNpk028CSdARwJfFwU3VvfWnSShgO/jojcYPyv1tEX+FFEHCdpR2BW\nRIwo9u0DvBIRyRtLzMzMzMzaruY80UlTapMNvMKFEfGnb+JEReOwtoG4IzANGFFs7wMMBdzAMzMz\nMzOzr6VVN3slTSt73r+YzXJB1Nte0vmSRkkaK+moovwGSXuW5QYX591R0tBiVs6jgRMkjZG0A6UZ\nNM8vtnsviOszMzMzM7O2qVU38BpR28gaI2n35LE/BqZExGbAZsCRklYDbgT2B5DUEdgF+FftQcWs\nnJdT6j3sUyyjcCfwm2L7K2sJSBooabSk0YOufmQ+X6aZmZmZWesTtGvSR3PlIZrzZzdgw2LNO4DF\ngDWAe4CLJHWitIzCoxExQ5q/JTIiYhAwCOZjHTwzMzMzM2tzWnsDr7xR1HkB1ivg2Ii4b54dpUlZ\ndgcOAJKrbpqZmZmZWTVqwv0flTTfvsUF40NJ60hqB+y7AOu9D/ippA4AktaU1LXYdyNwOLAdcG+F\nY6cC3RvYNjMzMzMzmy+tvYF3EqUZKkcA73+Nev4l6Z3icTNwJaVZL5+R9DzwN77sDb0f2AF4MCJm\nVajrLmDf4t6/7Sj18v1G0rOeZMXMzMzMzL4Ohbs2W4RH352c+kJtN21Qqv5Hug5M5XfoeFsqP/f+\nYVVnL1v9zFTdP339tFS+5uPPU/kPB16dyq/40PGp/Jz/TEnlO+y+WSr/UKcfp/K7fPKXVH7Ww2NT\n+RnH5m59XWzqE6n8Bz+5JJVf/vpTUvl48elUnpqaVFwbbJHKD5+4bSq/Q/ubUvl3Dr88lV/mX7nP\nno5jh6byM+9+NpV/5ojqf363mp37WX+k3aGp/A6d7kjl6dApl58xNRUfssIFqfzBcy9N5d/pd2Iq\nv8Kpu6TyU678dyr/xSW3p/LLTbwulWd2pb/p1m/sXlek8hved2yu/t0vTuWXffrxXP7jIan80DkH\npfL9Pr4wlZ82+MlUfvKf7krlV3rnr1VntWbu9/T4KVum8qt2fzmVf2Xymqk8wIZLdZ2/CSS+Ya99\n9kWTNmR69+jcLN+n1t6DZ2ZmZmZm1ma09klWqibpdmC1OsUnVppIxczMzMzMmpYnWanMDbxCRCzI\nSVjMzMzMzMy+cS1uiKakNyU9VqdsTDHZCZIWlXSdpHGSnpf0uKRuxb5TJL0gaWxxTOpmF0mDy9a+\nMzMzMzMza1Zaag9ed0krR8Tbktaps+8XwIcRsQGApLWA2ZK2AvoBm0TETElLAx2/2cs2MzMzM7MF\nocYjNCtqcT14hZsoLSQOcBBQPpXT8sC7tRsRMT4iZhblE4vnRMTEiHivvhNIOlfSi0VvX/m0f9tL\nGiHp9drePEndJD0k6Zmi53DvoryXpJeLHsWXJN0iadFi36aSHpH0tKT7JC1f4RoGShotafSd1w6e\nj7fJzMzMzMzakpbawLsV+H7xfC9Ka8vV+jtwoqQnJZ0laY2i/H5gZUmvSLpU0g71VS5pKUoLo68X\nERsCZ5XtXh7YllJv4LlF2RfAvhGxCbATcIGk2mlT1wIujYh1gM+AnxULpF8M9I+ITYtrPrvudUTE\noIjoGxF9v/fDAVW8LWZmZmZm1pa11CGanwCTJB0IvAT8d2GziBgjaXVgN2BXYJSkrSLiJUmbAttR\naoTdKOmkiBhcof4plBpt/ydpKKXF0mvdERE1wIuSli3KBJwjaXugBlgRqN33dkTULuR1LXAccC+w\nPvBA0Q5sz9dbiN3MzMzMrE3xLJqVtdQGHsCNwF+BAXV3RMQ04DbgNkk1wB7ASxExFxgODJc0DjgM\nGFzh+DmSNgd2AfoDxwA7F7tnlkVre+kOAXoCm0bEbElvAp1rq6tbfXHcCxGxVfUv18zMzMzMrGEt\nuYF3O6XhkvcBK9QWStoGeDEiJknqCKxLqUG3FlATEROKaB/grUoVF7NuLhoRd0t6Ani9kWtZDPio\naNztBKxatm+VogfxSeBg4HFgPNCztrwYsrlmRLyQewvMzMzMzNom9+BV1mIbeBExFTgP4Mvb3QDo\nDVxW3APXDvgXpXv2NgEulrQ4MAd4FRhYT/XdgX9K6kypt+2XjVzOdcBdRa/gaODlsn3jgZ9L+jvw\nInBZRMwqJmj5i6TFKH0d/gy4gWdmZmZmZvNN4ZbvQiOpFzA0Itb/unXF+D+mvlBabtXGQ+X1fz4l\nladT11z+/YqdpQvExN6Hp/JLv3ZVKh9Tcu/N9M0GpPLdJj+Vyqv70qn8J9oolV/igbMaD5Vp993c\n0pDx0RupPB27pOLq0LnxUJnX+/0hlV/6oVtS+YjcXFY9Jj6Yyr+/+IGp/AoMT+WZMzsVv2viTql8\nvx53p/LMmJrLfz696qi+tXGq6vT3cvJzc2r3zVL5uUcdmcovceVpqfz17X+Wyh/08Smp/Htd9knl\nV+z071T+4fdz7+fOKz6Tyscnb6fyWS9/+9zGQ2XWefycVL5m5KOpfLvNt0/lh0/eufFQmTWWyH12\nrvD8eam8+myTytO++j6R1z7PvTevTfq88VCZ7VbMfa91mZX8rAJYdB81Hmp6L3w6vUkbMust2bVZ\nvk8ttgfPzMzMzMzarrnup6qozTfwJN0OrFan+MSIuO/r1h0Rb1KaLdPMzMzMzGyha/MNvIjYt6mv\nwczMzMzMcjzJSmUtaqFzSWdICknfKis7vijrW2wfIWmcpLGSnpe0d1G+paSnJI2R9JKkM5Ln3rFY\nE8/MzMzMzKxZaok9eOOAA4HamSD2o5h9UtJKwCnAJhExpVjuoGeR+wewf0Q8J6k9sNY3e9lmZmZm\nZmYLV5P34EmaVva8v6TBjRxyB1DbK9cbmAJMLPYtA0wFpkFpwfOIeKNs3/tF+dyIeLGBa9qh6Okb\nI+lZSd2LXd0k3SLpZUnXFUsxIOk0SaOKHsNBZeXDJV1U1PN8sXg6krpK+rukkUX9e9dzHQMljZY0\netCNuZkWzczMzMxas5po2kdz1eQNvPnwGfC2pPUp9eTdWLbvOeBD4A1JV0naq2zfhcB4SbdLOqpY\n464+vwZ+HhF9gO2AGUX5xsDxlBZPXx2onWP3kojYrFgOoQvQr6yuRYt6fgb8vSg7BXg4IjYHdgLO\nlzTP/NkRMSgi+kZE34EHbNHgm2JmZmZmZtYSG3gAN1Bq3O0D3F5bGBFzge8A/YFXgAtr77WLiDOB\nvsD9wMHAvQ3U/wTwv5KOAxaPiDlF+ciIeCciaoAxQK+ifKfi/r5xwM7AemV1DSnO/yjQo1hofTfg\nJEljgOFAZ2CV/NtgZmZmZtY21UQ06aO5ag4NvPJ3p9oViocChwL/iYjPvlJZyciI+B9KjcAflO17\nLSIuA3YBNpK0VMULijgX+Aml3rgnJK1d7JpZFpsLLFL0BF4K9I+IDYAr6ryOul/9AAT8ICL6FI9V\nIuKlKl+7mZmZmZlZRc2hgfehpHUktQOqWrIgIj4HTgTOLi+XtIKkTcqK+gBvFfv2rL03DliDUgNt\ncqX6JfWOiHERcR4wCli7Uq5Q25ibWEzq0r/O/gOKOrcFpkTEFOA+4Niye/U2buj1mpmZmZmZVaM5\nzKJ5EqUeuY+B0UC3ag6KiBsqFHcA/iRpBeCLos6ji32HUhqy+TkwBzikGNJZyfGSdgJqKM3QeQ+w\nVT3XMVnSFcDzwAeUGoTlvpD0bHFtRxRlfwD+DIwtGrZv8NX79ubx+9f3amj3PE6b8OdU/gz9IpX/\n/QYPpfKz7h2dyn9w1JCqsytcOyBV94yXPknlFz3rmFS+yzV/SOVnTZzReKhMx98en8qPeL1LKt9v\njd6p/PRf/zGVn3pO9V9bgGWn3pnKf37edan86g+cm8p/euSPU/ma2TWp/MT/uyWVnz0n9/WNCWNS\n+ce/V+mjtn79njkplY+R/07lZz7xn1T+/O3+t+rs/5t8Taru0yceksr/fsNhqXz3eX6dNOJ3Df4a\nmcc7/U5M5Q/6+JRUfkjPsxsPlTnwkbGp/HsXPJrKb3/7X1L5eO2ZVJ7FezaeKfP4JrnPnm3vPDCV\nH7flyan8zIdz32+bvnVxKv9hu20aD5XZ6vqjGw+Vee32Can8B7f+NpXf+uXTq86uVpNbVWvWprnv\nhU5Dc9/LQ9bM/SwCHLRu+pAm0ZwnOmlKTd7Ai4hbgKr+RxMRZ9RTvmPZ5s71ZKr+ZIyIYysUDy8e\ntZljyp6fCpxaT3XXRsRX/kceETOAo6q9nrYm07gzMzMzM7MvNXkDz8zMzMzMLKs5T3TSlJrDPXjz\nkHRK2Tp0tY/c2JDqznN4hfP8tYH8m5Ieq1M2RtLzxfNFi/XxxhVliwAvS7pQ0vFlx9wn6cqy7Qsk\n/XJBvz4zMzMzM2tbmmUPXkScTZ0JVBbSea4Crkoe1l3SyhHxtqR16uz7BfBhMZsmktYCZlNadmF/\n4M/FPXdLAz3KjtsaOGF+XoOZmZmZmVmtZtmD18zdRDEzJnAQxTp3heWBd2s3ImJ8RMwERvDlJC3r\nUZqQZaqkJSR1AtYBkndzm5mZmZm1XV4HrzI38PJuBb5fPN8LuKts39+BEyU9KeksSWsARMR7wBxJ\nq1DqrXsSeIpSo68vMC4iZn1TL8DMzMzMzFonN/DyPgEmSToQeAn4vHZHRIwBVgfOB5YERpUN4xxB\nqXFX28B7smz7iUonkjRQ0mhJo5++56aF9HLMzMzMzKy1aJb34LUANwJ/BQbU3RER04DbgNsk1QB7\nUGoIPkGpMbcBpSGabwO/Aj6jnvsAI2IQMAjgjHtear79wGZmZmZm3zCvg1eZe/Dmz+3AH4H7ygsl\nbSNpieJ5R2Bd4K1i9whKi5l/GhFzI+JTYHFKwzRHfFMXbmZmZmZmrZd78OZDREwFzgOQVL6rN3CZ\nSoXtgH9RumcPYByl2TOvL8uPA7pFxMSFfc1mZmZmZq1Jc57opCm5gZcQEb0qlL0JrF88vxq4up5j\n5/LVpRGIiAEL+hrNzMzMzKztcgOvhdhxg+VTebXbOJXfo91KqTydl07FOx7ar+rshE+np+peZc+d\nUvlF9u6Yyr81d/dUfpV9pqby7Sd9kMq/Nz33td1ruYdT+Wkd90zlO633bCrfXrNTefVcLZXvcui2\nqfwL03dI5dc5+O5Unlm51/v4J11S+TWWyP28aJ2+qfw2f3238VC51yek4uq7eSrfef31Uvl1ZixZ\nfbjLcqm691g197mpLrnPzZqnn0zlJ23zq1R+hVNzg0fe67JPKn/gI2NT+Rt2uKvxUJmDnj8slWf8\n8Fx+2ZVz+am593PboQen8tPW3S+VX/f0N1P5p+bWpPIsm/v+32eJt1P5jt/dNJXvfdCuqfxyy7yT\nysfy+1ed1bDcxHjrdHs0la/p1jWV77fGpFS+JPd5aM2LG3hmZmZmZtbieJKVyjzJipmZmZmZWSvh\nHryFQNKfgf2AlSMiOebBzMzMzMwa40lWKnMP3gImqR2wL6V17ire3CPJDWszMzMzM1vg3MADJE2T\ndKGkFyQ9JKlnUd5b0r2Snpb0mKS1i/LBki6XNFrSK5LKZxDZEXgBuAw4qOwcZ0i6RtITwDWS2kv6\nk6TnJY2VdOw394rNzMzMzKw1cgOvpCswOiLWAx4BTi/KBwHHRsSmwK+BS8uO6QVsDuwJXC6pc1F+\nEDCE0mLoe0rqUHbMusCuEXEQMLCoo09EbAhcV/eiJA0sGpGj77pu8AJ4mWZmZmZmrUNNRJM+misP\nFSypAW4snl8L3CapG7A1cHPZYuadyo65qbi/boKk14G1Jb0I7AH8MiKmSnoK2B0YWhxzZ0TMKJ7v\nClweEXMAIuLTuhcVEYMoNTIZ/s7k5vtdZGZmZmZmzYIbeJUFpd7NyRHRp4FM3e3dgcWBcUWjcFFg\nBl828HILVpmZmZmZWUVeJqEyD9EsaQf0L54fDDweEZ8Bb0jaD0AlG5Uds5+kdpJ6A6sD4ykNz/xJ\nRPSKiF7AasC3JS1a4ZwPAEfVTrgiKbEar5mZmZmZ2bzcwCuZDmwu6XlgZ+DMovwQ4MeSnqM0ccre\nZcf8BxgJ3AMcTem9/A7wr9pAREwHHgf2qnDOK4s6xhb1H7wgX5CZmZmZmbU9HqJZiIhfVih7g1Kj\nrZIHI+LoOmXz9MJFxPfrOd8c4JfFw8zMzMzMEuY244lOmpIbeC3EXf9+K5XfYdMZjYfK3Pz0G6n8\nlnstlsrH1HnmkKnXaotXGtFavxln3ZbKdzls+1R+1XVHpPKzrshdj7p3TOVX2L1z46Ey/1niiFR+\n5c9y1x9L5q7n2Q87NR4qs9uyuVtXY+rUVH71Hq+m8nNeeD+Vjy/mpvKLbt4+le/QLvn+vD8hlZ/2\nr9z70/2IZVJ5Pvkol/8899n25mdTqg+vmfuVePPjyc/NfZZI5dttnvusWmrWyFR+0pX/TuVXHJTL\nv3fBo6n8Qc8flsoPWf8fufrf+1Uqn6WlVk7l3zriqlR+lat7pvKf3JH7WX9x9c9S+a16qfFQmRc+\nXTuVX+fWM1J55ub+o3/T9/duPFTm8I7/rD7ctWuq7olzN0jll9rog1R+yJjc9QAM3Cx9iDUjbuAB\nEdEtmR+wkC7FzMzMzMyq4ElWKvM9eGZmZmZmZq2EG3jfIEkDJK3Q1NdhZmZmZmatk4dofrMGAM8D\n7zXxdZiZmZmZtWg1nmSlojbZgydpmqQLJb0g6SFJPYvy3pLulfS0pMckrV2UD5Z0uaTRkl6R1K8o\nby/pT5KelzRW0rFF+WmSRhXlg4o19PoDfYHrJI2R1EXSuZJeLI79U1O9H2ZmZmZm1jq0yQYe0BUY\nHRHrAY8Apxflg4BjI2JT4NfApWXH9AI2B/YELpfUGRhYlPeJiA2B64rsJRGxWUSsD3QB+kXELcBo\n4JCI6AMsCuwLrFcce1bdi5Q0sGhUjh77wC0L7tWbmZmZmbVwNRFN+miu2moDrwa4sXh+LbCtpG7A\n1sDNksYAfwOWLzvmpoioiYgJwOvA2sCuwN+KNe2IiNq1AHaS9JSkcZQWTl+vwjVMAb4A/k/S94HP\n6wYiYlBE9I2Ivht+u//XfMlmZmZmZtba+R68kqDU2J1c9K7Vl2loG4CiZ+9SoG9EvC3pDGCehcIi\nYo6kzYFdgP7AMZQag2ZmZmZmZvOlrfbgtaPUqAI4GHg8Ij4D3pC0H0Bx39xGZcfsJ6mdpN7A6sB4\n4AHgKEmLFMcsyZeNuYlFr2B519tUoHuR7QYsFhF3AycA5ecyMzMzM7MG1ETTPpqrttqDNx3YXNKp\nwEfAAUX5IcBlRXkH4AbguWLff4CRQA/g6Ij4QtKVwJrAWEmzgSsi4hJJV1CaLaHiFl4AACAASURB\nVPMDYFTZeQdTun9vBvBd4J9Fj5+AXy60V2tmZmZmZm2CohnfILiwSJoWEd0S+cHA0GKilCbxiyHP\npr5Q5+2fq/+H501K5S85YcNU/vXJHVL5jXu+WXW2y/SXU3X/c2JuJOxmy+eufdkuL6by7V59IpUf\n1vknqfxWlx+Syk899apUvue0e1L5n9y6Vir/2wPrGzVd2dgPp6byc+bWpPIHzrw8lY+p01L533x0\naCr/x7gwlW//g1z9s0uDDqr2/Ho/SuU3eGFwKn/986uk8iOefqfq7GWHz0jVfcB5ue+di47NDdRY\nbtodqfwtk/ql8tuunPsb70ufKJXffsXxqXz78cNTeRZfMhUfssIFqfzBcy9tPFQmPpiQyr/d47BU\nfvLM3Pfbhh3vTeV3+lUqzt2XfiuV7zT6hlR+5l3PNR4q88FJt6Xy9730YSp/+KYfV53tcN+Vqbrp\nVvV/SQFQ796p/Emjtk3lAc7bZ4PcD3wTuf3Vj5u0IbPvt3rO9/tUjPy7kdKEjW8C+0dExf+QS2pP\nabLGdyOi0Q/7tjpE05qxTOPOzMzMzNqmFj6L5knAQxGxBvBQsV2fXwAvVVtxm2zgZXrvivyApuy9\nMzMzMzOzVmVv4B/F838A+1QKSVqJ0jJtVXcNt8kG3vwoFjtPrVUg6WhJPyqeD5C0wsK5OjMzMzOz\ntqWmpmkf5WtWF4+BictfNiLeL55/ACxbT+7PwG8pLfNWlbY6ycpCJ2mRiCi/WWcApYlX3muaKzIz\nMzMzswUlIgYBg+rbL+lBYLkKu06pU09ImmfMp6R+wEcR8bSkHau9rjbbwJM0DbgC2I1Sq/nAiPhY\nUh/gcmBR4DXgiLo3PEo6DdgL6AKMAI4qvjDDgTHAtsAQSd2BaZRunOwLXFfMoHkKcGRE7FPU923g\nZxGx78J91WZmZmZm9k2IiF3r2yfpQ0nLR8T7kpanNLN/XdsA35O0B6Wl2HpIujYiftjQedvyEM2u\nwOiIWA94BDi9KL8aODEiNgTGlZWXuyQiNouI9Sk18spns+kYEX0j4r/TdRX3740GDikWUr8bWFtS\nzyJyOPD3BfjazMzMzMxatZqaaNLH13QnUDud7mHAP+sGIuJ3EbFSRPQCDgQebqxxB227gVdDaWpS\ngGuBbSUtBiweEY8U5f8Atq9w7E6SnpI0DtgZWK9s340V8l8RpbUprgF+KGlxYCtgnrnmy8f1Pv/Q\nrdW+LjMzMzMza97OBb4taQKwa7GNpBUk3f11Km6zQzQrqKoZXixMfinQNyLelnQGpS7TWtOrPN9V\nwF3AF8DNETFnngsqG9ebXQfPzMzMzKw1WwBLFTSZiPgE2KVC+XvAHhXKhwPDq6m7LffgtQNqZ8U8\nGHg8IqYAkyRtV5QfSmn4ZrnaxtxESd3K6mjMVPhyxeDii/cecCqlxp6ZmZmZmdnX0pZ78KYDm0s6\nldJNjQcU5YcBl0taFHid0v1x/xURkyVdQWlGzA+AUVWeb3BR7wxgq4iYAVwH9IyIqhcuNDMzMzMz\nq09bbuAREb+sUDYG2LJC+YCy56dS6nmrm9mxzvYZZc9vBereSLctpZk8zczMzMwsYe7Xn+ikVVK0\n4LGrX4ekaRHRrQnP/zSlXsRvR8TMRg+IYakv1JOr/zR1PVu8nmtnPrbSkan8pvuuWHV25Im3pOpe\nf+lZqXz3c45I5R88/B+p/EbLdE3lV6kZmspf+NwmqfwJW05I5eOjN1J5Jk9qPFNe/6Rc/rkj70rl\n1/3Juql8h81WT+VZpH0uX1P1uqQAqHv3xkNlPlzzZ6l8p5//IJXvukl9665W1uGHudVehq/z+1R+\n61/nvr5PHlD9BMUdtpnnb3sN2urN3Ofmk71yn5ubn7RRKt/hiMMaD5WJD19L5bVS7r2P155J5Vlq\nhVw+SYtXWoqqfte3z/1sHfTO8ak8XRdPxdVjmVS+5s7rU/nY+8ep/L+6H954qEznF55M5fssMzuV\nX4anUvmae25P5R/f4sKqs9t3uy9X9/TvpPLbzLgylVevDVN5ANp/W/mDvnnXPv9+kzZkfrj+8s3y\nfWqzPXhN2bgrzr9pU57fzMzMzKwlWwBLFbRKbXmSFTMzMzMzs1bFDTwzMzMzM7NWwg28KknaUVLq\nZqliocJbiud9JM2zpoWZmZmZmeXVRDTpo7lyA28hkbRIRLwXEbXr5PWhwqKFZmZmZmZmC0qrauBJ\nmlb2vL+kwQ1kB0u6XNJoSa9I6leUd5Z0laRxkp6VtFOFYzeX9GSxf4SktYryAZLulPQw8JCkXpKe\nl9QROBM4QNIYSQdImiCpZ3FcO0mv1m6XnWdgcX2jBw3KzbRoZmZmZtaa1dREkz6aqzY7i2ahF7A5\n0BsYJulbwM+BiIgNJK0N3C9pzTrHvQxsFxFzJO0KnAPUzj2+CbBhRHwqqRelymZJOg3oGxHHABR1\nHwL8GdgVeC4iPi4/SUQMAgaVNnLLJJiZmZmZWdvT1ht4N0VEDTBB0uvA2pQWH78YICJelvQWULeB\ntxjwD0lrAAF0KNv3QER8WsW5/w78k1ID7wjgqq/1SszMzMzMrM1rbQ288l6uzsl8pe36/AEYFhH7\nFr10w8v2Ta+mgoh4W9KHknam1It4SJXnNjMzMzNr85rzMMmm1KruwQM+lLSOpHbAvlXk9yvuf+sN\nrA6MBx6jaGwVQzNXKcrLLQa8WzwfUOW1TQW61ym7ErgWuDki5lZZj5mZmZmZWUWtrYF3EjAUGAG8\nX0X+P8BI4B7g6Ij4ArgUaCdpHHAjMCAiZtY57o/A/0h6lup7QYcB69ZOslKU3Ql0w8MzzczMzMxS\nPMlKZYpmvIbDwlTMsDk0Im5pwmvoC1wYEds1lo33B+W+UB27pOKTujV6CV+xxIwnU/m5Q++uOjt9\n/9NTdT/6zuKpfL9FhqTyWn6NVP6vT6+dyh/99hmp/P2bXZDKf6frXak80ybl8h9NTMU/2ehnqfxS\nnV9N5Xl2WC6/Su9UXIsvl6tfub+jfTBzo1T+2Q+Vyn93qeGpfLwyNpWfsVH/xkNluozPfX/G2++k\n8u9ud37V2ZWmXJOqe9JS30nls5+bvPtGKl6z7o6pfLvXk9fTY6lcPuvzKam4llo5lY/PPkrlSf7/\naMhKf07lD/7iwlQ+Xh2Ty3+Ye73auZqBT2VeG52KT11lr1R+8szc13f5awak8p8M+GsqP+mLRavO\nrrFY7nPzi5q6A7wa1u2LugPLGvbxIlul8gA9Oy+f++XSRAaN+k+TNmQGbrZKs3yfWts9eC2GpJOA\nn+J778zMzMzMbAFp9Q08SacA+9UpvjkiBjTB5fxXRJwLnNuU12BmZmZm1lLVtNGRiI1pbffgzSMi\nzo6IPnUeZ9fNSXqzWNx8rKT7JS3XSHk3SX+T9JqkpyUNl7RFWX37SIpivbvasl6Snq9w7sGScuOa\nzMzMzMzM6mj1DbyknSJiQ2A0cHIj5VcCnwJrRMSmwOHA0mXHHAQ8XvxrZmZmZma20LX6IZrz6VHg\nuPrKi2UVtgAOKRZKJyLeAN6AUu8epQXTdwLuAnKzhpiZmZmZWYPmNuOZLJuSe/Aq6weMa6B8PWBM\nA2vX7Q3cGxGvAJ9I2nR+LkLSQEmjJY0edO2j81OFmZmZmZm1Ie7B+6phkuYCY4FTGyjfvpF6DgIu\nKp7fUGw/nb2YiBgEDIL5WCbBzMzMzKwVa85r0TUlN/C+aqeIqLSo11fKJb0AbCSpfd1ePElLAjsD\nG0gKoD0Qkn6zMC/czMzMzMzMQzTnQ0S8RmnCld9LEvx3hsw9gf7ANRGxakT0ioiVKd2bl1tJ3MzM\nzMzMLMkNvPn3E2BZ4NVi6YPBwEeUhmPeXid7K1/OprmWpHfKHnXX6DMzMzMzs0bU1ESTPporD9Es\nRESvZPlnwJEVdu1UIfuXss0OFY65ubHr+8truzYW+Yrjet6Syt/xn9y3whFrdErl2y2+aNXZz+cs\nmap7i5P2TOVnb7tiKt/hoO6p/EGXz7PMYoNqtlghld/9ldykrLetdloq//2awan87KfGp/Iz18+9\nn5paadR0/WbcNiqV73JK31R+1mVXpPLqkPs7WpfDz0rlV+y+fCofn76Tyk84utGPp69Yc8RWqXzM\nmZPKz3nlo1R+zJozqs6u1KG+ebMqu+PF5Ofm2l1TedbZovFMmXavP5nKj90r97284SMnpfKPb3Ju\nKr/t0INT+beOuCqV1z9z78/Kc+5I5Q/+4sJU/vrOJ6TyB43cP5V/4bh7U/nOT/xPKv+txd5K5e95\ndbFU/vtPHJHKv3dL7nfRhD1zn807v/zbqrNaf/1U3a93OjSV33CReZZUbtBzn+b+zwaw6yrpQ6wZ\ncQPPzMzMzMxanJpovr1oTclDNM3MzMzMzFqJVt3Ak7S2pDGSni0WJ/86dfWRtEfZ9vckNTheRdKZ\nknYtnh8vqfpximZmZmZmZkktfohmpaUKyuwD3BIRZ9U5RoAioiZxqj5AX+BugIi4E7izoQMiovzm\np+OBa4HPE+c0MzMzM7MKmvNEJ02pRfbgSZom6QJJzwFbSdpU0iOSnpZ0n6Tli96244GfShpWLGMw\nXtLVwPPAypIukzRa0guSfl9W/2aSRkh6TtJISYsBZwIHFD2CB0gaIOkSSYtJektSu+LYrpLeltRB\n0mBJ/SUdB6xAacH0YZKOkPTnsvMdKSl3d7aZmZmZmVkdLbUHryvwVET8SlIH4BFg74j4WNIBwNkR\ncYSky4FpEfEnSb2ANYDDIuLfAJJOiYhPJbUHHpK0IfAycCNwQESMktSDUq/baUDfiDimOHYAQERM\nkTQG2AEYBvQD7ouI2cUSeUTEXyT9kmLBdEndgFMk/SYiZgOHA0ct7DfNzMzMzKy1cA9eZS2yBw+Y\nS2ltOYC1gPWBB4qG1qnASvUc91Zt466wv6RngGeB9YB1i/rej4hRUFoOISIam8f7RuCA4vmBxXa9\nImIa8DDQT9LaQIeIGFc3J2lg0cM4esSdQxq5BDMzMzMza+taag/eF2X33Ql4ISKqWXxpeu0TSasB\nvwY2i4hJkgYDnefzeu4EzpG0JLAppcZbY64ETqbUY1hxMZ+IGAQMArjo8df9JwozMzMzM2tQS+3B\nKzce6ClpK4Di3rf1qjiuB6UG3xRJywLfLatveUmbFfV1l7QIMBWouEJz0SM3CrgIGFrPpC9fOT4i\nngJWBg4G3D1nZmZmZpYwN6JJH81Vi2/gRcQsoD9wXjHpyhhg6yqOe47S0MyXgeuBJ8rqOwC4uKjv\nAUo9e8OAdWsnWalQ5Y3AD6l/eOYg4F5Jw8rKbgKeiIhJjb5QMzMzMzOzRrTIIZoR0a3O9hhg+wq5\nM8qev0npXr3y/QPqqX8UsGWFXZvV2R5cdswtlIaLVqw/Ii4GLq5z/LaAZ880MzMzM0uqySx41oYo\nmnH3YmslaXFgJPBcROxX1UGf3Zz6QkVNY/PCfFXNYqum8u1nTU7lY+yT1YdXWjlV94ye1dx++aXO\nI69N5ZlT3zKLlc3ddv9Uvv3jN6XyWn/jVP4/Hfun8iv9a2Aq3/47e6TyKDlwYJEOqXhMej+Vn/4/\nt6TyXS7+QypfE7m/o3WY+2kq/9K0ef621aC1Z9+QyjPlk1T8ia65759t1OCcVPOanHt/tMJq1Yd7\nLJOqey6dUvn2cz5L5We2WzqVn3vK/0vlu/y8Xyr/8l51/0bZsLWvOjCVn7Z+pcEx9ev20fBUflzn\nH6XyGy7x78ZDZeKlp1J5Pp+Rig/ZPPe74qBXfpLKk5yNUKuum8rf/2Gjg6u+YvuV3krlFxnyv6n8\nFweelMp3/bT6r+87XXPfyxM+nZXKb7fihFR+xtzFU3mAHh3WVOOppnfOg680aUPm5F2b5/vUInvw\nWrqImAys2dTXYWZmZmZmrYsbeGZmZmZm1uJ4HbzKWvwkK2ZmZmZmZlbS6ht4koZIGivphAVQ18l1\ntkc0ku8r6S/F8x0l5Qagm5mZmZmZJbT4IZqSFomIijOKSFqO0kLm38oc14CTgXNqNyKiwQZbRIwG\nRhebOwLTgAYbhWZmZmZm1jgP0ays2fTgSZpW9ry/pMENZAdLulzSU8AfJXWV9HdJIyU9K2nvIno/\nsGKxdt12koZL+rOk0cAvJO0l6animAeLBc+R1E3SVZLGFb1/P5B0LtClqOu68muWdIOkPetcX/+i\n126opF7A0cAJZdfyhqQORb5H+XZZPQMljZY0etBVD37dt9jMzMzMzFq5ltyDtxKwdUTMlXQO8HBE\nHFG7BIGkB4HvAUMjog+AJICOEdG32F4C2DIiQtJPgN8CvwL+HzAlIjaozUXErZKOqa2rjhuB/YF/\nSeoI7AL8FNgCSmvwSbocmBYRfyrqHA7sCdwBHAjcFhGzyyuNiEGUFkhPL5NgZmZmZtaa1Xi5t4pa\ncgPv5oioXaBsN+B7kn5dbHcGVgEqLTJTvujSSsCNkpYHOgJvFOW7Ump0ARARkxq5lnuAiyR1Ar4D\nPBoRM4oGZX2upNSgvAM4HDiykXOYmZmZmZk1qNkM0QTKm+Cdq8hPL3su4AcR0ad4rBIRL1Vx3MXA\nJUVP3VFVnnceEfEFMBzYHTiArzYi6zvmCaCXpB2B9hHx/Pyc28zMzMzMrFZzauB9KGkdSe2AfZPH\n3gccq6LLTNLGVR63GPBu8fywsvIHgJ/XbhRDOQFm171PrsyNlHritgPurbB/KtC9TtnVwPXAVVVe\nr5mZmZmZUZpkpSkfzVVzauCdBAylNMvk+8lj/wB0AMZKeqHYrsYZwM2SngYmlpWfBSwh6XlJzwE7\nFeWDinNcV6Gu+4EdgAcjYlaF/XcB+9ZOslKUXQcsAQyp8nrNzMzMzMzqpfDNiU1GUn9g74g4tLHs\n4OfeTX2hDn355MZDZf683P9L5U/o9H+p/OTLH686O/r3/0zVvesbZ6Xyn1z+71S+/T+uT+WXePnq\nVH7yRQ+l8jWXXZvK9+iQ+3vJIuMfTuWnXFCpw7p+sy/J/T1j6Zf+lspPPO/+VL7n336Rys+++Y5U\nntk1qficI3M/u+M+WT2V7/vGOY2Hyjz8vdtS+V2ePT6Vn31r7vt/9htTUvnzd/tL1dnTZv4pVfeF\nS/wulf9l59xgjZg+vfFQGW2yRSo/duvfp/Ibjcx974zbMve9vO7pW6byk+6YkMovffkvU/mah+5O\n5elRd5BOw144LvfZuf7tP07lh6x5ZSq/0jtPpfLbjvpVKn/XBuem8ntNOD2V//Sa51L5OVfm/q+x\n3JxHqs7GZx+l6n69++Gp/Oqzbkrlb/nkO6k8wH5rLdPgRBLNxSl3vdCkDZmz91qvWb5PLXmSlRZN\n0sXAd4E9mvpazMzMzMysdWjWDTxJpwD71Sm+OSLOborrWZAi4timvgYzMzMzM2tdmnUDr2jILfTG\nnKSTIyI39iR/jl6U1uRbf2Gex8zMzMysLWjOE500peY0yUpTyt0oYGZmZmZm1gy1+QaepHOBLsXs\nlpVmx0RSV0n/kvRcMbPmAUX5ZpJGFOUjJXWX1EvSY5KeKR5bV6ivvaTzJY2SNFbSUQv5ZZqZmZmZ\ntSo1EU36aK7afAMvIk4CZhQLpB9ST+w7wHsRsVExxPJeSR0prX33i4jYCNgVmAF8BHw7IjahtOh5\npSncfgxMiYjNgM2AIyWtVjckaaCk0ZJGD78lN3OimZmZmZm1Pc36HrxmZBxwgaTzKN1H95ikDYD3\nI2IUQER8BqXePuASSX2AucCaFerbDdiwWCYBSguurwG8UR6KiEGU1t5LL5NgZmZmZmZtjxt4VYiI\nVyRtQmlJg7MkPQTcXk/8BOBDYCNKPaRfVMgIODYi7lsY12tmZmZm1tp5kpXK2vwQzcJsSR3q2ylp\nBeDziLgWOB/YBBgPLC9psyLTXdIilHrj3o+IGuBQoH2FKu8Dflp7TklrFj1/ZmZmZmZm8809eCWD\ngLGSnqnnPrwNgPMl1QCzgZ9GxKxispWLJXWhdP/drsClwK2SfgTcC0yvUN+VQC/gGUkCPgb2WdAv\nyszMzMystXIPXmWKZjwDjH3pqd5rp75Qm7/2t1T9/14tN5Hnlk/+OpVn0sTqsx3r7Uyt6Pev7JHK\nn77Czak8i+T+DnJbx5+k8pss1yOVX63jw6n8+Bk7pfJrdcyNHB7z+a6p/HJH5/LLXnRYKk+HTqn4\nnDsfSOXPXvG0VD77y+c3Q49J5R/9be77eddV3mg8VObVKeuk8kcecWsqP+zWdVP5jm8+ksqP6XdF\n1dneY+9M1f3Cmt9L5bd84vhU/sMl+jceKrPMs+en8h9t/Jtc/U+elco/s/4fUvlZc2tS+Rff+yyV\nv+5vI1P5B/+2fCrfTrNT+VenbJ7Kf+uDi1P5x7oNTOXfWWmLVP7g2bnrmThnvVT+2L++msoP+fnU\nVP6LP+b+nzTrdxdUnb1iRG6A3Pc3WSmVn5P8vbLkMd9O5QGWuuZxpQ9qAr+65bkmbchc0H+jZvk+\neYimmZmZmZlZK+EhmmUkLQU8VGHXLhHxyTd9PWZmZmZmVpmHaFbmBl6ZohHXp6mvw8zMzMzMbH60\niQaepKeATsCSQBfg3WLXPsBw4O2I2K4sPwZYpFjUvFJ9fYAVIuLuBXR9A4C+EZG7+cbMzMzMrI2q\nmesevEraRAMvIraAyg2p0iSWdJe0ckS8LamaGQX6AH2BBdLAMzMzMzMzWxA8yUrJTcABxfODgCH1\nBSV1BM4EDpA0RtIBkrpK+rukkZKelbR3kR0g6TZJ90qaIOmPZfUcLukVSSOBbeo510BJoyWNvuOz\nyQvqtZqZmZmZWSvVJnrwqnArcBXwJ2Av4BBKi5TPo1j/7jTKegIlnQM8HBFHSFocGCnpweKQPsDG\nwExgvKSLgTnA74FNgSnAMODZCucaRGmNvvQyCWZmZmZmrVnU5JZXaSvcwCv5BJgk6UDgJeDz5PG7\nAd+TVLs4XGdgleL5QxExBUDSi8CqwNLA8Ij4uCi/EVjz670EMzMzMzNr69zA+9KNwF+BAfNxrIAf\nRMT4rxRKW1Dquas1F7/nZmZmZma2kPgevC/dDvwRuK+K7FSge9n2fcCxKmZskbRxI8c/BewgaSlJ\nHYD95uN6zczMzMzarJqaaNJHc+UGXiEipkbEeRExq4r4MGDd2klWgD8AHYCxkl4oths61/vAGcCT\nwBOUhoWamZmZmZl9LYpovq1PKzPz7tQX6v4VT0hVv9v7F6Xyd/f8RSq/1feXqzo76vTbU3X3WWZ2\nKt/t9MNS+QeOuiaV33jZbqn8Ku0fSOUvGLluKn/89h+l8u2nvtt4qEy8Nb7xUHn+7XdS+Sd/OjyV\n3+RHvVP5TtusmsrTbuH+XUw9l07l3/zWSan8sn/YJ5Vvv3SXVL7TMbmfrzuXOTGV3/Vnq6XyI4+7\noerstHW3SNXd75Pc5+a9y+Y+N3c6Zb1UvtPPBqTy8fFbqbyWXDFX/1svp/Isu1IuXxo0U7UvFtsw\nlX9g8f1T+b2eG5jKs1jPVFzdlkzla+7N/S5t1++AxkNlru9wbCrf/bUnUvmNlumayq8y985Ufs5d\nQ1P5x3e8uOrsDovckqp72OwfpPI7ffTnVF5r5r73Aej+g9wPWBP52T9GNWlD5tLDNmuW75N78MzM\nzMzMzFoJT/jRAEm7A+fVKX4jIvZtiusxMzMzMzNriBt4DYiI+6hu0hUzMzMzM/sGNeeJTppSqx+i\nKemUYjKUMZLmlj0/TtIZkkLSt8ryxxdlfRuo8+QFfI3TFmR9ZmZmZmbWNrX6Bl5EnB0RfSKiDzCj\n9nlE/KWIjAMOLDtkP+CFRqpdoA08MzMzMzPLqZkbTfporlpsA6+810tSf0mD57OqO4C9i3p6A1OA\niQ2c91ygS9ELeF1R9kNJI4uyv0lqX3uNks6W9Jykf0tatihfTdKTksZJOquBcw2UNFrS6EFX3jOf\nL8/MzMzMzNqKFtvAW4A+A96WtD6lnrwbGwpHxEl82RN4iP4/e+cdbkVx/vHPl46A2BUrdqwgKmKJ\nYkuisdeoiWJUUlXiLyYmGjXRJBo19hJsqLF3Y2+gCBaKFFHUKPZeQFSa976/P2aOLOfunnMGL9x7\n4f08zz5nd/Y7s7N7tsw75R1pPeBAYOvYSlgHHBLlnYBnzKwn8CRwVAw/H7jUzDYC3q9wrEFmtpmZ\nbTbgyF2+wyk6juM4juM4jrMo4E5WAjcRjLsfADsChyfE3RHYFBipMCdPR6A08dgsoDTRymhg57i+\nNVCa9OQ6GnrqdBzHcRzHcRynAu5kJZ+WbOBl/9EO3zGte4GzgFFm9oXSJk8VcI2Z/TFn32ybM5N8\nHXNfb78jHcdxHMdxHMdpVFpyF80PJa0nqRXwnealM7OvgT8Af6sxymxJbeP6Y8B+kpYDkLSUpNWq\nxB/OHMcuh1QSOo7jOI7jOI7TEKu3Jl2aKy25Be8EQsvbx8AooPN3SczMbkqQDwLGSxoTx+GdBDwc\njc3ZwK+BNyvEPxa4QdIfgLtrOmL9NwnZg8+HPZmk/6b15CT9zFFPJenvm5GQ/2kzOaTjDbXr34MP\nVzysZvm1+/279rSBX6z4dJL+3fp+SfqP2CJJ/39bjEzS1w8bmqR/YNW8xuhiunVLHB/aLU3+0WPT\nk/SDPpiWpF9jxcWT9F3apb02WyV1CICNl/0sSd99wj+S9E//tuIw4waMnpyWn9/MGJGkrxub9i65\n+pOvkvS/6nBP7eLXT+T+aT+qWX7fO/CD1V6tWT/9ubRzfWe5Lkn6p1/7PEnfdbGtkvRdpqTd+x+2\n2jpJv9eSbyfpJ37WI0nfa1StdbiBDhPT3v3TViz0z5bLA//rmqRf8qu21UUZpm+U9m3Z+ptZSfou\nrw1P0k9bM+1+WMUGJemf+SDtW7TiXnsk6Xu1K3SZ0ICp7EDXTx+tWb99m1u5ddVzatZ/MDXt3uzY\nZkqSHmCJ5BhOc6LFGnhmdhtwW2KczmXbpxbo+lVJ5w+EFr/S9s3kOGfJS4zfPwAAIABJREFUHi+b\nXzObDGyZkZ5UNfOLEEnGHWnGneM4ThEpxh2kGXeO4yw6pBh3QJJx5zi10GINPMdxHMdxHMdxFl3q\n6+ubOgvNkoXKwJN0ImGi8iy3mllav4w56T0LtC8L/qmZTZiX9BzHcRzHcRzHceYnC5WBFw25eTXm\nvszpwpnWgb1y+v2Bh83svbj9BrCZmaV12nccx3Ecx3Ecx6dJKKAle9FsafQHVmzqTDiO4ziO4ziO\ns/CyULXgNTaSlgUuA1aNQQPNbLikU2PYGvH3PDO7IMb5M/ATgnfPtwkTnL8BbAZcL2k6cxysHC1p\nd6AtsL+ZTVoQ5+U4juM4juM4zsKJt+BV5nzgXDPbHNgXuCKzrwfwA6APcIqktpJKup7ALgSjruRB\ncxRwiJn1MrOS3/dPzKw3cCnwu/KDSxogaZSkUYOufGj+nKHjOI7jOI7jtEDq66xJl+aKt+BVZidg\nfenbiawWl1Qap3efmc0EZkr6CFge2Bq428xmADMk/bdK+nfE39HAPuU7zWwQYc49mH5P872LHMdx\nHMdxHMdpFriBV5lWQN9osH1LNPhmZoLqmLdrWUpjXuM7juM4juM4ziKJO1nJx7toVuZh4OjShqRe\nVfTDgd0ldYgtfbtl9k0DujR+Fh3HcRzHcRzHcQLeajSHxSS9k9n+F3AMcLGk8YRr9STwi6IEzGyk\npHuA8cCHwARgatw9GLiszMmK4ziO4ziO4zhOoyEzb9psTCR1NrMvJS1GMAgHmNmY75pu3x8NTvqj\nnrlrhaT0dzp+VpL+8tO+n6T/fMY3NWt7L/FUUtqf/uz0JH2bKwcn6Rf/bGiS/sPfXFFdlGG547ZL\n0qvHxmn6dh2T9NM7rJmkb//Mf5L0R4zfK02/14ZJ+lUW75CknzxlenVRhm2GHl1dlGVWXZL8jJVP\nSdKf8M5fkvStd9spSc+7byXJPznz4SR9l+svTtIPeXvV6qIMIyd9XLP2mB3aJaW9/wkTk/SXnbpz\nkn5WXX2SfrnFPk3SLzX2siT9exv+IUm/zMWHJenb7bJpkn7G7c8k6Zmddj2nnXR1kn5G3eJJ+m43\n/SxJX3f475P07R65PEl/yMQDk/Rn/rxPkn6Vzs8l6W/UgCT9QW/8Kkn/80f6JunPe6X2d3OHndZK\nSlubJdb7T0ubQnngiG3T0gfOP2gTVVc1PQed80STGjI3/t92zfI6eQte4zNI0vpAB+CaxjDuHMdx\nHMdxHMdxasENvEbGzA5u6jw4juM4juM4jrNo0mydrEiqkzRW0jhJYyRt1YR5+TJR30/SvfMrP47j\nOI7jOI6zqGP11qRLc6U5t+BNN7NeAJJ+APwDSBus5DiO4ziO4ziOswjRbFvwylgc+BxAgbMkvSBp\ngqQDY3g/SU9IulvS65LOkHSIpOeibs2o213Ss5Kel/SopOVj+KmSrpI0NMY/pjwT8RhDJd0maZKk\n6xUnxZP0wxg2hsyk5ZI6xXSfi8fcM4b/VtJVcX2jeD6Lzd/L6DiO4ziO4zgLB/X11qRLc6U5G3gd\nYxfNScAVwGkxfB+gF9AT2Ak4S1K3uK8nYRqD9YCfAuuYWZ8Yv+T67inC5OWbADcBWbdUPYAfAH2A\nUyS1zcnXJsBAYH1gDWBrSR2Ay4HdgU2BrAvLE4HHYz62j/ntBJwPrCVpb+Bq4Odm9nX2QJIGSBol\nadRHbw2t5Zo5juM4juM4jrMI05wNvOlm1svMegA/BK6NrWXbADeaWZ2ZfQg8AWwe44w0s/fNbCbw\nGmGicgjz0XWP6ysDD0maABwPbJA55n1mNtPMPgE+ApbPyddzZvaOmdUDY2O6PYDJZvaqhXknsn7j\nvw+cIGksMJTgXXPVGL8/cB3whJkNLz+QmQ0ys83MbLPlVu1XwyVzHMdxHMdxHGdRpjmPwfsWM3ta\n0jLAslWkMzPr9Znteuac64XAv8zsHkn9gFML4teRf31q0WQRsK+ZvZyzb23gS2DFKmk4juM4juM4\njpOhvq75dpNsSppzC963SOoBtAY+BYYBB0pqLWlZYFsgZfbMrsC7cT1tFtZiJgHdS+P8gIMy+x4C\njs6M1dsk/nYFLiDkf2lJ+zVSXhzHcRzHcRzHWURpzi14HWO3RgitYIeZWZ2kO4EtgXGAAb83sw+i\nEVgLpwK3SvoceBxY/btm1MxmSBoA3Cfpa4IR2iXuPg04DxgvqRUwGdgNOBe42MxekXQEMETSk2b2\n0XfNj+M4juM4juMs7NTX1zd1FpolzdbAM7PWBeFGGDt3fFn4UMIYt9J2v7x9ZnY3cHdOuqeWbW+Y\nWe9ccIzfZNYfJIzFK093OvDznPCfZdbfBtYq1ziO4ziO4ziO46SgYC85zZ0Ppn+S9EctP+WOpPSH\n1R+QpN92uWeS9LP+fVXN2na/PCopbfv4zST9N3c/mqRvvd7KSXqtt2F1UYaZl96epG//q/2T9MNm\n7pGk/96US5L0daNeTNJ/dsA5SfplOrySpOfO2u81AG25ZVr6X0xJ0yfWLs5aZ6ck/c0T04bw/rTr\nrUn6aX+/K0n/+t/+m6Tv+fmlSfpZd45I0n/6m6tr1q5Y/3hS2k9O3SFJv+3yKaMJYHqun69iOkx+\nuLoow5f/eiBJ37l/2rPy2sAGdakVWfOWXybpZwy6P0n/we/T3rWrt0m7nrMHX5+kf++2vKH5xax0\n+EZJ+ikPvJ6kX+bKPybpmflVkvyZ6bsk6beYWfuzC3Bj97Rv14wxjyXpD1+q9vtHK6ydlPa732yT\npF+p/pEk/TNf7ZykB+i7wuJKjtQE7HP6o01qyNxx0k7N8jo12xY8x3Ecx3Ecx3GcIprzXHRNSYtw\nsuI4juM4juM4juNUp8UZeJL2kmQJTlUa67i9JO2a2d5D0glV4oyIv90lHTy/8+g4juM4juM4iwr1\n9dakS3OlxRl4hCkInmLuqQgAkDQ/u5z2Ar418MzsHjM7o1IEM9sqrnYH3MBzHMdxHMdxHGe+0qIM\nPEmdgW2AI4Afx7B+koZJugd4MYYdJ+mFuAyMYd0lTZI0WNIrkq6XtJOk4ZJeldQn6vpIelrS85JG\nSFpXUjvgr4T598ZKOlBSf0kXxTjLS7pT0ri4bBXDv4xZPwP4Xoz7W0lPSuqVOa+nJPVcENfQcRzH\ncRzHcZyFlxZl4AF7Ag+a2SvAp5I2jeG9gWPNbJ0YdjiwBdAXOKo0uThhKoJzCNMZ9CC0qm0D/A74\nU9RMAr5nZpsAJwN/N7NZcf1mM+tlZjeX5esC4Akz6xnzMrFs/wnAsBj3XOBKoD+ApHWADmY2rvxk\nJQ2QNErSqOuuvDbtSjmO4ziO4zjOQox30cynpXnRPAg4P67fFLfvBZ4zs8kxfBvgTjP7CkDSHcD3\ngHuAyWY2IYZPBB4zM5M0gdCNEqArcI2ktQkTqbetIV87AIcCmFkdMLWK/lbgz5KOB34GDM4Tmdkg\nYBCkT5PgOI7jOI7jOM6iR4sx8CQtRTCkNpJkQGuCAXYfUOtkLDMz6/WZ7XrmXIvTgCFmtrek7mQm\nNm8szOxrSY8QWiQPADatEsVxHMdxHMdxnAxW5+0febSkLpr7AdeZ2Wpm1t3MVgEmE1rnsgwD9pK0\nmKROwN4xrFa6Au/G9f6Z8GlAl4I4jwG/BJDUWlLXsv15ca8gdO0caWafJ+TPcRzHcRzHcRwnl5Zk\n4B0E3FkWdjtl3jTNbAyhy+NzwLPAFWb2fMJx/gn8Q9LzzN3COQRYv+RkpSzOscD2savnaGD9sv3j\ngbrogOW3MZ+jgS+AqxPy5jiO4ziO4ziOU4jMvGmzKZC0IqH7Zw8zq6+mn37irkl/VPud06YJ/OSS\np5P0S2y5YpK+9cpFjZ/5TNrx4pq1I9+ekpT2Tyf+MUl/7xbnJOlTadc6rZ7ly5l1SfofrvFpkr5L\n6/eS9J/MSrvXPu67Y5K++4/WSNK3Wb28Ab0yrdfqlqT/cutfJOln13dM0i92elr6X504KEm/jI1O\n0tO2Q5L8yQ/7JOm3efvMJD0ffJQk19prJuntzbdq1n567fiktBfffIUkfdu1l07Sq88WSfp3ujSY\nbagiq7R5Ikn/1KdbJ+l7LfdOkv6WCWnP+qzZae/OAe+cmqT/aJezkvQvfJz27u+74vtJ+i9nL5+k\nX+Ksw5P0bdZYIkn/3l5p76rTb0p7vvpuulKSvkPvtG9Rx1efStJvv+q0mrXvfpn2X23Q5v4k/Ven\npF17gE7nPqLkSE3ALn98oEkNmQf+sUuzvE4tqQVvoUHSoYTWxRNrMe4WNVKMO8dxnMYixbhzHMcp\nIsW4c5z5QYtxsrIwYWbXAj7vgeM4juM4juPMI815qoJqRAeSNxM8+b8BHJDnlyMO7zqS4FxyAnC4\nmc2olHaTteBJ2kuSSeoRt7tLeiGubybpgirx+0m6N/GY/WPXyNL2FZLKx8uV6y9KPMZgSfulxHEc\nx3Ecx3EcZ5HiBMKUbWsTHDaeUC6QtBJwDLCZmW1ImEXgx9USbsoumgcBT1HmJAXAzEaZ2THz4Zj9\ngW8NPDM70sxenA/HcRzHcRzHcRzHKWJP4Jq4fg2wV4GuDdBRUhtgMaCqs4QmMfAkdSZMSH4EOVZo\ntnVO0qmSrpP0tKRXJR2VkXaWdJukSZKul6QY52RJIyW9IGmQAvsBmwHXR0+YHSUNlbRZjPNDSWOi\np8vHcvI0WNIFkkZIer3UShfTvkjSy5IeBZbLxNlU0hOSRkt6SFI3SW1i3vpFzT8k/a1xrqzjOI7j\nOI7jLBpYfX2TLt+R5c2s5D3pA6CBtx0zexc4G3gLeB+YamYPV0u4qVrw9gQeNLNXgE8lVZvoe2PC\nJOdbAidnulluAgwkTEuwBlBy2XWRmW0emzI7AruZ2W3AKOAQM+tlZtNLiUtaFrgc2NfMegL7F+Sj\nG8Ew3Q04I4btDawb83AosFVMsy1wIbCfmW0KXAX8zcy+IbQkXippJ+CHwF+qnL/jOI7jOI7jOM0I\nSQMkjcosA8r2PxobnMqXPbM6C9MaNBhQKGlJgt20OqEXYidJP6mWr6ZysnIQcH5cvyluVxrrdnc0\nyKZLGgL0AaYAz5nZOwCSxhIGKT5FmJPu94RmzKWAicB/K6TfF3jSzCYDmNlnBbq7otfLFyWVrOxt\ngRvNrA54T9LjMXxdYEPgkdiw2JpgeWNmEyVdB9wLbGlms/IOFm+SAQAX7rIBR2yyaoVTcBzHcRzH\ncRxnQWFmg4DCeSjMbKeifZI+lNTNzN6X1A3ImwdoJ2CymX0c49xBaEz6T6V8LXADL3qM2QHYSJIR\nDB8DKvnGL7doS9szM2F1QBtJHYBLCIMR35Z0KpA2kVMx2eNVm/dCwEQz27Jg/0YEI3W5gv1z3TSp\n8+A5juM4juM4zsKM1bXo4vE9wGGEXoGHAXfnaN4C+kpaDJgO7EjokViRpuiiuR9wnZmtZmbdzWwV\nYDKwSoU4e0rqIGlpoB8wsoK2ZMx9Esf6ZT1aTgPyZtx+BthW0urwrRFaK08CB0pqHa3v7WP4y8Cy\nkraMabaVtEFc34fQsrgtcKGktNlCHcdxHMdxHMdpyZwB7CzpVUJL3RkAklaUdD+AmT0L3AaMIUyR\n0IoKLYYlmqKL5kHAmWVhtwN/rBBnPDAEWAY4zczek7ROntDMpki6HHiBMGAxawwOBi6TNJ0wnq8U\n5+PYHfIOSa0ITaQ713g+dxJaJF8kWNlPxzRnRUcsF0jqSrjW50n6kPAH7hhbGC8idFc9rMbjOY7j\nOI7jOM4ij7XgefDM7FNCi1x5+HvArpntU4BTUtJe4AaemW2fE3YBcEFmeygwNCMZb2aHlsWZS2Nm\nv8msnwSclHOc2wnGZIl+mX0PAA+U6QcTjELMrH/Zvs7x14DfkIOZjSW00pWzTkZTcb4/x3Ecx3Ec\nx3GcWlGwT5ovcQzdl2Z2dlPnpSm5+aUPk/6ondeYXl2U4ZXPU3qlQitVG4I4N0t3bFuzdo0ZNySl\nbSOGJ+lb7VnV+dBc1D9RyT9PQ2YOfSVJ3+FnP0jS29jxSfone5+VpO/XtcEsIZVp2z5JPvbLfkn6\nL2Z+k6TfYJlpSfr2rb9I0neuezNJT+u0erT3ZvVJ0nd7rZJ/qoZorY2T9LRKrAe0NLfRr80qHH+e\ny1ez65L0G3et/f3w1EdbJKXdplXaezBV/+onXyXpf7zkPUl6vpiSJNeavZL09U/en6S37Q9I0rd6\ncWiSflaP7yfpn/1grST9sou1S9KvO/L3SXr16p2m79g1Sf9Fh42S9GM+LHQhkEuv5Yr81+XT7qRf\nJek7/nqXJP1dsw9O0k9fe5uatXvNvi0p7daaWV2Uob2mJulfmlrkDqKY9ZZcLO2F1UTsNPCeJjVk\nHj1vj2Z5nZrKi2bNmNmpTZ0Hx3Ecx3Ecx3GaFy3cycp8o6nmwXMcx3Ecx3Ecx3Eamflq4En6ch7j\n7SVp/Rp0g6Mjk/LwzSRdENf7R0cmSPqFpEMz4SuWx81J6w1JyyTkvbukF2rVO47jOI7jOI6TjtVb\nky7NlebaRXMvwiTgL85LZDMbRc4cEWZ2WWazP8HT5nvzcgzHcRzHcRzHcZzmxgLpoimpn6Shkm6T\nNEnS9VLw0iHpDEkvShov6WxJWwF7AGdJGitpTUlHSRopaZyk2+NkfyV2kjRK0iuSdssc796cfJwq\n6Xex1W8z4Pp4jB9Juiuj21nSnWVxu0t6SdLlkiZKelhSx7hv05i3ccCvM3FaSzor5n28pJ/H8L0l\nPaZAt5j3FRrrejuO4ziO4ziOs2iyIMfgbQIMBNYH1gC2jhOX7w1sYGYbA6eb2QjCzO7Hm1kvM3sN\nuMPMNjeznsBLwBGZdLsDfYAfEea460AVzOw2QgvfIWbWC7gf6CFp2Sg5HLgqJ+rawMVmtgEwBdg3\nhl8NHB3zl+UIYKqZbQ5sDhwlaXUzuxN4n2AMXg6cYmYflB9M0oBovI569Jbrqp2W4ziO4ziO4yw6\n1NU37dJMWZAG3nNm9o6Z1QNjCYbZVGAGcKWkfYCvC+JuKGmYpAnAIcAGmX23mFm9mb0KvA70SM1Y\nnMvuOuAnkpYgTIL+QI50cpzbDmA00D3qlzCzJ2N41hL7PnCopLHAs8DSBCMR4GjC5O4zzezGgnwN\nMrPNzGyznQ74aeppOY7jOI7jOI6ziLEgx+BlJ/moA9qY2TeS+hBmcd+PMGH4DjlxBwN7mdk4Sf3J\nTFAOlI9wnNcRj1cD/yUYnLeaWd7kW+Xn0LFKmiK07D2Us29loB5YXlKraPg6juM4juM4jlMDzdnR\nSVPSpNMkSOoMdDWz+4HfAqUujtOALhlpF+B9SW0JLXhZ9pfUStKahK6fL9d4+LmOYWbvERyunEQw\n9mrCzKYAUySVZsDM5u8h4Jcx30haR1InSW0IXUAPInQ5Pa7W4zmO4ziO4ziO4xTR1F40uwB3x3Fz\nYo6hcxNwuaRjCC17fyZ0cfw4/maNv7eA54DFgV+Y2Yzov6Uagwlj9qYDW5rZdOB6YFkzeynxPA4H\nrpJkwMOZ8CsIXVHHRKcyHxM8hP4fMMzMnoqOWUZKum8ejus4juM4juM4jvMt89XAM7PO8XcoMDQT\n/puMrE9OvOEEZywlLo1Lua5/wXG/PZ6ZDSYYc5jZqRnN7cDtZVG3ITg9yabVPa5+AmyYCT87sz6a\nOa2PAL+P4fXAn+KS5a+ZuNOYh3GDjuM4juM4jrMoY3XeRTOPpm7BazZIGg18RWhda3a89u7UJP0B\nnfKG/RUz6fN9kvT913gmSU+HTjVL323dYO76inRbJrHhM3G44zub/S1Jv0q3C5P001fsl6Qf2/bQ\nJP0Wy76RpH9p2i5J+nUn/CVJv3TP7ZP0vbqm3Ws29aMk/ej6vZP0S+7z4yR9q7ZpPeGfu+Th6qIM\nB3RbNUlPu2pDh+em/oHbkvQznnorSb/G0W8n6amth8a3HHFFuXPjYq7Y4tyktK9rPSBJf2jie3PT\n2S8k6V/peHySft0V0vLz2rQtk/Sr1zeYragiGnJLkp5OtX9XANo+dEWSftut095V33RZLUmvDTes\nLsrwTqcDk/QrT7k2SX/5mLR31XHrpr0b+DTt22s7rZWk1wprVxdl2F7TkvTtZtd+vne1TSvHHDS2\nfPRRZT447f4kfasrhiTpnZaPG3gRM9u0qfPgOI7jOI7jOE5tuJOVfJrUyYrjOI7jOI7jOI7TeLRo\nA0/SG5Juz2zvJ2lwlTi9JO1aFrZLnFD8RUnPSzonhg+WlNbO7jiO4ziO4ziO00QsDF00N5W0vpm9\nWKO+F7AZcD+ApA2Bi4AfmdkkSa2BtIEVOUSvmfL57RzHcRzHcRxnPlDvxew8WnQLXuQc4MTywDjf\n3FWSnoutcntKakfwYHmgpLGSDiR4vPybmU0CMLM6M8t67NxW0ghJr5da8yR1lvSYpDGSJkjaM4Z3\nl/SypGuBF4BVJB0h6ZWYj8slXRS1y0q6XdLIuGw9Py+S4ziO4ziO4zgLPwuDgXcL0FtSubulE4HH\nzawPsD1wFtAWOBm42cx6mdnNhKkPRldIvxth+oTdgDNi2AxgbzPrHdM+R3Mm31sbuMTMNgBmE+bw\n6wtszdzTIZwPnGtmmwP7EubMmwtJA2LX0VHP3XdzDZfCcRzHcRzHcZxFmYWhi2YdwXj7I/BAJvz7\nwB6Sfhe3OwCJ/sQBuCt2s3xR0vIxTMDfJW0L1AMrAaV9b5pZyfd0H+AJM/sMQNKtwDpx307A+plJ\n2ReX1NnMviwFmNkgYBDA3x99xd0EOY7jOI7jOE7E58HLZ2Ew8ACuIxh42UmDBOxrZi9nhZK2KIs7\nEdgUGFeQ9syyNAEOAZYFNjWz2ZLeIBiQEObSq4VWQF8zm1Gj3nEcx3Ecx3EcpyILQxdNzGw2cC7w\n20zwQ8DRpa6TkjaJ4dOALhndWcCfJK0Tda0k/aLKIbsCH0XjbnugaHbTkcB2kpaU1IbQFbPEw8DR\npQ1Jvaoc03Ecx3Ecx3GciNVbky7NlYXCwItcydwtkqcRxtyNlzQxbgMMIXSNHCvpQDMbDwwEbpT0\nEqEVcI0qx7oe2EzSBOBQYFKeyMzeBf4OPAcMB94Apsbdx8Q0xkt6EahmVDqO4ziO4ziO41REZs3X\n+lwYKI2riy14dwJXmdmdqel8/c2EpD/qiXdWTEp/k+XT7oPRH6i6KEPbVmn6ndvdVrN2+rJbJqX9\n2FvdkvS7r/Rckv6LVuX+firTrlWtvXoDHb55P0lv459O0j+y3G+rizL0Xn56kn7SZ52T9J/PmJ2k\nnzE7zWVym9Zp9+aGy6blv13rtHq0Tm0+SdIv/dLlSfpxq/yuuijDlBnfJOm3a3VTkn5I3YFJ+k+/\nTrsf9l97Qs3aoe9tmpR2j6XTrk3qe3OjZRdL0j/5xpQk/eYrL5Gkf3Nq2rO+yuIdqosyrNf5yST9\nJ3UbJemXeu7cJP2Itf6cpO+13DtJ+tendk/Sf/L1rCT9al07JukTP9NMnpJ2P3yyRt8k/f4fnpyk\nf6/97kn6KTNbJ+nX6vpSzdp2L9yflPaNva5P0u8684HqogxTZ62UpAdYrXP7xDuiafjewTc2qSEz\n7IaDmuV1WljG4DVnTpW0E2GM3sPAXU2cn2ZPinHnOI7jOI7jLJq4k5V83MCbz5hZWnW54ziO4ziO\n4zjOPLIwjcFrUiS9IWlYWdhYSS/E9edLjlQktZH0paSfZLSjJfVesLl2HMdxHMdxnJaJO1nJxw28\nxqWLpFUAJK1Xtm84sFVc7wm8UtqW1AlYk+KpGhzHcRzHcRzHcariBl7jcgtQ8hhwEHBjZt8I5hh4\nWwGXAaWpEfoAo82sbkFk0nEcx3Ecx3GchRM38BqX24F94vruwH8z+7IteFsBTwIzJXWJ2yMWVCYd\nx3Ecx3Ecp8VTV9+0SzPFDbzG5VPgc0k/Bl4Cvi7tMLM3gXaSVgB6AC8TJkLfgmDgDS9PTNIASaMk\njbrqcvcs6TiO4ziO4zhOZdyLZuNzM3Ax0D9n3whgf+B9MzNJzwBbE7poNpiszMwGAYMgfR48x3Ec\nx3Ecx1mYac6OTpoSN/AanzuBbsBDQPls4yOAgcDguP00cBbwgZlNXVAZdBzHcRzHcRxn4cS7aDYy\nZjbNzM40s1k5u4cDaxBb68zsfaA1Pv7OcRzHcRzHcZxGwFvwGgkz654T9gawYWZ7JKBq8RzHcRzH\ncRzHqYzVeRfNPGTmF6Yl8OhbnyX9UTu8eFJS+mM3/WeSfpP3/pWkp03tdQmfrnlYUtLL1I9M0tv7\nryXpP1953yT9UvXjk/R1HZZJ0l8zdtUk/Y5rL5ukX7L9m0n6ziOvTNK36v29JL19+naSns8+TZJP\nXffgJP0XP0q7H1L55IZhSfreSzyVpLdP30nS1w9LS1/Lp93P6tgxSW+z8zpHFPPPGUfUrP391+ck\npT2+b5q+5/vnJemZNTtJrg23SNLPaNMtSW+W1umn/b0XJOnp3ClJrp6909KfNT1NP+Pr6poMWn71\ntPTr0v7f2V3S0m/z2aQk/f/a7p+kX+t/ZyTpP1jv2CT9Ch9fl6TXUisn6bFED4idl6pZ+sEBJyYl\n3eGGG5L097ffJUm/68wHkvQAS7RbQ9VVTc+Wu1/TpIbM0/89rFleJ2/BcxzHcRzHcRynxeFOVvLx\nMXiO4ziO4ziO4zgLCfPdwJP0hqS0PjuV0xssab95iNddUmFfLEkrSqo42ZykoZJeljRO0nBJ61bR\nXyFp/SqavappHMdxHMdxHMdxamFRasHrDuQaeJLamNl7ZlaL4XiImfUEriFMcVCImR1pZi9WSW8v\nwA08x3Ecx3Ecx0nA6qxJl+bKAjPwJHWSdF9s/XpB0oExfEdJz0uaIOkqSe1j+KaSnpA0WtJDkhqM\nBi/SSFpL0qPxWGMkrQmcAXxP0lhJv5XUX9I9kh4HHostfC/E+K0lnR3zOV7S0Tmn9CSwVpVzGCpp\ns7j+paS/xTw9I2l5SVsBewBnxXyt2ciX3XEcx3Ecx3GcRYgF2YL54mtOAAAgAElEQVT3Q+A9M+tp\nZhsCD0rqQJj0+0Az24jg9OWXktoCFwL7mdmmwFXA37KJVdFcD1wcW9q2At4HTgCGmVkvMzs36nrH\n+NuV5XUAocWvl5ltHNMrZ3dgQtE55Og7Ac/EPD0JHGVmI4B7gONjvuZy7yhpgKRRkkbdd8M1OUk6\njuM4juM4ziJKfX3TLs2UBelFcwJwjqQzgXvNbJiknsBkM3slaq4Bfg08Spg/7hFJECYDf78svXXz\nNJK6ACuZ2Z0AZjYDIGrKecTMPssJ3wm4zMy+iWlkNddLmg68ARwd85F3DuX+sGcB98b10cDOeRnK\nYmaDgEGQPk2C4ziO4ziO4ziLHgvMwDOzVyT1BnYFTpf0GHB3gVzARDPbskKSuZpo4NXKVwnaEoeY\n2ajM8WqdGGW2zZl0sA6fosJxHMdxHMdxnEZmQY7BWxH42sz+Q3BO0ht4Geguaa0o+ynwRAxfVtKW\nMW5bSRuUJZmrMbNpwDuS9orh7SUtBkwDajX+HgF+LqlNTKOSEVd0DrWSki/HcRzHcRzHcXAnK0Us\nyDF4GwHPSRoLnAKcHrtPHg7cKmkCUE/oGjkL2A84U9I4YCxhLN23VNH8FDhG0nhgBLACMB6oi05O\nflslr1cAbwHjY9qF0ysUnUNNVyRwE3B8dNLiTlYcx3Ecx3Ecx5ln5ns3QTPrHlcfikv5/seATXLC\nxwLb5oT3r0HzKrBDTnbKwwZn4rxBGNNHHHt3XFyy6fbLSbPSOfTLrHfOrN8G3BbXh+PTJDiO4ziO\n4ziO0whozrAwpzkz5ch+SX/UEpeekJT+8LUGJum3evyoJL1W71WzdvznfZPSbp3rP6eYHkuOS9JP\n/Kxnkn6ZjrOT9H+//X9J+osO/jxJP/nr7yXp27eekaR/64u0jgAr9e+XpF/53AOS9Fp57SS9Tfs4\nSf98258k6Wd8U5ek7zvyd0n6G9b4a5J+l7W/SdK//NniSfpXPvoySX/gBp8k6Tt8/nySfsZ5t9Ss\n7XjigKS0h6+X9p7d6tEjkvR8NiVJro23SNKP/3rHJP3GHR9J0t/4Rtq7fLe1095tN47tlKR/7d2p\nSfozd/8gSf/x7A2T9OM+ap+k79Mt7Vl56PUlkvQ7nL5Pkn7pS6p1hpqbKe0b1INX5JTb0/6vg7ZP\n6wS10Zn7JunfOrnIbURDWuU79iukQ5u072jXdu8m6e9vv0uSHuBgezmxdNU0bL795U1qyIwcclSz\nvE6L0kTnjuM4juM4juM4CzXuydFxHMdxHMdxnBZHc3Z00pQkteBJekPSMpntfpLurRQnJ420/jsJ\n+alBf6qkBv2fJK0o6bYqcYdKejk6aRkpqWqfQ0kDowfP0vb9ktL6TDiO4ziO4ziO49RIs+iiWZqO\noKkws/fMbL8apIeYWU/gEsJUD9UYCHxr4JnZrmaWNqjCcRzHcRzHcRynRhrFwJPUStKrkpbNbP9P\n0rKSVpf0tKQJkk7PxOknaZike4AXY9hxkl6Iy8AY1l3SJEnXS3pJ0m3ZVjHgaEljYvo9YpylJN0l\nabykZyRtnNH3jPl5VdJRmWO8ENdbSzo75mG8pKNzTvlpYKXMuVwqaZSkiZL+EsOOAVYEhkgaEsO+\nbXHMO1fHcRzHcRzHcWqkvr5pl2bKvBh4QySNjfPZXQFgZvXAf4BDomYnYJyZfQycD1xqZhsB75el\n1Rs41szWkbQpYT65LYC+wFGSSi6X1gUuMbP1gC+AX2XS+MTMegOXAqXul38BnjezjYE/Addm9BsT\npkvYEjg5TsCeZQDQHegV41+fcw1+CNyV2T7RzDaLaW8naWMzuwB4D9jezLbPRq5yrlndgGg4jho8\n6b2cbDiO4ziO4ziO48xhXgy87c2sl5n1Ao7MhF8FHBrXfwZcHde3Bm6M69eVpfWcmU2O69sAd5rZ\nV2b2JXAHUPLv/nacLw6CIblNJo074u9ogmFWSus6ADN7HFhaUsnX991mNt3MPgGGAH3K8rQT8O84\nFx5m9llm3/WSJgMnAhdnwg+QNAZ4HtiA6vPaVTrXbzGzQWa2mZlt1r9HuR3qOI7jOI7jOIsuVmdN\nujRXGm0Mnpm9DXwoaQeC0fRAdndBtK9qTb7C9sz4W0dtXkErpVWNQ4A1gGuACwEkrU5oOdwxtvjd\nB3RISNNxHMdxHMdxHKdRaGwnK1cQWthuNbPS7L7DgR/H9UNyYwWGAXtJWkxSJ2DvGAawqqQt4/rB\nwFNV8jGsdCxJ/QjdOL+I+/aU1EHS0kA/YGRZ3EeAn5ccv0haKrvTwszwfwb6xjF/ixMM1amSlgey\ns0lOA7oknqvjOI7jOI7jOM480dgG3j1AZ+Z0zwQ4Fvi1pAlkHJOUY2ZjgMHAc8CzwBVm9nzc/XJM\n4yVgScJ4u0qcCmwqaTxwBnBYZt94QtfMZ4DTzKx8cNsVwFvAeEnjCAZleV6nA+cAx5vZOELXzEnA\nDQSDtsQg4MGSk5Uaz9VxHMdxHMdxnCpYvTXp0lxJmp7AzLqXbQ8FhmaCehKcq0zKaCYTHJqUOKkg\nLmb2L+BfOYf+xsx+Uik/ZjaK0CJXGje3V47+1Jy0MbM3gA3j+jfAcXHJavqVbZ+TWe9fkO6FxK6c\nOfktOlfHcRzHcRzHcZx5w8waZQFOAN4EtmmsNGO63YEXGjPNhWkBBrje9YuivjnlxfWud/2io29O\neXG96xe03peWsTR5Bnz5jn8gjHK96xdFfXPKi+td7/pFR9+c8uJ61y9ovS8tY2nsMXiO4ziO4ziO\n4zhOE+EGnuM4juM4juM4zkKCG3gtn0Gud/0iqm9OeXG9612/6OibU15c7/oFrXdaAIr9bx3HcRzH\ncRzHcZwWjrfgOY7jOI7jOI7jLCS4gec4juM4juM4jrOQ4Aae4zRTJC3X1HloDCS1a8S0OklqFdfX\nkbSHpLY1xm0lafHGysv8RtIqOWErNPIxlm7M9Jx0JC02n9JdvZaw73iMjpLWraIZKKmPpDaNeewF\nTXN7ViS1noc4q0naKa53lNSl8XPmFFHtWZfUS5LmId35/qw7LQ8fg+fMhaRLgT+Y2Rc1aBevRdfS\nkPSAme2ygI+5VHkQMBrYhPCcfraA8/NfoPDlYGZ7lOlPNrO/5qTTFbjbzPoVHOefwOnAdOBBYGPg\nt2b2nwL9aOB7wJLAcGAkMMvMDinQ3wD8AqiL2sWB883srAL9msA7ZjZTUr+Yn2vNbMp3yX/q9Yxx\nvgFuBY4ws69j2Bgz612QlzuAK4EHzKy+6FhlcV4FxgJXx3iFeYwFhqOB7sC3hfW8vGfibA2MNbOv\nJP0E6E24/m/Oq1ZS7vln8jOmQn62ysn/tQXadYDjgdXK9DsU6BcD/g9Y1cyOkrQ2sK6Z3VshL1cA\nnc1sVUk9gZ+b2a8K9NeZ2U+rhWX2NbhXJI02s00L9MsDfwdWNLNdJK0PbGlmVxbodwfOBtqZ2eqS\negF/zXk3nA1sBfQAJhCe2xHAiErvNUm/Bq4vPXuSlgQOMrNLCvSp75Kk56WWZ0XSPpXSMLM7CtI+\nB7jKzCZWy0cmzuvA7cDVZvZiDfqjgAHAUma2Zrw/LzOzHct0F1L5XXVMmX5aFX2jVKpJ6mBmM8rC\nljGzT3K0G5nZhMY4boX8LGdmH5WFrWtmL+doa3rWJY0C1iB8+0cQnpWnzWxalbwkPetxf0/CtxRg\nmJmNq3QMp+XhBl4LpeBDMhWYkPPSyStcTgVGAf/OvjQlHU/4CJxiZjdUycNrwIlmdtM8nEJ5WoPM\nbEBZWGvgSGBl4EEzG57Zd5KZnV6mXwz4DeFcLwR+DOwDTCIUPL7MaIsKiQLuNbNuOXmcn/mpB8oL\nvSsD7wBmZmvk5GdjMxsf19sCfwD6AC8Ap5eMghrOGZi7YCxpuyraJ8rSfhgYaWYnZsKWBx4C7sgz\n/qJmrJn1krQ3sBtwHPCkmfUs0I8xs96SjgY6mtk/S2lUSf8QgsFwAjDazDYu0gObEYyA+4G7gQ3M\nbNfvkv/M9dwHWAEoFToPAj40s9/mpP08cDnhntvfzF6T9LyZbVKQl52Aw4G+BMPw6rzCRlkcATsB\nPwM2B24BBpvZKznacYQC8QTg2wJx+b1QFmc80JNQ2B5MKOQcYGYN7q9atZKGVDglq2CAXQesSSik\n12X0xxToxwGXEQpbJT1mNrpAf3PUHmpmG8bnf0SFe/NZYD/gntJ/KukFM9uwQD9XIS6+jyaY2fpl\nuh7ABsA/CQZqicWB481sg4L0HyAYLyeaWc/Y4va8mW1UoB8N7AAMzeR/QgV9O8KztRWwZVymlOc/\no2/wXFe5/1PfJUnPSy3PiqSri+IT7rWfFaR9ZMxLG8J/cKOZTa2QFgqtbz+O8VoBVwE3WUGla3y3\n9QGerfR/STosrm4NrA/cHLf3B140s18UpH8a8D5wHeE7egjQzcxOLtCnVqBMAI4ys2fi9r7AP8xs\nnRztMKA94T1yfQ3X8jTgL2b2TdwuVQQeXiHOy8CfzeyWuP1/hMq4BvdzyrMe3xt9CM/JVoR77QNg\neI5BOK/P+rHAUUCpwmFvYJCZXVh0vk4LxJrBbOu+pC/AfcBnhBq824FPgYeBV4GflmnPB24Ado/L\nf4BLgIuB63LSXonwUn+M8FLap7SU6VYD7gQeAdaqIc9LFSxLE1pNyvVXxHwPJBSc/pXZNyZHfwtw\nTjy3x4CLCDVUZ5WfJ6HA9jgwJGeZXpD/+Zmf/yPUOm+UCZtc5XqOyayfQ/iYbQecS2h1KtfnnWtp\nebzKsdoSWhOXK9jfAbi3dE2AtYH/Ab+oku4LmWv7w7g+roL+eULB8BmC4QWhkFuknxjzfiuwXQ3p\nj4m/xwNHl47ZiPkfVUtYWV62Bl4kPLsN7rOceF0JrZZvE2qBDwfa1hBve+BdYArwBKH1Jrv/2Wpp\nVDiHkwmFn9xnJVU7LwvwErFSs0b96MT0R5XfL1XuhWdr0QN/BKYB3wBfxGUa4Z1/Ro5+T4KR8Gn8\nLS0XAFtVyM/InPyMraB/Jkc/vsp9+UPgNOBRQgXj1RX0E7L/F9AamFhBPzH+1vQsluUr6Xmp9qwU\nxNm3Bs26wBmEyr4bgO1rvPe2i/n5CriGnO9x+f1GMKoq/V/PAG0y221L/3mBPu/erXT/jwN+STBm\nNi0tFfQbEXphnAVcT/herlxBvzbwD8J36AZg5wrafxC+6RsDOwMvA7+pcs27Af8lfFueBP5NaKGb\n52e9LE4nYEfC+/B/wOs5mnl91scDncqOVXgv+NIylybPgC/z+MeFlpHlM9ul1pKliIXOzL6ROfFL\nH/PcDyZwaPzgXZN5aVxVoN0F+JBQwL+ntOTo6oDXgcmZpbQ9K0c/PrPehjBXyx2EmrkGhW5iYYRQ\ne/gBc1qoVf7yIrRyrV1wPm8XhM+3/MTwlePH4l9Al7wXepl+roIYsVBSlH7i/XUZcwyorgQDYwKh\nEHFQQZy28XrcSCig7F3Dcc4gtGg+H+MvSwVDglCQuYfQjRhCd5YLKuiPiXm+P16X1QjdUYr0zxJa\n1V4AVi/dK42Y/5eANTLbqwMv1fD/dgOGAV9XuZ5LA8cSCs/3AAcSWo+H1qC/j1CR04bQ0jK5THsw\ncArBwO5dWqrk5wmCgfIKoeWyFQUGea1a4CeUVWLF8J8CB1fIy62EFoVan4FTgV/Fa/9thVQF/Qig\nI3MM1TWB5yrobyPU0I+J987vCC0wRfp/1Jr3qN82J2zrCvqh8X4o5b8v8EQF/ZXxnhhPKExfSOjy\nV64bROhq9iDwF8L3Yska8n82oZJsx7jcApxTQZ/0LKY+LynPSsGx3qqyvzWhwH4Xwdj4A8GAyL0n\non4PQiXr84QWy+UJlbKv5Oj/CfwpXqOdY7y/VcjPy9n7ndAt/uUq9/8hMV+t4vqICvqkCpQYZy9C\n5cZ71Fap3BrYl/ANeCme+z4F2h0J3XtrSjvG+TWhl81bVDaoanrW4/N0EfAUoVL4DELr2gpV8lG1\ngqFMPwHokNnuQIWKUl9a5tLkGfBlHv+40FUiu61SGGXGRnyxrZrZXpVYqMzRbkCojbqJGgpDhBrH\nx+ILbHtCAXw7YmtJmfbVbD7K9jUwqoBJOWEnEwoLr+bsG5tZv6ps37iy7f0I42Py8rJXQfh8y0/Z\nvj0ItacfVLn2r8eX/77lH9689AldPVbIbB9K6IJ4AWUFVzKGP6HF8q64vkL5PRPDj4vLHwi1iXdl\nwo6rch5LAa3j+mLVPmZR15mC2tIa4rapsG/9eD0OiturE43JGvPfqVL+CS0YbxEK008AbwA/KNB2\nK883OYX2zP47CYb4H3PiFrUSvgL8mZya8PLzJtRyvxPzPYTaWn5XiPfA9+L2qoQujPOsJRjhDf77\neO0LC40xv58TKsIKK6Iy+sk5S2GlC6HQ/ATwMaGF4Q2gXwX9MlH3IfARoWfF0hX0j9USltmX16ug\nsEWUYLAPJ3TfHx7vjY0r6BcD/kZoVRkV1zvk6B6M+wcTuv9vRA0tqQQj4ReEb8ttwM9Lz1mBvn3O\ns7h8BX3S85LyrBQcL7fiMO47l/B9/DfQp2xfrlFFeP9fSY5hQU6lV7yeRxEqOm6L64X/A6El8834\nv10T7//DKui7E74nn8Rn4C6ge46uVFlyKmkVKFcS3purAz8gGGu/LtBuHK/pK4SeSr1j+IrAmzn6\nbQm9Pf5IaO17gDAWtdL/+ShwLbBEvKefA84u0Nb0rBOM11GEbvnrVLunMvGWJRjvgwhdda+ioEI+\n6o8jtKCeGpexwMBaj+dLy1iaPAO+zOMfF7r93QscFpd7YlgnYEiZdldCoXJIfEG+CfwoageWaV8E\nvl9jHs4gGI+71Kj/NdCzYN/ROWH/IXa1KQs/EpidE14axFwevibw1Dxe58OaIj+EloANq+Tn6rJl\n+Ri+AvmFwTHED2j8oL1HMA5PA24r02Zbj+4D+ufty4SdUmmpcJ5tCa1spULc0VToHkX4kD4f7+G3\nCDXdG1TQH0sYjyBCAWFMwv29JBUKuFEzmlBIqdoikYnTnjDWrCfQPmf/edn8l+0bXCHdXfOOVSUv\nB+SE7V+g/R/BoUbyc9SYC5WNlEpdzrbLWxo5b0sT3q27Acs0UpodYrrj4j1ZKgx3J7/SaUtCl++3\nyVSyEApy1bqFtSFU8m1Y6Tksi7M40KWKRjHNAQSDYRRhSMFfCvStCWOnvtN9UeVeSXpeUp6VgviF\nLXgEY6pTwb6uBeHb5IQVttDO4723AqFVcU9qqHirMc3JNOzJU0sFykDm7rLbFbiyQPsEoUW/Y86+\nvNb/54D1M9v75D1bZXH2KttuQxiT912uTWtCRctvCIbmaEI570RghwrxRgBnAgcQvun7UqVLcDzO\nMXHZpDHvG1+ax+JOVlooccD3PsA2MWg4cLuV/aEKLuX7El4UPWLwy1bmjSqjL9X8PFVDHv5GcBYy\nc97OojDdnc3skcbUS1Lp2qSkn+edqqXmR9I4iw4HJF0MfGxmp8btuRwaREcW5xC6tgwBepjZB9Hx\nwgtm1qPBgYqP38nMvirYdwXByLsmBv0UqDOzIwv0IwhOIIbE7X7A381sqwL9OAsOI35AaAH4M2H8\nY5EnyqGEFtQ2hGfmI8Lg9uMK9GsRCmcHEscUAQ/nPIc7mNnjBc6RsIx3vex/nONYo5IXzTxPahXv\nl5Q4ku4CBliZE6eCdGv2rJeijfqXgM3K76nodGJkyr2ZR8p/FfVJXj2V7qXwWELhdkVCpUyJL4DL\nzeyiMv12QD9C69dlmV3TgP+a2at5x5XUgVBZsU3M3zBCl8uib8XmhJaCkqv9qcDPrMAJTYyzMmFM\n6VYEI3hpM1uiQPsUoVA7qyi9qFuBMG78P4QubiU384vH/OfeD6nPSy366Agk778VoUWmfUHaj1lD\nb5YNwuYl/xXyBIAVOJyKcVeioROUJwu0yxJaBbuX6Yscy+R5xWwQVra/I6EXUDXnUQPN7LyysGPN\n7PwCfWszqysLW9rMPq1ynNUIQz0ejXlrYzkeLyVdkBN9KqGl+O4K6S9PcG4zkDBkIHdqjDyHRAW6\nxc3sCzX02g2ALWBv3c78pUXPS7OoEr2nPWpm2xMcrBRiZvWSLrbguakWN7jjgLMkdSOMebjRzJ4v\n0B4FLC/pRkJXrcaqLTiT4Lil0fRleUtJP3lOmmacn9aS2ljwFLYjoTa9RPm74OeEroorEFp5P4jh\nOxJa9BpmLBQGuhFaUWYpzOM3EOhPKJzmsbnN7eXu8ei9sIhOJeMOwMyGSupUQV+6XrsSDLuJsXKk\niK7xA3gkwVHNKQreHXMxs/8BJ0r6M6HAehVQF73pnZ/5YG5HcOqze14yzPFmls1z+XoumQJuR0mb\nZOIsTuhGlxdnF8I1Wams8LE4wZlHHksAkySNBL6t1LGcaRLMrEs8Tq5nvXnVRq4EbpP0C4tTKEjq\nTuiK1cClv6SnzGybHENS4fAN3Lin/FcQKkKKMIKnySyjKugbJhAKpedLOtpq8HJnwavpE5IGW850\nFBW4lmAElo5xMOG/2L9AfyXwKzMbBiBpG0IFx1wGg6RjmOMRcDZxigTCs1LJlf3rwHBJ9xCch5TO\n719luh8Q3jErE8Yvl5hG6LY2F6nPS+KzsluF82lANKoXA5ZRmAYim5eVCuJsSbiWy0rKVjwtTmgB\nKicpT5njnEmouJrIHK+5RhjCkcfdhEqBR8l4na3ACEIrUrWwUn6+nZYDWF0F03JEDgXOKwvrT3A4\nl8cykv4OrGRmP1ScIoSc90kmP99OO0HolbMyoUIlzyjvQKhgvzVu70tosewpaXszGxjT3Jg5z8pW\n8VxHEJ7J4eWJZrhX0q5mdn8FDYRWwd0IlZcN3oWEMe3OQoIbeC0QM6uTVC+pq1Vx/xt5TMGl8B3V\njLBMYWI1ggvmq2LN1I0EYy/rPn09wli2k4BrJN0eNc/My3llSDVi5qd+XozW5pqfGwkFv08Ig8lL\nBbO1CLWJcw4S/ucfNji42UOSGtTySRpI6EbyP6C9pEsIhuW1BO9oRdRJWtPMXovprEHlwsHr0Zi6\nLm7/hFAQLGK0whQOqwN/jK08lea8ahMrNw6I51OV+FE+nFAIvJ0w1mIbgpHQC8DMTom/hW63M7SK\nhb1WmfXSf5hXgEsq4EbeIxgaexA+9tk4DaZsiJxSQ97L2aPMgL80GvB5rtNr0prZ2ZK+BJ6U1DkG\nf0nwKHlpeaJmtk38rWlS58T/iljRVtgikaO/Ju7b38xuLdM3MKZKLYrAu3mtijktiufFAuNFkhq8\nLwoKxBC6hGddvA+RVGl+tbqScRfTfUph7sZyuhMKtr81s/crpFfOa3FpxZxWwrzzuYbw/dnXzCpW\neEZSn5ean5UigzoavwcRhilk+TlzWmezLb1fEJxt5NGOMAa5DXOuSynOfuXiRCM/y16Eceq19tBZ\nzMz+UE00LxVSkVMJHjeHApjZ2Pi9yKZ9EKFiYvVYMVCiC8HreBGDiVOExO1XCJ7ECw08wn/ZhzAm\nGDN7NVZq5rExoftsXcznpYTv7zbMXckxmGDIPQCcZGZvVTh+lmOBP0maSahEya28MrPd4q9Pgr4o\nYM2gn6gv6QuhtuwtwgvogtJSoJ1GKNTOZo6L7S8SjrUJYdxTXQXNioSXzNOEj3Khd64ajpfkGn1+\n6qngIr8l5ofQXXdv5naRvA5V+uATnI+cRjDg8hwQvMic8X2rAjOo4PI6E29HGjodKXQNThiDdAGh\nMDSGUCNbOP6NUDjsDSwRt5emsuOI/QleAS+N22sQuj4X6UcTnAwdTNn4HUKFSrn+76W8ZM7n9DLN\nG8zbGJWqbthz4hQ6nGmMhQTPeinaTJwuVBn/VaZvHd9Vq5aWCtr28X/9E8HIPBk4uYI+dQxYTXri\nODUajrm9mhxHCqXnjsQxh4Qujn0z21uQM91KZv95BKcg/WLalxAMprm8qxIK7W0z2+sSDKNcb4YV\njteBKmPeCOMff1/j/5X0vKQ+K4Tv5lnxeR5CzjjzjLZwX4U4qyXq+xIc4nwJzCJUpBWWAwhGRs2O\nrAiTzDcY15ijOyxej2nMPVXPPZXuCWqYloPQnbQfoRySve97V/r/SJwiJO6vedoJgkfSrpntrkTn\nOczDN/27LiQ6bPKlZS7egtdyuYOGXYVysRprrrMojLXahdCKtyOhAH5qhWO8J+lKgpe64wiOR2pq\nAWnmVOoW0RR8p/xYWetq7N64BeF//lHZvu6EWueDCJUDqxHGPr2Rk/QMi90RzewtSS9bhbE4mfw8\nJmltQqEPwkevsMbYzD4nDAqvFSMYp7sBfyU4FmrQqpJJ/1bmdKPBzF4ndKcpYv+oyUsrbwzXLmb2\np4zmc0m7ElrBS2HdKxyvAZJ+Ymb/AbqXddkqpVfepQ1Jt5jZAcDzBa08DcblSOpL6Cq0HqEVoTXw\nlTXs4pjlYIIRXuoa9VQMm2dtpoUKwpiv8zP7BptZ/7zEJR1NaIX8kLm7nBWNQbqb0LI9mkyX1Jx0\n52eXPyy2KAJHWtk4oTwyz93SwH2VnqcyNgVGSCq1GqwKvKw4hivnnii1tpa37G7C3F1THwSOAF6N\nvQWeJrRy7yZpczP7Y1GG4nCEHxDeQTsT7olbC7SXEa739gQHV/sRnGeU65Kel5RnRWHy7tI78xNC\nK5AstvLm5CWpdTbGmdcW2osI7/lbCVM7HEqo3Cvia2CspMeYu0t20fu31Io0i2BAFrUipba4lpgo\n6WDCUIO1Cd+BEWVpv0lwwLVlQroAX0lamthCHN911XpHPSHpT4TnfmfC+NX/Fmj/SbiWQwnXZVvg\n7/H7+2hJpOLhAKVrWd79uYeZTVLBOGBrOP43uUuw03JxA6+FYmbXqPYBx6XxLKub2WmSViG4hc77\n+O1M+DjtSvg43kRwrFDkJKMDYazKQYQ+4w8CJ5A2hq6cNxa0Pnah6UNwIPJwKdzMfpOYdrPPj6R2\nBGPuYELh6XbmdsaApKcJL/2bCDXdr0qaXGDcAaxcVljtljJd80QAACAASURBVN0uKhTkFGrWkjSV\nMCdPA2cekv5Lw25aUwldqP5tDQfoX0IozO9AMPCmEc5384L8rANcSvBIumHsfrmHmZ2epycUzA6m\noWOBvxboW0tqXyp0x2c41/FCAqUxiJ0rqubm2PibMj4ntYBIvF/2rCXxBO22mfXDmHtcTaHDCMI5\nr2tVHCdkWNnMGnRTziHb5e8c5hSavuA7dvkrY7KkBwlGQy1jnncHzpX0ZIzzoIXxt0XUcq7fUmS0\n5LCkzXHschihG//R8T00muCafi4UHMUczJzv0NaE+SO/rnCcrcxsY0njzewvks4htEKVk/q8pDwr\nkwhd73azMD4XSZX+0+1IG+8Jc7qnn11DfuZO0Ox/muNQ5GpJz5Nz/SOlqURqTTu1Inm1HAN7KmGq\nk7E5+qMJlcYzCcMNHiL0KvkWpY+3LXEc4VzXlDScMO1Ag+6uZZxAqLiYQOhqez+hYmEuYvnr4bi/\nTwz+k5mVHCYdn5HXx3zfQDAWp1fJw3GEcYB544CzlSwlsl2CRzP3u6qoS7DTUmnqJkRf5m0hfBD+\nv73zDpekqrb4b82Q0wgCgkoSEESCIDyCPAUVFUFABEkKIiomBEFFTCDyQASeKJIkChIECUpOEiQJ\nDGlIAzgkQRGegANI3u+PfWpudfWp6qq+3ffevnPW99V3u6p3VZ/bXeHsvddeeyqhwSpe6xPt6YRP\nWA9nqPfd/ESan4f3/oRn3+o0oj0VVxk8E89ytPVAiuyzCEFuGb+Jbk61zH1f7Mk1IMbFYm7HI9HX\nAd+t+RssFY6//HDtR2I8wEdwWtfjOB3rE8DDJbbn4tTJXxH6LFFND9yhaqnY7wK8NuKssPwf/jB8\ngLic9S/CefeJsPwWd+IOx0VUivZZ0+Y89aaqB+HV+EM4b1/V6DybcH8Hl6bfA9ijwn5PPAuxU1iu\nBb5T5/cd7YVAzSVHQ6IDvQh3es7B7xP/DL9xWx+xJraF36bYx7OKEnklDWh2eE+plRrYt/2OeFCt\nif2uFfZz4bWhZ+NBm18Rkcov7DMr7kiegmc2jq3xfyxMDQprsO1IiSycL9eRk5ePXYt4r8XrcUXd\necO2h2qMO6PM3YhPYGcHHiyxnYjXBNb9bSdSaD9UYrcZHhR7DDgGZ7/UGXtpf7+KfTanQxuUgv01\neOb9JDyj9M3Y91/YZ05K+sVGbIXXRP8wrC9Goadfwf5UvNbtkLBMxecSN8eujX4vdNEipMGxazcR\nx8VYfoyXIPwWD3L0lEpPF5TgtAzeMuoDSEuXP5xHXyZRYyJKw0luZP+5w8P2gsL27SmpfyHSYBaP\nHj0UJidfwYuTjws39p1G0r7wXdwMLJT7X6M3Y0Kz7/B60/BZJ4Tjf2449iM0njdwB2ap3LYqp20S\nLh5yaTj2M1Q/sBfCMztvKrOJ7HNJ/lwB3hK2LRA7n4kEJhiqn7g78t5f8MnZrbkxljolNKzFiI2x\nxv+8IR59P5iSJucNj/fLqqVkn+l41La4lNbn0t0E8bJwDs0Sls8Blw3HlqF+cLHecFXO+3G4Q70X\nuf5wFfb34FSzqXhd5hSq++zF6ueqGq/H7GvV44T/+SQq6qJztrPiwZCzgacr7DbBAysvhOv9jdg1\nlbM/KozhMTwYNYVIXzJ8knpwOF+exMU4wFVZYw7eofg9/Hw8izc3Ffep3H4/DMf8FPAPXJH1JxX2\nN3U6ZsH+Ckp60kVs5w5jPy98n0dS0X8TD6b9GncIOzaBD/ucgDvtJ+PZxUonAKfYz4EzM/bG6yWX\nqbCvHUQO79cOJIf3ryFX44dnVK/Gncp7ctvPYyib2LaUHHstcnMTvFZ3zYjd5lVLybGn4PeD6FKy\nz29wxeja51vYbyuc6vvtDnbFfrJfp4OTijuyn8bncdsD2zcdX1rG9pIomoOLV83sObUqvpepA74a\nahk8zOb9aqqUBGvR+MzspMI+2cN1W7xOpyiN/3U8QjYn/mBaxry32vx4dL2oWNVP+7xS4UQzeyr8\nTy+UKMGBPyAz7In3aHpI0oL4w//EYdiPxHhWwyl2l0uahkeao311wmc/RxBzCOpgW+GUr8XNbLG8\nrbytwP64wM5Skr5kZnXoPYuZ2ZO59X+Gbf+S9GrEfp7w+Y+Gz12cIapVrF/WL/Gs0MLyvo2Z6msZ\nnpa0NEPXyhb4RLEM10taycyq5N5bYGYXEaeOdYuOtY6RMTSuy8WDPBPw6+ybeIS+qj4RPFBxQm79\nRLni6nBsJ9FKL7o1YhPDo2GZLSydsGGdg0paHr/vTCpQjucjUu+p7pX+MuriVjid8hZ8glZmu2Gw\nXQ+voT62yh6nu62Ft+BZVdL6eEamDHUpkV/EaY5L4k5ORrNcgQjN0Mx2C7TG9XDq/8/w7/bTwIVm\n9nxsMGaW0fXOknQ+ziipqqO6TtKv8Ax8vg1D2fn0PDBF0mUF+zb6uXlJw6nAqeG+vgV+j760aBuw\nPO6kfQ04Loz/dKvoR2tmO0qaFT9PtwEOl3SZlfQQxR2FV8xp7D8Oc4Iqevg+dFCtLGBNM1st0D4x\nry+uus4WprW29VU82PcfuRpkhuwc2Rxn6Pw2rG+DBwxiOJLWdgsvRLbBEDV2YbzE5E9hfX08ixyj\nyGZU3UwRNa/obCXjWRPYTtIjYSzRmjqY0W5oa1wM7Rn8XntOyXEzHIk7eUeE9c+GbWX9ZPfGr68V\ncOrohnjw66SYfcJgIjl4g4uOBcc5ZJPct3Sa5Er6CH7j/AjuFJ2ER56ikuGhhmhTfMKyKj5J2Yx4\nr5zXwsP9RUl/tdBbLTwIYjfGftrnJ4kmaVEz+7tcdr2sbUH+GLOZ2UPh+E9LijnMTez7Ph7zuobb\nge9KWgf/nWeVdBFwjpn9uuRzMK+HO0zemHyXiMluOBX2qTAJOIV69RtXhclMvj9Q1tvu2Yj9HsC1\nkv6Kfy9LAV8N9r8pGpvZKZImEyLjOD3s3orxfA2PpC8v6XE8k9E2ydVQ8+BZgB2Dw/wyFQ/usF83\nQiWVsCC73wTqouGtDcmtv4RTiOrg/yR9Bq+ZAT/nymrgatlaQxGa3H51x5zZZz32FqZCmAcXCNoY\nzx7la6mm485NEdfjQYMFaa2dmY5nAaKQ9DCuZnwGHtGP1kXnsD3uvOxs9YRWXjWz/5M0QdIEM7tS\nUrGXWB5ZfdCLkt6K/1ZtfQvN7D/ATyPbs354bTAzI6grBicmE1o5Av/e2iDpa8ApZvasmb0saS5J\nXzWzI2L2hBYmeG3ujI+mvW4pQ0dhM3nz9wVDECf7X54J95LvlO0XnltnAGcEh/AXeDarNAAX9ns1\n3L8ND2xuRsmkHg/6fRh3VAn2l+KOTQxNgsjQPJB8CvAXSVmj70/gDvHcePYcAPO+jkg6xMxWz+1/\nnqSynpIK51B2jDfkwnEtyOY18lY6K1ho4yFvlXNi7MC5+8IG5v2FM+wp6Va8Nq+Ij5aMs3XQ0tX4\nHOoMnM2Q3f9mk7RA7L4c0LSf7Ba4SNJtIVDwFoYc54Txgn6lBtPS3wWvx/gfnM53S3hdWgOHRwi/\nFpZ3VdjVpvHhEcrH8MzYBvjD6KGKY08m0AbI1dbgk6cYVaev9hXfa7RuBle4y2hsr+BCNeAT9TZq\nRlP7fo+n5BgTwm/XRq3K2UwkNArHqU+/j9jcWrVecWzhTt3Pw7IFJRSlMNZ18KjzKmGpU/dZWxo/\nt8/cVMjv49nT0qViv1uAZfCJ+kT8IX5Ane+q4piHhr9RKlPJPueHvw/R3pKh7Hp/H06jvD/sM63M\ntvA9/RF4Kiznln3/TWwj+y6NU/SqKIUL4bL1F+KR+j/hYiVl9k0pi2sP53es8T/O18U+SwAfDq/n\n7HBOX45nww/DnexfUNGmgpqUSCrobHS4T+H3spWBlcLrOSts26jUjLAEfTinlij5HUrPtWDzAdyB\nnYZP8CvbOOBZlxNxOuuJdKjVKvl+qujnx+GB2zuBZcN5cVSF/Xbh+v0bPh+ZCny6w/+wBp7d3RVX\naK6yvRcX2snWlyLQQSO2Z+NB71nDsiu5kobYsQvrE8qOnf/u8N522fo6Vd9nsKmsbw2/5Yz7cG4p\nvS+H/W4Fls6tv4PqeuSbwt/JONNAwH39ui7SMjpLyuANKMwjft+XdKCv2vQOu8yFTyizSF8ZmtD4\nVsApBPfiN8PXSzJrGQ4Nn4+Z/S23/c14D50Rs5e0M3CiFSLbZvaipE1oVebLsDFwiYU7Yw5zEZfu\nrm0/QuOJYSmclrVW8Q01U7Irqmi2rFuExhSivZebq/F1lMs2j8Iebh41rYpO5j8jL43/OiHDRona\noqTZ8QnrknjT8+yzW1QxLdc8WC5RvW447nVWTvHK9m2iZFcHjVX1rLuGt8fhdKHJVDejz3/OI7ij\n1FNbgJA12go/R1cCDsDvXWU4Bc9obQx8GRcAeqrCvhZlUdJ3zOxnwLaBftmC4rmv7pX+FpF0DjUV\nXiV9EVfYWwB3gN+O0+w/VHL8TfHs7DfxyfokWrNbxf+rLiWyqTJgNv6Nwnjz2fqdKac3T5Q0I3MT\n7i+VVNzwGe8ml6EtXus522Xxc2yFgn2etjivRRqLm9kjcup82Tgepll2FppnaF+QtFp2f5L0Xqp/\ni7xq5alEVCvzsOZsCXDH5HECm0w5+n0E38TZHdPC8ZfAz4cYvowzl36An3tX4NdCGa6QdAlD7IGt\nyLUvKMFOwPGSJoXxPAN8PmYYnuGH4IHGf4ax34ufezNgXbITcCXOKwvfTZR1FXCLvKTmGPx+/jze\nviRhPGG0Pcy0dLfgka8peMTnYXzCG20sjaubTcE59T8Otj+o8Rnr4FG7J/CH6pciNpni0304h/sp\nIgIrwfZ1nHbztsh7McGBvtnjD7a7gffUOXbu+H9qOJ5a9iMxntx7b8UfljfjE7q9KagF0lDJju5V\nNGsLFwT7g3EHrK4QwYPAmxscv6kqZnZt/bjOtUUXQiVNFgoZj5r7bI4LLhxCTuEwYveXLsbTDxXN\nL4Xr/H48cLNy1bmZ229y+JtXdawSgchUQ+8AJmSvI3afqLoGevjbNlV4vT2cD3n72mp+Nce0Du5g\nVwo10IUyIP5MWSa3vjQVWQY8O3sG7mB8KLw+pMK+lkhMzv7acNw78Qn0PsC+BZuoameN9xpnZ7v4\nrdbAneU/h//lQUrmDMG+ral8bFvuvZiKcdu23Hu74HWBd1NDxCjsk2dv1FYQrfn9bM4Qk+STDfab\nRIdnWLiHvJmhpujrV51rXY5/9nAvXLnJd4MHM1fu9/mXlpFfRn0Aaenyh/Mb4n/n1tctuzniVIk5\ncutz4g2l637WBLwmr/KGhDfKPRgXMmij9uARyi+GB+oWxfdG0j7YfgR3jr/V6djjZDy1J8Z0qWTX\nxXn8h3C+HEcH5cdgPx3PCLxCB9XHYH8lzaTxG6liNr22aKhk13AsG4Vz4SrcGXgUb6xetc8ReB3O\njmG5GDi8YLNaWH6KT6LXzm1brcPx+6Gi+Ur4/1bPbaujsnhj+HtJ+K5WBf5aYd+Istjgd1qgaqnY\nr6nC61/y9uE7rVIB3RynpD5X89o6GQ8CHRG+o8Oqrt3cfnWVAW8urKu4rfD+BFw9OVMS3JmK9gPZ\nd5H7Ow/w5wr7LEAwpbgtt34UTk9UYdz7Ar+OHPM74e9h1FfAvTb8LSrhVv5eYZ9ZcfXEjq0AiAct\nqwKHxaDlRHJqmBH7RsG3sE9lQKGb77PbBXeotsV7XZa2CQm2tYJFXYxhWfwZehd+j2oL9tY8zjuB\nY3r5/aRl9JdE0RxcvG5mf85WzOxalastPoFPKrMm0LPjtIhaMKfGPUwH5U0zmwxMlvRt3OGMmNgx\noZD4lECP+Zo55c9G2N7M7FJJqwPHyhXnPmNeZB079ngYz69wGsa2ZnYLQBml1hoq2SnegDx/vDLq\nXUfhgsJxmqo/TsNpPReQU2wzs/8tsW+qitno2rIOQiWSzjKzTsqUZTgEWN+GGiwvjfcZrFLs/CBe\nk2thn9/gEfXicfPICx0Y5aIU0B8VzUWBLYFDJC2CZ2pmrRhDhv0CnWoPfAI4H9WNxWtRFrs49ycH\n+5h4kuH1MzE0VXi9WtL3gDklbQB8FadIluFneDayE60uw+q4MEXp/55B3SkD3iLpQvz3Nfw3v1lB\nqdTMWu4b4Tl1HO50voEHWqqoxLVEYnJ4WdIE4AFJX8ev82Kz9D3wYNWDkrJm3avgtbcx8ZPsuy4T\nC2mDma0b/ja6F0raEm92f5ekHwCrSdrPCpTy8Oz5OPC2Au1+Przuu3jcvXAnZ05J/84244GYUuEu\nPBhVpXJa/JyT8Szu7QxRxI1W5cfG32c49ubAgXiNnOhMlwZ3rJ7Dr+dOFNln5YJp1+DP6n+SU2Id\nBo7H//9rcHr7YXigJopA6z4YZ/Gci7e1+BWu8hlrlp4wwEgO3oAh1PuAP7yPxqM2hkdFryrYHhbe\new5X3bwsrG+A11TFjt/oBhAe3IviUdBX5Ipzu+HR92KbBADM7H5Ja+NZpNskbV/1P/fT3syeBjaT\n9GVc0atqwjfo42k0MQ4Ttyupp2SX1X8J5/WXKbkVP6MbBcj58chlvg4mptoKzaXx1wU+J+khaqhi\nUnJtZRMji9QedkCVDHknTM+cu4BpeFS/Cg/iBf+Z47lY2DYD5jWSSHqHmU3Lv6dq2XToj4rm/+GZ\nkqMkvR2/9z0p6V5cDfZ7sYOb2fnh5XM4RaoS1loHVXWe1q59DMdtUveYR0zhdbsK++/idUJT8GzW\nhWZ2TIX9kw2cO/CswSJUO5nDUQacA6+d/UBYfwrPkH8Cv9ZaHLxYzZ6knS2naFnA+aEO6SCcOmp4\nK4ky7IrXN38Dr0X7IE7DnYFwzmwdrousvuru4nWTs88c7hfNrFiXvWXFWJB0spl9ttO2HH5oZmdK\nWhenmh6MS+mvWbB7AneQNqG1Bct0IgERMzsAOEDSAWZWWkss6d1mlg8eNQ2+dQwoDOP7bBrcAKeP\nf6ymbaP61gaYN3dNHyRX8azCMfhvfgPeauV2/N62nXn7jIRxBNUIviWMIUi6suJtM7MP5mx3qLCN\nTq4l/YXWG8D38BvAj4o3gBBd/z4+IZwdn/gfSKgvCtmnvP1t1iorjKT18CjUQsWIZD/tS2yXx4UY\nVjSztv5Agz6egl02Md4Gp1+WTowj+85pLn0ezTjFxlVxrDrCBXn7L+ATrbfjD6e1gBvy5/1wIGmJ\n2HaLCCcE+8bXWIfPv9XMir2aOu2TRWw3wCmg+YzHo2b21cg+WdZpEl6bc1NYXxNXWFuvztgkTTaz\n91aMbQk8qrx2OP71wDcsIqTQxLbks5YFtrGCSEYu0BXDy7hDcIoFoSq1i5/E7L9vZldExjAbTncC\nzyDFejnm7TcB3h9Wr8o5oVX7zI3TvKZL+pSZdRQoyu37OzPbqrAtO38+gDts59I64S46Utm5My/e\nauCmgv0mBfuHGfo+899rFjwZTlAj/zn3ARsXM9hmtnyNfWenc9+8OmNYGH9mLoM71geY2b+r9yq9\ntirvBcX35W0A7jSzFUrsbzMXCzoAp5meWnWvljRr1fkbu/dXITLevWN2VtLORNKZ+P2gMqAQ+6yy\nbbn3rjOz93U6bmGfXwOHWYMeqL1GOOe3YYgNcApOGxVAJDt7u5m9J7c+rVfXX8LYQ8rgDRiyaHpN\n28bZEbw498TweqqkXc2srH/Pl4DlzJtSL47Xdr3PnKoZQ9uN28yukqt5xdSw+mnftr+Z3SfvU1b2\n0Br08eTt/oZnZA+R9E5y6oPy/j6XVeybV16LPRyaRI1OwGvRfo5nVXbEa2nKsCvukNxoZusHJ3j/\nopGkQ81pplH6XGQSOl+YiHXKeBWPU3mNNZ0EdYl877VixqOsf1vtrJMaNvIO+8xvZs9YDWXMJrbB\nfg3gMQt9LkPG+lN4FnKfyC5VdK1Z8P/tbNxBrqS+yZUZV8RpVuua2bO599bDg2EP4xOsxSTtYCXZ\nZUk/xc/lU8KmXSWt0ynQYq2ZxZ9TQ4E2h7Uj2/Lnz4t4LfCMj6OdQt00Y7lkE/sM4b50JDVVQ6mZ\nwS6cw8X3qhzaKAr3kpPwrNdhuFrrL3E2S9nnNaJDhn26pUQ+Lmf9bAAcGJza0nttp+AEzdkGLZTk\nzJGTNJfFlZmLWBC4R1JpQKGb7zPgFkm/o0Nwo4DabA91RwGtg7/jddwZ/pFbj9Hn55C0KkO/xcv5\n9aJDmDDYSBm8AYUKcu7Z9mL0Oti+D5/4LBFsSyOnTSJCkYjcHdbabDNhANEki5TZqrVh9pV47d6M\nB7qV0LCyDJCkKWa2Un5bif3NZraGvL5lTfOGxneb2bsLdu81s8nyVg9tsNA8N2d/vpltHB7Wxfqo\nrrMMTbKZ3diPBCRtijdQ3oTW5vXTgdPNG1YX9/knLqRxHZ6Ju87M7i85fm3bYH8r3tvtX5Lej7dy\n2QXPJr3LzLbo4n+8CHjAalJq5RTqLxXuf5Px+tapYf2dwGkV5/KduGruG2F9Ii6IUkYHjh3jMTNb\nrIH9o2a2eF37DseaG/iPee3bO3GlzItqOAZ1j381Lv9+dHZNSLrLzFYssT+SSAabIHefTdYlnRDb\nP8DMrEXqvuwektvh6pxtyzOwRhZuFfy83RcX6cgwHbjSzJ6p2LeSEhmxnwtn5UwxswfkzbxXMrNL\nw/vzV31e5HiN2AaR+cLaeL3iPGa2ePgudrYI4yDYd7yXd/t9lpwTbedCYZ/abA9JD9KcAtpzqAED\nLGHwkTJ4g4smBb5N+lc1iQgVe58tqg69zxIGAjHxh04oCkfkI4FVwhF1hAvy+Ju8buZc4DJJzzBU\nPzb0gUNZ5OeLGWVJG0fsS/vCSerm+5hx6Mjx5sSb3E6N2O/Z9AMU+rCphIoYuw7VoBebmf0B+IOk\ntc2sVq8kM1s4TPrXCcsekhYCbsQduJ91YxswMRcw2ApXJzwL78d2O13AzDZU5/qVvP1R8t6Vecya\n/03Na2M7ib+8Ccj+l0l1Pz8/lOIGDdVpt71FRc2tpJ/hdbz/wdVUVwa+aWa/LdnlGuC/5TWxl+Jt\nV7aiui6wCeYys5sKl19VFqZWzZ6ZVfUHa0PBgehIwQ3fRzboifn1YqDLzO4A7pD3N3zBgihMcPbb\naPkF3CRpkgVaabgvrmdm55b8Hy+Sy8aaUx3zdMcrcGXckcKheF33H8N47ggBmyiKQbkSm+z7PLVJ\noKHJOZELZjZhezStb20ESV/DaebPhvX5cbr6EXk7a8AASxh8JAdvcNGkwPc5Ky80b0HDG8C3C+tl\n1MyEwUKTtH42celWOKIoXLA+BeGCloGZfTK83CdEIyfhk1EfTHsU+hhJ25vZXeH9bXARoGitk6R9\nzexHufUJuBx8Tyatkj6BU9xmA5aS9B68l9Ym4f+7tIvDjpQS34NyVcYlaWUNRKPcIQt3P66GuTRO\nndoVpwD+rFtbfNI8i5m9hotF5BsYj+QzrXid3CLpWLzPG/g5U/WbHICLIl2JX0fvx4VRWiBpSuSz\nCPu8JbK9Sg3vvor3PmJm35H0SZxmujnuxJU5eDKzFyXtBBwRggx3VBy/KRqphjZ13OSKqnszVAN5\nNX4tRuvwVI+CO4nW4Ba59apA16XAh/GG0+CO6aV4wKMMe5vZDCVSM3tWXtcWdfBqoGkgq6n9K8UN\nZvZYwYFvC0BHglD5z28JRuWwpLzWsLK2uywolrOPBalrq+BqiA7cDQW0Cb5oZofnjvuMpC/iught\nqOsQJgw2koM3uGgi536lpIPw6F3+5tIWsZY0H17z8EBY3xJ/2ABcYmZP5vbvpsYvYQARMhErAo+b\n2T9zb+2Zs5kFb99hkhbDBTseNLPSrIqZ3RxePo/X3xU/9zAz26Vk31hEtxiF3gL4vaRtgf/Geyd9\nJLJfhsUk7WVmB8hp0Gfg/Qa7RXESsA/erPoqADO7XVK3zjHhGJly3O+sXQipqHZK4f0Pm9nlhW07\nlFzbf8CbJF9OByaApCwbtzauzDkNz8h9hsIEuIltwGm4ivDTeLbpz+E4y9BAdr0P+AqudJlNCv9M\nyQQLwMxOk3QVXocHsKeFusIC2jLOVagbpFN7rW02H9gIONPMnuuQvFag2W2Hq3VCdf1sUzRSDVXz\nmr3jcSXQT4f1z+I1wWU1eofgTnALBRfv/wp0X2+IC7zMaD1jZs8HSmUVYt/1cOZ0Tet19oTKjLEf\nNMwzzGytwluPhWvfwvNlV4aCVfn9m7bGgfq13Y3aKYTxNLlfN61v7RYTJclsRrubiVSrRjdyCBMG\nFDYGmvGlpfkC3INHxKbiTc+nUN7o/MrI8qcS218Dn8utP4gXjB8LHFWwXZdco1G8ueyfwvLB0f6O\n0tL2264BLJJb3x6ftP+SXINl/KFzFPDusD4pnG9TcArlNpFjfxGnmj0aXt+P10ZNxSeu3Y65tLFu\niX2swfs7w/gvBubssL+AU4G98Aj6bjU+c05cbCj23kcK6zcWx1l23XbxXd0JrJVb/xRwf4d9rsEn\nxXPj2aDzgN+X2JY21Y7YvoFPnrbDqXY9sc3tsxbeU23uwu9c2Xi96bnTxbk2G7ASNRpJB/tN8Izu\nwXiNznB+/xsa2hcbU/8Uz/DdhlM5FyI0Sy/Z//04vW7PsP4OetxMOhx3blwOvpPd1XjwJH9t3VVh\n33Y+V53jseu0uA0X0TgUZwjsD8xX83+8Ln/u4k5j5e+JO6j/i/eGWzq8PnEY3/Ot2f9UskTnGOH6\nvZOhZ3/HeUbYb0G8xv9J4J94pniBDmOciLdfWjxbSuw6NqXvwXl5Fs40mNDL43Y5loPwYOSHwnIG\ncEiF/RSCBkfue717tP+PtPR2SSIrA4omBb4Nj3sb/qDJIkEzRB+yup2c7RXALmZ2T1ifgiuGzQ18\nz+pTSBNGAGogTqGccIm8HcZ6ZraZvH/eRdbenuFu3OGfF4/CLmFmT4co9M1WEEFpMmbropA/Qmtb\nGM/uvAxgBSGLQhR6VuBofNJ1XLCP1mflKZdm1ka5zO7jDQAAIABJREFUjNgfh2cZv4s7YN/AHYEv\n1/0fyyBpJXzSdxU+CXoz8AVzxdSyfYQ3Z87qyX5kZqeV2O4HXG9mF9YYyyIM1dT9F55ZuBVvv3KD\n5fqCNbEN9nlBnzZYeV+1TmP+nJmdWPf4KvRwi1H4gB2svormNvi1UqtdSeR4wxb0Cf/7c2b2ulxE\nZV4bUiutVNeNHL80+15z/zfjWZh18Wv5WvzaivZR1JAAU/6Z1SILX7C/Afi2mV0b1t8HHGxmMaVR\nJB2POzN5Cu5Ey1GUJV2MU/iuwTOv85rZ52r8r2vg9+Mn8HNnEWArK1ekzkRufohTOwEuA/azVpXV\n2tBQG4Xb8e/7VDzgk1dNbptjhOfDFvj99XS85c7zdAFJu5nZoSXv7YKfD0/iv0MYTlS18nr8vMmC\nzo8DPzWz5UqOfRmwpbVSFk83s49WjPXDeGZwLeBM4AQr1FUH5tSDZnZ0YfvOwFJm1kbJ7gahlGBn\n3LkDPxeOtVDTGbE/CBckysa1M65MvEcvxpMwRjDaHmZaul/wG9iO4fVC+A0jZvcWfKJ6UVhfAdip\nxHZKYX3F3Ou7Cu/dXFg/O/f6utH+ftLS9tvekXt9OLBPbv32gm0+Cn4BrVndWObittjnlNk3GHPT\nDF4WhV6iaonsF8ty14lCT8YznPn/f0qF/VzA/+CCFLeE13P08DfeDC/+fwJYpob9Ani092KcrvZd\ncpHdgu10fGL1HyBrKfHvmuOaC/g6zgh4fTi2OFVvWlgeKizTIvbn4Zmm6FJx/Ifw5sTTqo5fOBeW\ny62/k4qsAZ71mJBbn8gwsrndXitjxT6y/2W4A7NUWH4AXF5hfxGeycruAVsQnnkl9u8B7sAd8kfw\nzOXKFfazA7vjDIezceGy2Qs2xXtf7e8ADyytSM3sbxff58lV22hlcSyPt+G5FXdoPw7M0uH478Db\nN/wl3FPe08UYH61470HgzTWPswYu1vV2nK55Njl2Q8Q+ls2t9dzC7/9fBh7DVYB3zH6/cE9ou5/i\ndNHS7HK/l/D5X8Ed4N/jDt7E0RpPWvqzpBq8AUUopl4dWA6/gc2K34hjzTpPDDbfD+v3A78jZCcK\neEPSIhaitjYkTvE2hqJmGd6UXzGzfO1CrPg/YXTRRJziWbna5OP4ObUTzKizm5N2zCnvpzMBmE1D\nvXVEeS+2Oui28L9pP7tu1cVetfZapVJahLmS3fcZuhZ7hpAdXBpXP3wncH7IohxesduNeGT7eLm6\n54F45rJN3MEa1MIEAYu1GcrMrQo8gDtb13VrG8bRtGYx69sm4BjgC1XG+eM3zIqNhormSGI4arLd\nYFEz+0lufT9JW5VaN6zZM68NXiXUnWMdGpKbt2T5FZ6BfwNX0WwTDlEDFc0ClmNIFGQ1eU++k8qM\n5Uqz38H7OOaFRMqk7outZCbSWj/4r9zr+/Bs2d7hOz8JvzccVDYeM5sm6Q/48+Gz+D2oqapt1Tn2\nGDVrbK1DbXcEr0ta3MwehRkMqY70tpBl/gz+/96GZ+PXxYXC1sMDAG3HMW8tMuzrSdIZZvbpCGMl\n+5xoyxXz1ixHhiVhnCI5eIOLT+IToayA+QlJZROwBc3sDHmDVMzsNUllIgkHAedJ2oMhcYnV8ElS\n8eZ+n6SNzOyC/MbgGMQk4BNGF03EKXbGa/MWwevQMvGHD+EZvSLy7TXyrTWy9W7xizDGurS8jKJS\nW+ksHH/3Dsf/35K37pYLuEyUtCxOuWzrC5f7nFjT5OfwbN7RVhBJaYgpOCXTgIckrUnr7xDDh7NJ\njXkD+2+oQqo8TFaXpXVCGaMgPkigWOI9qW4Ox4+hiW1jWKvM/fNWQ249v3sD276oaDZA0wnjww3t\nR7qe41JJW+PZIPCM3CVlxuZU3g8H6uIEM6sM8hQpoJI6UUA3wmuT/4p/10tJ2tlaFaonEbI2uW0d\nVTRDwHY93MG7ENgQp6SWOni4M/E7nAr6ZdypeCpy7MaN0UNAd2t8nvEMnq08p8T2HcF2U9wJOx3Y\nv8truOocmwZcJekCWsXi2u5xklbHg2hL0Kr4W9Zj8vvAtfLei8IFub5UYpt9xjm4U34yXj+bKbz+\nTlJ23f9H0rIWROty+y5LgfraJXYNf2sJMXXrECYMJlIN3oBC0k1m9l+5mqO58XqVGB/9Krze57Jg\nuxZwoJl9oOTYH8MfCO/GbwJ341H+iwp2y+CT/esZeoi9F4/Cb2wVzYoTRgfht18UuNRCrYZcDW4e\nK6kz68FnzmqFnkQljs4MWKGGTa0NyBdlqFYlmHfXiDx3/L2r3jezH5fsNxc+OfhIGM8lwE/KHDVJ\nv8Dp1Fmd21Y43dFwQYbPdvUPDB2/qsdezF64I/IOM9tX0uK4EM9NEdsv4BOKt+OR+bXwe07H5rgh\nS2KdJt1NbZtCw2zO3MF2djyLlNUp/xlvH1Dap1TebDpT0bzJIiqaktYysxtrfP6KZnaXpP0t1PGp\nYd1ch+M3/e4a1QRG9p+O13NnwciJQFZfZlaQxy86bHSu2buM1jYQ2+G1xh8usb8Pf649GNaXBi4w\ns+W7+w9bjj0FWAWnBa4i6S3Ab81sg4p9JpvZeyXdmT33FeoQS+xrNUYPTs68uGN9FtDy/RWzkJIy\nkZU/MHQvy9v/b8G+qu3BnGYWTTyU3aNj92ZJU/E2TlPIMY+sQqNArjicKX3eaGZPl9kG+49boR5Z\n0uz5613ShrhI3X4MtZFaHRfx2q24fzcImdjL67BQJC1qZn9XnzQcEsYWkoM3oJD0LTySvgEeCf48\ncKqZHRaxXQ2/yayI19ksBGxhZncO4/PzUvLbMUT/uDuMYziZiIQxArmwQBuspPdZbj8BHwS2xSdF\nbym8nwUXorS5qixLnYmjpOXN7D6VSHj3y5nthNgETEPiEDOEbbo8diPBl7DPkfgE6INm9q6Qobs0\nNkkMk9A18MnPeyQtj0fqy2Tls0j6CfiEUcCzwOctIh7RxLYJCtnfK/FMyYwMS2TCms/m7k4hC1qR\nzc1oc5hZWyalYDcLnqXJnIN7gYvN6dNF2xmOlaQbrEQEpMS+kVPW4bhnl/3W4bx5Nk9HUxCt6cVn\n1xxfU4ftLjNbsbBtipmtVGLfcu2Ge9xNZQ5Vw7FnAdvJuKz/dODeKudR0o1mtpakS3C2xRO4Au7S\nwxzLwww5YPkJYtZ3rsh+6Co41k+oIAhXYdf1cyJ2bZVsWxF3NrNz7S5czKdOi6takAvebW4lPRxL\n9lkEF7UynDUxHKZNwhhEomgOKMzsYEkb4BGz5XD1u2ik1sxuDRPq5fCb9NRiRqULbAkcEKJVUScg\nQ51JScKYRZ6OOQdO2XmizDhkCLfFxT4WwDMa3yraWf9pc7vjFJtY02fDnc8ZkPQd80bN0ca3Fm94\n2w3lch611nosjosBQKQRcEPsQ3uPvU6ZzTVDVv+2sM8zksr6J71kZi9JyiLV90mKqtLlcDzwVTPL\n6MDr4k5cjArUxLYJinTd/KQtRpvLU92PKay3IUz098aFYSaEba8Dh5nZvhH7t+HKfn/HafDCKVaH\nSFrfzIrXV57uN5x61rLxr4Er6GVqmdvjjI9HcCGmf8FQjbWkHwFnhN9/dlygZxXgNUnbWuirOJLO\nXUDTmr1GFFCcgnthsDf8GXizQjNrG17T6lskvQk/3ybjtWM3dNhnP3n96h54AHc+nEo5XHygYSbn\n/8zsVz343EqoWc3h3nK69BVUNxZv9JwI41gEeBtDdefZ9TkfLhDVehDPqp9vZjsUjrOlmZ0Z+dxu\n8DwwJQQ5ZqioVjy3vgD8CL8PCThM0r5mVjmXSxgsJAdvQCGnZP7JzC4Lk6zlFKHCBdst8ejw3ZJ+\ngBdw7zfMLEaTeo+eT0oSRgZmdlZ+XdJpOPWJwvb98QnPozj98MfALRZvmN32MT0YausBzb4U/tYV\nT8ka7DZtfDuNdsrldFxg4Bi8+D6PPfBajxl1PMBXw/Vc57uqQkzwpSiM1LZPoPgYzJhEle3ztzAJ\nPRe4TNIzuBNQhdczhw3AzK6V1Jal6sK2NqyhKEsXGYdv4kJEa5jZQ0BWl3SkpG+a2c8L9v8DHGkF\nOXhJ38DZGDsU7CeEDNmE3OvSDCSwcMhCKvc6//8VM5BHE6T25fWXP2Wofcqvcccnj62AzJHKxroQ\nfs7/Bric0UFTh+2LwG54DRUECqhcwt6sQAHFn2NPAhn74ClcUOQTDKNpdQgQHGAu0X+UvNXCfFUM\nm3DNLmtm5+MBpW5FomI4B6+7r4vPA3138KhZcxiwI54dn5VcSwUKv1H2nAA2LAbjJJXNWz6Kt4N6\nO63Z/el4aUsMe+GtFDpt6xaZsmseVc/VbwOrWqAvy+nN19MhWJ8wWEgUzQFFoHL8NzA/PuG+BXjF\nzNpUwxQ4+iEi/hOcxvUjM1tzGJ/fpDalZzShhNFFCCZcYGbLFLb/E1dnPRQ4z1xxblqRzpOzHxHa\nXMhGtMEq1OmaoEjbym9TgXIp71W0Fh6hz6hXUyNZvm7H0rjHnqTt8An7avjkfAvgB50iy4ERMAkP\nHJVmHiUdik+CT8MnHFvhrQd+C60UqCa2IwFJJxDP5n6+YHcbsIEVanaCs3yptfeau6+MeidpqhV6\ndQXK3BvEg2rDpsxJusPMVgmvDweeMrN9wnpbHzm19pk7K/yPR4f1UbvXq2HNXh8+fy8zO6DLfUup\noRX73GRm/9XN53U4btN+iiPym6tBzWHsOupw7Fp0y8L7nyoGQCM2G+ItJj6NO6cZ5gNW6NXvJ2lX\nM/tFp225967H6cuvhPXZgKvMrE09OWFwkTJ4gwuZ2YuSdsKjwT+TNyiNIXvgbQQcY2YXyJsWD+vz\nh7l/wgBA7QXx/wD2jJguiteDbgMcKlcGnFNDbRmK6CttLof8w38OXGXzVkrU6cK4Y5P6MiGR2pRL\nc2nsw8Pk6Y6a42+CXXDBl5dxJ+kShjItUZjZKSFY9CH8t9jMzO4t2oWMwd2ZY9KAUrtK+Ft0Olal\nnQLVxHYkcH7udRU9edaicwdeh6d4m4Qq9bwXI8dZssM4i/ZNM5BN2qcAvCyvK3oSzxzlKdhtFLWR\ngjVo49EnbIlnYLvBrZLWsCF5/zq4Tt624Xe00vKGGwh5m6Rflr0Zof2trCF1zjyymr1eOdYZO+nv\nckXTJ/AygBiul7SCmd1TdcCmdMuwz2fM7LfAksXsOLQFG5/Ag++bMCSyAp7t6wWdNsMOBMXpHD5X\n3JYb74PAX+RtLQxXQO1akyFhbCI5eIMLSVobLyTfKWybWGL7uKSj8Qn4gfK6iQnD/Pwm1ILkDA4o\n6k6azOx1vBbn4nB+bYxnYx6XdIWZbVuw7zdtLttvl/x6oBieXrFLfrI6B54Jq6IJNqVcXiHpU8DZ\n1mP6hDXosVfIoP6TIYopkhYoZlDN7HVJU/PObM0x1aaONbEdCdSlJ1NdOxl7b5JC3VYBwieWPUHd\nDCTN2qeA0xp/j9Myf56jpX6codY6MyOG85xbE9hO0iO4s5Y5R1X1p1lmNV/n2YtAyH9odUY6YUqT\njN8w0KTmcC3gdrn68suUf5/d0C3nDn/nKXl/BszsDuAOSafi8+3aCsd1IGkbvOZ9KUl/zL01L0P9\nNSlsB2/18dfc9j/0akwJYweJojmgCBSpPYDrzOzAUPOxWyS6hlzK/WP4jfgBuTT3SmZ2acQ2KjKR\nIXb8GmNd0ULD9ISZC3LJ+80ySqSkHaxeXV7Z8epOWsv2nxW4qyF9J0qF6oZymaORvYbTD4cd5VbD\nlhNhn3zbCXL7R5Xywj7X4Nm0m2jNGFSpdNaWrm9iOxqooCe/ztD3kf8+BcxhZrMW7E+o+hwzq9OY\nuc54P5VbnZGBLHlGjHj7lPGGbqiKkpYys4fUQLY+o95JWtfMYgGHYaHp/9GU0jkSaPJ9BvuOdMth\njqexwnHN4y6BBxUPoLWH5nTgzhL2TH7/eQDM7PnhjCNhbCI5eOMYkuYzs3+rpEl0MUof9skX+P+Y\nAl0qPzmP0PdmvMUI1DwkDB6GW6/RZNIa7PPOzwS8kfAZZhZtKF24VibgfR1/WeYQjoXJjYZaTkQR\no1Nmk0NJc1Q5pHU+p4quqQbS9U1sRwIl9OS9+jkR7CdCQOLaYp1NCAC+akGgKziyHwcesYgyZJis\n3plNluWqmpnq5q5ZRm9mQzf3glxd2RVm9qGa+9xu3qakL7VvCu0XGth/z8z2r2HXdY1i2H8pnIa+\nJK3Ny6NOkqRVcJ0CgD+HbFrV8TeiXaEzpoJbSl8N+8QCKJPxzOpVNlS/2rjusgwhwP9Edi+X90N9\ni5k9XGK/Ii4ulD3vnga2N7O7ezGehLGB5OANGCQdama7lUXt8zc7uTTvxpFofTCtbg7d5IE1Fia6\nCWMfvT5PyiatuffzTslr+KT1bxXHy18rrwEP4ZHWaKRc0sG4nHltyqVcBXFZWicS19TZt+R4V5jZ\nhyQdaGax+sjYPtnEsq8CCWrQa6yJ7ViFXMhqWTM7Qd44ed4yh0fezHp/4K1mtqGkFYC1zey4Po2t\nLAN5DbBTYHcsg2doT8GDITdZoTm2pDuBtcxrwDfGqW3b4NndLc3so/0Y/1hHXUensM9teLnDV4Ci\n2mpUPCpQhVcH3korza4OrXPU0IPg3h3AcbQ3L48FsHbFVVKzAMUngV9bpE9wsD8Kr7lbHzgWF5u6\nycx2itgWVW5bEGOoaKhnYV6g6M5e/VaSbgHWsVbRlOusvOn99cD3zezKsL4e3tM0iayMI6QavMFD\nJul8cCdDM9s4/G1U75Q/RJ9sE2Ze9Po8WRZYuPTDWvvtLQhU0v26uFZ2xlU9X5PUkXIp7z+0K17z\ncTtO8byB4dXNLCppHWATSadTqAUqodi9KunXwNtjEel8FFou5LSAmR0U1v+G178I+LaZHVUxtibS\n9U1l7scU5OqVq+P9Rk8AZsOzke8r2eXEYJfVTN6PC2b0xMEryUDGAgDzm9kD4fUOwGlmtkuYJE7G\n5dzzMPN6T4DNgePMm9FPlvTVXox9LKITPbypcxewNd4zdBZqCkeZ2TZycZBLcPGOQcFwa/FfMrPK\n7FkOO+E9PjO68YH4fTbq4OHO0crB6fqxpEOAi2KGMQeuBu6WtC0uaLQsrnB8fRfHKcMsllMzNrNX\nVN7PFGDuzLkL9lfJ68YTxhGSgzd4eABKo1aLF9YztSckvc/Mrsu993UbgeakCQkFDOshX3fSGmqK\nfooXmv8ED4wsiPcR297MLo7sswTwgpk9HfZfF3jQzM4tG481V+7bFVf2vNHM1pe0PJ7FGQ5+BPwQ\ndxoPoZCpJ+48boz3PvsonQUVvozX8GZ4yszeLu8TdQlQ5eBlvcYy2uUEynuNNbEdi/gknsW6FcDM\nnpBUdX4saGZnSNor2L8mr+frCRqcm/nr6YPAQWH/VyTFeiIq1O68iKtuHpF7bzz3PK2rqlob5oIb\nBwbHIupQlOz3D2CVQMXrqXBHHzHc4N4vQhDlUlqbl8cCWGJIPZzwuurZkynbvijprXggcNGYYRMW\nVQ6NFY4b4ilJm5jZH8MYN8Vpl2WYJumHDCUMPoP3dE0YR0gO3uDhKkIT0ghv/1xaG5TuztBk6bDC\ne9HmpIUJ9Fwakj9uy0xoSAlOwJtUUIaL1W8kzPS4rrNJORpMWn+Fq6BNAv6EN7K9MThUp+GKnzMQ\nHnafAyxkwT6MX2sbSVrPzHYr+6CGlMuXzOwlSUia3czuC9S5rmFmvwd+L+mHZlZr0mAu63+6pHur\nalOC8yFrFTo5MxzjpTDBrPqc2g5wF87yWMMrZmaSsqbxnSLiL8iFZTL7tYirVvYbdwaq8ePAMvgE\nGrnibAyH4tnnfwP3mtktwX5V4O/9H+7owOqrqnaDW+V9LGvTdZUT7gCWUo+EO/qI4WbwVgI+iwch\n8s3LYwGsE/A2AOeE9c2ozoyfH873g/AAjeFUzRhqs6gyWAOF4y7xZeAUeR9LA/4GRHvABnwe11jI\n5mh/DtsSxhFSDd6AocDhbqlnqlrvZNvlWDI1uKxmqajEl24YMxlC7cMJuIrXsXhG47sWUWzt8zhm\nNGgOTsy7cu+1nfuS7sFlx+cCHgUWCTVGswC3F2vDcvtFKZdW0jcvTDh2xDNVHwSewfuofXxY/3Cf\nIOlWYL5i3VZ4bwKe4exUy7sJ8P6wepWZnd8L27EGSd/CHf0NcFW7z+N0xyitTNJqeOBtReAuvO3A\nllUOdz8QnPRd8YzF8dnnB9rv0mZ2cmSft+HU6DvM7I2wbVH8XK7dRmOQoZKaxi6PdRGBrmtmq4T7\nzm1WUX+qPgt39BrqokaxsP+DeHPwqrYkefvVcBYGuMhKrRYe8jY/c5hZx2BLoEEuj899phbHVkbr\nDbBYjd9woKSKmZBDyuANHqzkdaf1TrbNBxLkvANtIia5njDz4fPmEt4fBebHI64nE7ICI4g8tazY\nWDp2fr4UHs6vSPprVmMUaHNVE4pGlEsz+2R4uY+8qfokCtnEMQbhtXH7mdkPCu/tS4ffVdJP8e/n\nlLBp10AXL9Z1NbIdizCzgyVtgGe2lgN+ZGaXVexyN/CBYCtgKsPvT9oYZvYfnM5c3H49kTqhMHHO\n8B6pLTEzLh28BjWN3aAbuu6rZvZc4fsftWdvmTMzzBrFPO4C3oT37awax0TgbjNbnkCXroMQ0FiS\nMC+WhIX2PiX2G+H09Bk9UCXtXKDaxgJUi+H9+8r6FjeGGgo2yVugfIt2RdLh9lBMGENIDt7gYWFJ\nu+M3lOw1YX2hgu3ycsUzAUuH15ltZdS9IfLRojnw+p57e3j8hMFBNtv4OHCymd2tyAxwBLBKoBcL\nmLNANY7VCWUUYwHzFejHkyo+pzHlMkxA3oIrdAIswtidFBvwbeDYEEHPskurALcAX+iw/8eB9+Sy\nPL/Bm2HHnLYmtmMOGlIxvSyyLYYbzFUF787Z30orlb7vyD0XorB2pb9b8Ml2VuNTp+Zz4NFnCnE3\ndN1+C3c0Rc9rFAt4E3CfpJtprcFroaSa2euSpkpavG42WdLJwNI4CyNzrA0odfDweuf1zezBcIyl\ngQvIibPkab3yVgbfwxkKP6VHYkoBJ9JMsOlM3Dk9ltZaxYRxhOTgDR6OYUhtK/8a2jnj72IEYGaH\n5NdDPcfAqN8l9BSTJV0KLAXsJReZiAk19BVmVis6Kml+M3sGuBr4RNh8Te51tl6Gv4XajXOByyQ9\ng/cDK/u8XfDekk/SWkcyJqXNcRr/C8A2YYLy7rD9HjP7a8V+ebwJF7uBame5qe1Ywwa0Z3Q2LG6T\nKyC+DQ88rMqQgzQfThEeabyBn4OnAufRnvEuYndc4fQ/wOnAOYkSNmzsDvwRD8Rehwdrt+iwT164\n41T8mbtfPwdZhT7XKEKhJ28HzI87wDcBL4RtZmabltivjtM/m2RAp2fOXcA0vDShBYHV8QO8XOEg\n4MvWoQF5F2iaAX7NzI7s8RgSxhiSgzdgMLMf17FTg6aikm4ws7WHN7IWzIXXJCXMfNgJr2WbFmrY\n3ozXnI1VXAGsltGNO0HSDpaTye6CcrkrsFxBtGQs48zshZlNo7nS2gHAbeG7ER69jjaZb2g7ZiDp\nK8BXaWVJgAffYqJCH8UFfd6O95DL8G88wj+iMG+avTzey+5U4J7w99LYRNTMDgUODQ7/1sAVkh7B\n+2jdPoJDHxcItaxzUKDrWmg8X7LPRFxQ5Vv0T7hjuKhsYdMUZnZ1oCJmvd1uMrMyuuYPc6+FNzzf\nuuLwd+FMio4iQTl2xy2SLsTbuhiwJXBzwfZM4L14tu+beLZsvozUYmb/ojeolQGWlDU2P0/e0uQc\nWrOhvRpPwhhAElkZp1CDpqIapuCKpCkMce8n4tHHfS21YZgpoR438u4nmp77sesqR7nM1zJEqUHB\nedmgDxHcrtCpbqZHn7EorZOyf/TCdqxA0iQ8Y3AArQ7p9KoJk6RPFbMeYwGStgIOBw600Puwwvbd\n+MT5s8B3zOyMKvuEOLp5Bis0z+7XmJqipEZxr16d45I+jWfArmLIafu2uYpwzH5VYFvc8XoIONsK\njc411OpgXjwweRMV9M+wzwnFbXnkg4WSHmboO8mL0AXTaoGqulBcsGkLM7uzYPcQrXoJhaH3ZjwJ\nYwMpgzd+0aTuabhe/sa5168BT46VCWzCyEL9aeTdTzQ991uuq7qUy1yt7DTgKkkX0DqRyGdyRhJ9\nqZspCHGAy3YDvFXSWy3Xu6qJ7VhEUNt7TtLf8QbC99Tc9aAQaT/ezEa1Zlmuirk1/vs/g2cbzimx\nzTJ3mwKP4TTN/YNYS0J3uELSp3AnpO496TZJf8Sz7BkNcdTaE/W5RhE8U7lGlrWTtBBwOTDDwQvi\nIduE5Wm8Dk1mtn7JMWu3OshQl+0RbJdsevxuYGa3SuqYATazpUZiPAljAymDN07RMINX2zYhoQoh\nm5upSmbUr/3NbPMOu44Kmp77RfsgPLJmJ8qlXGm2FHWp1/1GoItda2brDPM4V+ZW34sLc+Qj1x/s\nxnYsIwQ3dsQDpyfgLRJKhTJCferWYZ8JwPHA6Wb277J9+gFJV+MZjDOAs/AmzzNQzELKm5/fCfwB\np5VawX60ghUDi5D9mhsPkL4E7X1nI/vEMknWy+z7WIIKLSDCveqOwrY38J5uO+XET6bVyUyF2tj/\nws/nmzuxByTNgZckvJtWtsqIff8q9B4uoszZD2P/Kt5GwvDv7Cgze6nng0wYNaQM3vhFkwzeaKgc\nJoxP9LyRd5/R9Nwv2j9GjebUY8WBq4Ge1M3kI+aBflbqpDWxHcsws2NxtdHlcKftziCYcYyZXRmx\nn44LZR0Tou+nAj+X9HvgJwUBh35iCXyStzPwpdz2rLdpcXK8L0NO3Tx9H91MgG6yX50ySU3q8AcE\nF0u6BDgtrG8FXFiw2RwPmlwp6WI8u9zxHh+CMz8C/hTsD5O0r5kdX7HbycB9eE3tvsB2jLx6+Ccq\n3jOGGpkXcRIuCJNRVrfF/58teze0hNFGyuASRcNKAAANg0lEQVSNU6hBU1FJK5rZXf0eU8L4h8Zo\nI29JcwErAI+Y2VO57Qs0KSyX9Csz+3qOcvlunBZTi3Ip6TK8mfWzYX1+PGvz0ab/Uy/Q77qZ8Bkz\nDZsg1GNujF8Di+FZsXWBF8xs64jtRsF2SXyCdQpeW7S/mb1z5Ebee4xDB2OgMOjXUgwhY5VvXl5G\nI54bpxBvgz+HTsLVXqN9OyVNBdbJmBhBsOR6MysNTmZ1k5LuNLOVJc0axjRm6iLLIOkeM1uh07aE\nwUbK4A0YJB1GRd2QmX0j/N0/MnmbcRhy9I/k3CX0CjZGGnlL2gT4JS65/wNcNOJJYElJe1pQwsw7\ndyGL8oyZ3RkK+t+PN7E9wsxeDvZfD+ZZxP3RsMwWlk5YKHPuwvGekdQzpbmmGIG6mZkGkn6OO3d/\nwh20m8JbB4YJZBEPAFcCB5k3Fc/we0nv7+9oRwRb4sIzCaODccfMCZTDsyUtSIFKXLB7Ac+InxqC\naFvi7UqiDl44Vr7FwfSq4wdkNW7PSloRD46Nyr1cDRudA7dKWsvMbgz7r4lT4xPGEVIGb8AgaYfc\n6o8p9IaxnIR7Yb9hKWUmJFQhJ78cRZMsWS8g6Q78oT4Jn0SvbGbTgjN1Rb5uI9gfjgujzI43iZ0H\nd0zfB0wws+16NK7JwCctqGxKWgKPLI+3SHs+ELU1TpWagSwQ1dR2LEPSjsAZYXKZbZs/OPGTsno8\nSYuZ2WOS5rFC/zhJG5vZ+YwDpGfO6GK8ZPCCENFP8WDdT/BM94J43er2ZjbsAKKkk4CV8LpSw7N/\nd4YlysgItM6zwn4n4s+MH5rZ0cMdT1NIuojQ6NzMVpE0C3Bb8TmXs78XZ55kas+LA1PxGlAzs7Ha\nlzWhAVIGb8CQd+Ak7Vbm0MV27dOQEhIAJlMhv0x7HU+/8YaZ3Q8uDW3eww0z+6ekmMLr+ma2Qig+\nfxxY2Mxel3Q04SEfQxeUy+8D1wZhi0zq+0sltoOMfDR4cg9txxwkHWtmXzCzEwrbFwMuAlYsiK1c\nJuljZvZwwf7z+PkxLhw80jNntDFeMni/wvtDTsKz4xua2Y1BwOs0esMQ+WtYMvwh/K1iOFxhZs8A\n1xCeb5JGS6WyaaPzj43QuBJGEcnBG2ykB2jCmICNPfnlCcHZmgC8EV5nE54JEfuXAIJAzCNm9npY\nN0mlDYdpSLk0s4vlbQGyOo3dzOzp+v/WYKBu4EnSYWa2S2T7Ip1U7MYQZpH0Wzyb8AZAoEidj4sv\nFLE7cKmkjczsgWC/Fy508IERGvNIYLw4GIOKM0d7AD3CLFntXBA+uREgCHj15AO6FME6CyhmSH+P\nKwGPNGo1Os9gZo9IWgUPMILXDt7R/2EmjCSSgzeOkZPQFfCmoqRumYRuQkJTqL2XWQts5HuZTcKz\nQdkMIP/5scDIwkE4RbnXhPWFKj7ndUmLFyiXlYGX4NCNlyzNcPG+ku0X0j55GqvYETga+J2krYE1\n8f5bX4nRLc3sQkkvAxdJ2gz4Ai7P/v6QERgvGC8OxpiEvE1C273Ggkx/XZG1AcAbudfFXovDCnJL\nOtTMdtNQw/PWg8cbnS+Pi2tNKsyp5iPXLmGEsTvwR2DpoNy7ELBFmbGkXYEvMqSy+VtJv7ZCI/iE\nwUaqwRswFIRT5gJezN6i0DdHQ31yMuqcFWzHZb+chJGHhnqZzQGsDtyBn2crA7eY2dqjNbY6UJd9\n6iR9DPg10EK5NLNLej7IcYiyOqFBrN+S9EtgVbztwKezTEOF/X/jzcSvD/YD1YOqk4OR0F/IG6Nn\nmANvUv/EoNSs1kWgGr6A31/npHXOM4eZzTqMY7/XzCYHga02mNnVkX02BTYDNsGdqgzTcXr+9cV9\nRgKh7q6y0XnO9k5chOWFsD43cEOqvRtfSA7eTIAwec3XRxmAmcXoQwkJXUPS2cDeZjYlrK8I7GNm\npdHEQUdQdMsolzeOR8plv1Dh4H3VzI4YjTE1RU4kRjjN8lZy/bCKE+5ckE64qM+rwOtEgnRjGTOL\ngzEokDf+vtbM1hntscwMkLS2md0w2uMACC0avoIrPwNcBRxd5uRJmgKskQWVQu35zWWiLAmDiUTR\nnDmQV2qbA5fyHumGnAkzB5bLnDvwFhyS3jWaA2qCbrISiXI5LKhEgfX0bPtIK7B2gVtKXkdRtzVF\npsDZ9aj6DCv0SpR0GnDtKA0nAZZllGT6BxXB0SlrJfWGma1SsfsnJd2N00Yvxtkq3zSz3/Z+pB1x\nJDArkAXFPhu2faHE/gTgL/K+teAZybKWCgkDipTBmwkhaXbgEjNbb7THkjC+ECZ5LwDZQ247YB4z\n22b0RlUfKSsxspD0ObzVS5bRWhR4Insbz2iNtAJrX1AmKFNhP1Ay95KWAy4ws2VGeywzA9Te5/Yf\nwF5FxzuhHKFmum0zsBj+XX68Yt/bzew9kj6JB813B67p4BT2BZLuKH5ubFvh/dVobRp/Wz/HmDDy\nSBm8mRNzAW8f7UEkjEvsiFNFdg3r1+CRxIFAykr0BmWiBRky8QIzOxHvIZXtN3C1dw1QJihThjGt\nQlniYOw5SsOZ6VA3E5xQDjN7JHstaVWcYr0l8BCuklmFrPZvI+BMM3uuV6qeXeB1SUub2V8BJL0D\np323QdJE4G4zW55W8bGEcYbk4M0EKNAQJuIKS6n+LqHnCG0GDgcux8+5ymLvAUCiPXWHg8NfAcdQ\nThUqIlFKhjCmv4vkYCQMOiS9E9gmLE/j6rcys/Vr7H6epPtwiuZXJC1EaLczCvg2cKWkafg9dwk8\n2NqG0N91al79OWF8IlE0ZwIUaAivAU+aWazZc0LCsCBpPeA3wMMMUV12MLNrRnFYtZFoT71Hk6zc\noNESm6Dp/zaev4uEhLEASW8AfwZ2MrMHw7ZpdWnhoU74ueA0zQXMN1r9O0PpzXJhdaqZvVxhew2u\n+HsTXlIBxNtCJAwuUgZvJkCehpCQ0GccAnzEzKbCjAjpaYxO89fGSFmJvqAyipjrOQitPQh9Z7P/\n7cuoRh5N+VtjmqKZkDAOsDmwNZ79uhg4nWbX3fLAkqFFQYaTeji+WpC0JXCxmd0p6QfAapL2q+g/\n+8MRHF7CKCE5eAkJCb3ErJlzB2Bm9wcJ54SZCAVlzImS5ic3cSooY+ad6mMK6+MJv4C276YNue/m\nQ30fUULCTAwzOxc4N/SB2xTYDQ8yHQmcY2aXlu0r6WRgaeB2hurdjFFw8IAfmtmZktbF7xsH47Xv\na8aMY/39EsYfEkUzISGhZ5B0PPAGrSqaE1Pz45kLkh6itfdmHuNGGRPqC8rk7PPfTaYaqiHz8fPd\nJCQMGkIwaktgKzMrDbJIuhdYwcbAJDqjwUs6AJhiZqfGqPGREoQWDEoPzoR6SA5eQkJCzxDqAL5G\nTn4ZOKKqHiAhAbrrQTgWIOkD2UsigjJV0fJxrhqakDBuIelM4Btm9vcxMJbzgceBDYDVcOGXm8ra\nJEj6CfB34GT8vrUdsKiZ/WhkRpwwEkgOXkJCQkLCqGM89CBs6rAlIZWEhMGEpCuB9+BCJTMCmKMh\nVBIEXj6GZ+8ekLQosFIZxbSbvnkJg4dUg5eQkNAzSNoY+Aku0zwLQ82qE/UjoRLjpAdhipgmJMwc\n2Ge0B1Co570qt+1l4JaKXV+QtB0uKmN4m4gXKuwTBhDJwUtISOglDsWVyaaMhdqEhIHGQPQgbCgo\nMzOphiYkjFuMEaGSyQzV8xZrng0oq+fdFhd9+kWwuy5sSxhHSA5eQkJCL/EYcFdy7hKaoqQH4Z6j\nNJwmyE+yAPLS5LFJ1syiGpqQMO5QIVQy4mwVM1uqy12nm9mmPR1MwphDqsFLSEjoGSStgVM0r6a1\nLiFlJRISEhISEkYZkh7A2zscj/fPS47AOETK4CUkJPQS/wM8j4tkzDbKY0lIGLMYVNXQhISEgcc7\ngQ8DnwcOk3QGcKKZ3T+6w0roJVIGLyEhoWeQdJeZrTja40hIGOsYD6qhCQkJgw1J6+N9a+cG7gC+\na2Y3jO6oEnqB5OAlJCT0DJJ+BlxeJs+ckJAQh6QJwLVmts5ojyUhIWH8QtKbgc8AnwWeBI4D/oi3\nfThzGLV9CWMIycFLSEjoGUIB+tx4/d2rpDYJCQm1IGk54AIzW2a0x5KQkDB+Iel+vMn5CWb2t8J7\ne5rZgaMzsoReIjl4CQkJCQkJI4wS1dC9iv0AExISEnoJSUrCKuMfycFLSEhISEhISEhIGMeQdB7x\nFg8AmNkmIzichD4jqWgmJCQkJCQkJCQkjG8cHP4K78H5hVEcS0KfkTJ4CQkJCQkJCQkJCTMJJN1m\nZquO9jgS+ocJoz2AhISEhISEhISEhIQRQ8rujHMkimZCQkJCQkJCQkLCOIakBXKrEyXNj9M1ATCz\nf438qBL6hUTRTEhISEhISEhISBjHkPQQnrlT5G0zs3eM8JAS+ojk4CUkJCQkJCQkJCQkJIwTpBq8\nhISEhISEhISEhISEcYLk4CUkJCQkJCQkJCQkJIwTJAcvISEhISEhISEhISFhnCA5eAkJCQkJCQkJ\nCQkJCeMEycFLSEhISEhISEhISEgYJ0gOXkJCQkJCQkJCQkJCwjhBcvASEhISEhISEhISEhLGCZKD\nl5CQkJCQkJCQkJCQME7w/+XZsfauIF61AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae270d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix2 = norm_HemoPI2_model.corr()\n",
    "\n",
    "figpath = \"/Users/fabienplisson/Desktop/MODELS/Figures/HemoPeps/\"\n",
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(corr_matrix2, annot=False, cmap=plt.cm.RdYlBu_r, vmax=1.0, vmin=-1.0)\n",
    "plt.title(\"Correlogram 56 modlamp descriptors HemoPI-2 dataset\")\n",
    "#plt.savefig(path.join(figpath, \"Correlogram 56 modlamp descriptors HemoPI-2 dataset.pdf\"))\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(812, 27)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix2.where(np.triu(np.ones(corr_matrix2.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.75\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "to_drop\n",
    "\n",
    "# Drop features \n",
    "trim_HemoPI2_model = norm_HemoPI2_model.drop(norm_HemoPI2_model[to_drop], axis=1)\n",
    "trim_HemoPI2_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HemoPI-3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAMNCAYAAADKgdY8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e9c0dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix3 = norm_HemoPI3_model.corr()\n",
    "\n",
    "figpath = \"./Figures/HemoPeps/\"\n",
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(corr_matrix3, annot=False, cmap=plt.cm.RdYlBu_r, vmax=1.0, vmin=-1.0)\n",
    "plt.title(\"Correlogram 56 modlamp descriptors HemoPI-3 dataset\")\n",
    "#plt.savefig(path.join(figpath, \"Correlogram 56 modlamp descriptors HemoPI-3 dataset.pdf\"))\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1298, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix3 = norm_HemoPI3_model.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix3.where(np.triu(np.ones(corr_matrix3.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.75\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "to_drop\n",
    "\n",
    "# Drop features \n",
    "trim_HemoPI3_model = norm_HemoPI3_model.drop(norm_HemoPI3_model[to_drop], axis=1)\n",
    "trim_HemoPI3_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define X and y of model and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_HemoPI1_model = norm_HemoPI1_model\n",
    "X_HemoPI1_validation = norm_HemoPI1_validation \n",
    "X_HemoPI2_model = norm_HemoPI2_model \n",
    "X_HemoPI2_validation = norm_HemoPI2_validation \n",
    "X_HemoPI3_model = norm_HemoPI3_model \n",
    "X_HemoPI3_validation = norm_HemoPI3_validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_HemoPI1_model = HemoPI1_model['y_model_2cl']\n",
    "y_HemoPI1_validation = HemoPI1_validation['y_validation_2cl'] \n",
    "y_HemoPI2_model = HemoPI2_model['y_model_2cl'] \n",
    "y_HemoPI2_validation = HemoPI2_validation['y_validation_2cl'] \n",
    "y_HemoPI3_model = HemoPI3_model['y_model_2cl'] \n",
    "y_HemoPI3_validation = HemoPI3_validation['y_validation_2cl'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score, matthews_corrcoef, average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skfold = model_selection.StratifiedKFold(n_splits=10, random_state=seed, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running basic binary models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('logreg', LogisticRegression(fit_intercept=True)))\n",
    "models.append(('knn', KNeighborsClassifier()))\n",
    "models.append(('cart', DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('rfc', RandomForestClassifier(random_state=seed, max_depth=5, n_jobs=10)))\n",
    "models.append(('gbc', GradientBoostingClassifier(random_state=seed)))\n",
    "models.append(('adc', AdaBoostClassifier()))\n",
    "models.append(('lda', LinearDiscriminantAnalysis()))\n",
    "models.append(('qda', QuadraticDiscriminantAnalysis()))\n",
    "models.append(('nb', GaussianNB()))\n",
    "models.append(('svc_lr', SVC(kernel=\"linear\", C=0.025)))\n",
    "models.append(('svc_rbf', SVC(probability=True)))\n",
    "models.append(('svc_poly', SVC(kernel=\"poly\", probability=True)))\n",
    "models.append(('svc_sig', SVC(kernel=\"sigmoid\", probability=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg: Accuracy Score 92.65% (2.68%)\n",
      "logreg: Accuracy 92.65%\n",
      "logreg: Precision-Recall 89.39%\n",
      "logreg: Matthews Coefficient 85.30%\n",
      "logreg: Cohen Kappa Score 85.29%\n",
      "logreg: ROC AUC Score 92.65%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.93      0.92      0.93       442\n",
      "     high 1       0.92      0.93      0.93       442\n",
      "\n",
      "avg / total       0.93      0.93      0.93       884\n",
      "\n",
      "logreg: Accuracy 89.55%\n",
      "logreg: Precision-Recall 84.73%\n",
      "logreg: Matthews Coefficient 79.17%\n",
      "logreg: Cohen Kappa Score 79.09%\n",
      "logreg: ROC AUC Score 89.55%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.91      0.87      0.89       110\n",
      "     high 1       0.88      0.92      0.90       110\n",
      "\n",
      "avg / total       0.90      0.90      0.90       220\n",
      "\n",
      "knn: Accuracy Score 93.22% (3.22%)\n",
      "knn: Accuracy 93.21%\n",
      "knn: Precision-Recall 89.63%\n",
      "knn: Matthews Coefficient 86.48%\n",
      "knn: Cohen Kappa Score 86.43%\n",
      "knn: ROC AUC Score 93.21%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.95      0.91      0.93       442\n",
      "     high 1       0.92      0.95      0.93       442\n",
      "\n",
      "avg / total       0.93      0.93      0.93       884\n",
      "\n",
      "knn: Accuracy 86.82%\n",
      "knn: Precision-Recall 81.15%\n",
      "knn: Matthews Coefficient 73.79%\n",
      "knn: Cohen Kappa Score 73.64%\n",
      "knn: ROC AUC Score 86.82%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.89      0.84      0.86       110\n",
      "     high 1       0.85      0.90      0.87       110\n",
      "\n",
      "avg / total       0.87      0.87      0.87       220\n",
      "\n",
      "cart: Accuracy Score 90.39% (3.09%)\n",
      "cart: Accuracy 90.38%\n",
      "cart: Precision-Recall 85.83%\n",
      "cart: Matthews Coefficient 80.84%\n",
      "cart: Cohen Kappa Score 80.77%\n",
      "cart: ROC AUC Score 90.38%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.92      0.88      0.90       442\n",
      "     high 1       0.89      0.93      0.91       442\n",
      "\n",
      "avg / total       0.90      0.90      0.90       884\n",
      "\n",
      "cart: Accuracy 83.64%\n",
      "cart: Precision-Recall 77.55%\n",
      "cart: Matthews Coefficient 67.37%\n",
      "cart: Cohen Kappa Score 67.27%\n",
      "cart: ROC AUC Score 83.64%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.86      0.81      0.83       110\n",
      "     high 1       0.82      0.86      0.84       110\n",
      "\n",
      "avg / total       0.84      0.84      0.84       220\n",
      "\n",
      "rfc: Accuracy Score 93.79% (2.98%)\n",
      "rfc: Accuracy 93.78%\n",
      "rfc: Precision-Recall 91.10%\n",
      "rfc: Matthews Coefficient 87.56%\n",
      "rfc: Cohen Kappa Score 87.56%\n",
      "rfc: ROC AUC Score 93.78%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.94      0.94      0.94       442\n",
      "     high 1       0.94      0.94      0.94       442\n",
      "\n",
      "avg / total       0.94      0.94      0.94       884\n",
      "\n",
      "rfc: Accuracy 87.27%\n",
      "rfc: Precision-Recall 81.81%\n",
      "rfc: Matthews Coefficient 74.66%\n",
      "rfc: Cohen Kappa Score 74.55%\n",
      "rfc: ROC AUC Score 87.27%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.89      0.85      0.87       110\n",
      "     high 1       0.85      0.90      0.88       110\n",
      "\n",
      "avg / total       0.87      0.87      0.87       220\n",
      "\n",
      "gbc: Accuracy Score 94.01% (2.71%)\n",
      "gbc: Accuracy 94.00%\n",
      "gbc: Precision-Recall 91.32%\n",
      "gbc: Matthews Coefficient 88.01%\n",
      "gbc: Cohen Kappa Score 88.01%\n",
      "gbc: ROC AUC Score 94.00%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.94      0.94      0.94       442\n",
      "     high 1       0.94      0.94      0.94       442\n",
      "\n",
      "avg / total       0.94      0.94      0.94       884\n",
      "\n",
      "gbc: Accuracy 90.45%\n",
      "gbc: Precision-Recall 86.45%\n",
      "gbc: Matthews Coefficient 80.91%\n",
      "gbc: Cohen Kappa Score 80.91%\n",
      "gbc: ROC AUC Score 90.45%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.91      0.90      0.90       110\n",
      "     high 1       0.90      0.91      0.90       110\n",
      "\n",
      "avg / total       0.90      0.90      0.90       220\n",
      "\n",
      "adc: Accuracy Score 93.79% (3.03%)\n",
      "adc: Accuracy 93.78%\n",
      "adc: Precision-Recall 90.67%\n",
      "adc: Matthews Coefficient 87.57%\n",
      "adc: Cohen Kappa Score 87.56%\n",
      "adc: ROC AUC Score 93.78%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.95      0.93      0.94       442\n",
      "     high 1       0.93      0.95      0.94       442\n",
      "\n",
      "avg / total       0.94      0.94      0.94       884\n",
      "\n",
      "adc: Accuracy 91.36%\n",
      "adc: Precision-Recall 87.34%\n",
      "adc: Matthews Coefficient 82.76%\n",
      "adc: Cohen Kappa Score 82.73%\n",
      "adc: ROC AUC Score 91.36%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.93      0.90      0.91       110\n",
      "     high 1       0.90      0.93      0.91       110\n",
      "\n",
      "avg / total       0.91      0.91      0.91       220\n",
      "\n",
      "lda: Accuracy Score 94.23% (2.74%)\n",
      "lda: Accuracy 94.23%\n",
      "lda: Precision-Recall 91.12%\n",
      "lda: Matthews Coefficient 88.50%\n",
      "lda: Cohen Kappa Score 88.46%\n",
      "lda: ROC AUC Score 94.23%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.96      0.93      0.94       442\n",
      "     high 1       0.93      0.96      0.94       442\n",
      "\n",
      "avg / total       0.94      0.94      0.94       884\n",
      "\n",
      "lda: Accuracy 90.45%\n",
      "lda: Precision-Recall 87.05%\n",
      "lda: Matthews Coefficient 80.94%\n",
      "lda: Cohen Kappa Score 80.91%\n",
      "lda: ROC AUC Score 90.45%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.89      0.92      0.91       110\n",
      "     high 1       0.92      0.89      0.90       110\n",
      "\n",
      "avg / total       0.90      0.90      0.90       220\n",
      "\n",
      "qda: Accuracy Score 91.52% (2.77%)\n",
      "qda: Accuracy 91.52%\n",
      "qda: Precision-Recall 88.27%\n",
      "qda: Matthews Coefficient 83.04%\n",
      "qda: Cohen Kappa Score 83.03%\n",
      "qda: ROC AUC Score 91.52%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.91      0.92      0.92       442\n",
      "     high 1       0.92      0.91      0.91       442\n",
      "\n",
      "avg / total       0.92      0.92      0.92       884\n",
      "\n",
      "qda: Accuracy 85.45%\n",
      "qda: Precision-Recall 83.81%\n",
      "qda: Matthews Coefficient 72.66%\n",
      "qda: Cohen Kappa Score 70.91%\n",
      "qda: ROC AUC Score 85.45%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.79      0.96      0.87       110\n",
      "     high 1       0.95      0.75      0.84       110\n",
      "\n",
      "avg / total       0.87      0.85      0.85       220\n",
      "\n",
      "nb: Accuracy Score 85.87% (4.95%)\n",
      "nb: Accuracy 85.86%\n",
      "nb: Precision-Recall 82.32%\n",
      "nb: Matthews Coefficient 72.13%\n",
      "nb: Cohen Kappa Score 71.72%\n",
      "nb: ROC AUC Score 85.86%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.82      0.91      0.87       442\n",
      "     high 1       0.90      0.81      0.85       442\n",
      "\n",
      "avg / total       0.86      0.86      0.86       884\n",
      "\n",
      "nb: Accuracy 85.45%\n",
      "nb: Precision-Recall 81.02%\n",
      "nb: Matthews Coefficient 71.01%\n",
      "nb: Cohen Kappa Score 70.91%\n",
      "nb: ROC AUC Score 85.45%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.84      0.88      0.86       110\n",
      "     high 1       0.88      0.83      0.85       110\n",
      "\n",
      "avg / total       0.86      0.85      0.85       220\n",
      "\n",
      "svc_lr: Accuracy Score 88.13% (4.93%)\n",
      "svc_lr: Accuracy 88.12%\n",
      "svc_lr: Precision-Recall 84.25%\n",
      "svc_lr: Matthews Coefficient 76.31%\n",
      "svc_lr: Cohen Kappa Score 76.24%\n",
      "svc_lr: ROC AUC Score 88.12%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.87      0.90      0.88       442\n",
      "     high 1       0.90      0.86      0.88       442\n",
      "\n",
      "avg / total       0.88      0.88      0.88       884\n",
      "\n",
      "svc_lr: Accuracy 85.00%\n",
      "svc_lr: Precision-Recall 81.11%\n",
      "svc_lr: Matthews Coefficient 70.35%\n",
      "svc_lr: Cohen Kappa Score 70.00%\n",
      "svc_lr: ROC AUC Score 85.00%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.82      0.90      0.86       110\n",
      "     high 1       0.89      0.80      0.84       110\n",
      "\n",
      "avg / total       0.85      0.85      0.85       220\n",
      "\n",
      "svc_rbf: Accuracy Score 88.70% (4.79%)\n",
      "svc_rbf: Accuracy 88.69%\n",
      "svc_rbf: Precision-Recall 84.80%\n",
      "svc_rbf: Matthews Coefficient 77.41%\n",
      "svc_rbf: Cohen Kappa Score 77.38%\n",
      "svc_rbf: ROC AUC Score 88.69%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.88      0.90      0.89       442\n",
      "     high 1       0.90      0.87      0.89       442\n",
      "\n",
      "avg / total       0.89      0.89      0.89       884\n",
      "\n",
      "svc_rbf: Accuracy 85.45%\n",
      "svc_rbf: Precision-Recall 81.02%\n",
      "svc_rbf: Matthews Coefficient 71.01%\n",
      "svc_rbf: Cohen Kappa Score 70.91%\n",
      "svc_rbf: ROC AUC Score 85.45%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.84      0.88      0.86       110\n",
      "     high 1       0.88      0.83      0.85       110\n",
      "\n",
      "avg / total       0.86      0.85      0.85       220\n",
      "\n",
      "svc_poly: Accuracy Score 71.50% (5.08%)\n",
      "svc_poly: Accuracy 71.49%\n",
      "svc_poly: Precision-Recall 71.38%\n",
      "svc_poly: Matthews Coefficient 52.13%\n",
      "svc_poly: Cohen Kappa Score 42.99%\n",
      "svc_poly: ROC AUC Score 71.49%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.64      1.00      0.78       442\n",
      "     high 1       0.99      0.43      0.60       442\n",
      "\n",
      "avg / total       0.82      0.71      0.69       884\n",
      "\n",
      "svc_poly: Accuracy 60.00%\n",
      "svc_poly: Precision-Recall 57.04%\n",
      "svc_poly: Matthews Coefficient 23.24%\n",
      "svc_poly: Cohen Kappa Score 20.00%\n",
      "svc_poly: ROC AUC Score 60.00%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.57      0.85      0.68       110\n",
      "     high 1       0.70      0.35      0.46       110\n",
      "\n",
      "avg / total       0.63      0.60      0.57       220\n",
      "\n",
      "svc_sig: Accuracy Score 88.02% (4.92%)\n",
      "svc_sig: Accuracy 88.01%\n",
      "svc_sig: Precision-Recall 84.06%\n",
      "svc_sig: Matthews Coefficient 76.08%\n",
      "svc_sig: Cohen Kappa Score 76.02%\n",
      "svc_sig: ROC AUC Score 88.01%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.87      0.90      0.88       442\n",
      "     high 1       0.90      0.86      0.88       442\n",
      "\n",
      "avg / total       0.88      0.88      0.88       884\n",
      "\n",
      "svc_sig: Accuracy 81.82%\n",
      "svc_sig: Precision-Recall 79.17%\n",
      "svc_sig: Matthews Coefficient 65.49%\n",
      "svc_sig: Cohen Kappa Score 63.64%\n",
      "svc_sig: ROC AUC Score 81.82%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.76      0.94      0.84       110\n",
      "     high 1       0.92      0.70      0.79       110\n",
      "\n",
      "avg / total       0.84      0.82      0.82       220\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAEXCAYAAABYh8V/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXRQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124dc2b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI1_model, y_HemoPI1_model, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI1_model, y_HemoPI1_model, cv=kfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_model, cv_preds)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI1_validation, y_HemoPI1_validation, cv=kfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        \n",
    "fig = sns.boxplot(data=results)\n",
    "fig.set_xticklabels(names)\n",
    "fig.set_title('Comparison of Binary Classifiers on HemoPI-1 dataset with 56 sequence-based descriptors')\n",
    "plt.xlabel('Binary Classifiers')\n",
    "plt.ylabel('Model Accuracy')\n",
    "plt.show()\n",
    "#plt.savefig(path.join(figpath, \"Figure3.1_Comparison of Binary Classifiers with 200 descriptors.pdf\"))\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-2 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both model and validation datasets (HemoPI-2 and HemoPI-3) are not balanced. We need to take that unbalance into consideration with 10-fold stratified cross-validation while computing binary classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg: Accuracy Score 67.99% (5.23%)\n",
      "logreg: Accuracy 67.98%\n",
      "logreg: Precision-Recall 65.21%\n",
      "logreg: Matthews Coefficient 35.03%\n",
      "logreg: Cohen Kappa Score 34.79%\n",
      "logreg: ROC AUC Score 67.22%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.67      0.59      0.63       370\n",
      "     high 1       0.69      0.76      0.72       442\n",
      "\n",
      "avg / total       0.68      0.68      0.68       812\n",
      "\n",
      "logreg: Accuracy 65.84%\n",
      "logreg: Precision-Recall 63.21%\n",
      "logreg: Matthews Coefficient 30.53%\n",
      "logreg: Cohen Kappa Score 29.83%\n",
      "logreg: ROC AUC Score 64.63%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.66      0.51      0.58        92\n",
      "     high 1       0.66      0.78      0.71       110\n",
      "\n",
      "avg / total       0.66      0.66      0.65       202\n",
      "\n",
      "knn: Accuracy Score 71.56% (3.20%)\n",
      "knn: Accuracy 71.55%\n",
      "knn: Precision-Recall 68.07%\n",
      "knn: Matthews Coefficient 42.35%\n",
      "knn: Cohen Kappa Score 42.10%\n",
      "knn: ROC AUC Score 70.85%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.71      0.63      0.67       370\n",
      "     high 1       0.72      0.79      0.75       442\n",
      "\n",
      "avg / total       0.72      0.72      0.71       812\n",
      "\n",
      "knn: Accuracy 63.37%\n",
      "knn: Precision-Recall 61.54%\n",
      "knn: Matthews Coefficient 25.34%\n",
      "knn: Cohen Kappa Score 24.81%\n",
      "knn: ROC AUC Score 62.18%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.62      0.49      0.55        92\n",
      "     high 1       0.64      0.75      0.69       110\n",
      "\n",
      "avg / total       0.63      0.63      0.63       202\n",
      "\n",
      "cart: Accuracy Score 69.57% (3.13%)\n",
      "cart: Accuracy 69.58%\n",
      "cart: Precision-Recall 66.99%\n",
      "cart: Matthews Coefficient 38.57%\n",
      "cart: Cohen Kappa Score 38.56%\n",
      "cart: ROC AUC Score 69.24%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.67      0.65      0.66       370\n",
      "     high 1       0.72      0.73      0.72       442\n",
      "\n",
      "avg / total       0.70      0.70      0.70       812\n",
      "\n",
      "cart: Accuracy 62.38%\n",
      "cart: Precision-Recall 61.91%\n",
      "cart: Matthews Coefficient 24.60%\n",
      "cart: Cohen Kappa Score 24.55%\n",
      "cart: ROC AUC Score 62.34%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.58      0.62      0.60        92\n",
      "     high 1       0.66      0.63      0.64       110\n",
      "\n",
      "avg / total       0.63      0.62      0.62       202\n",
      "\n",
      "rfc: Accuracy Score 68.98% (6.31%)\n",
      "rfc: Accuracy 68.97%\n",
      "rfc: Precision-Recall 65.96%\n",
      "rfc: Matthews Coefficient 37.05%\n",
      "rfc: Cohen Kappa Score 36.80%\n",
      "rfc: ROC AUC Score 68.21%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.68      0.60      0.64       370\n",
      "     high 1       0.69      0.77      0.73       442\n",
      "\n",
      "avg / total       0.69      0.69      0.69       812\n",
      "\n",
      "rfc: Accuracy 63.86%\n",
      "rfc: Precision-Recall 62.07%\n",
      "rfc: Matthews Coefficient 26.47%\n",
      "rfc: Cohen Kappa Score 26.16%\n",
      "rfc: ROC AUC Score 62.91%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.62      0.52      0.57        92\n",
      "     high 1       0.65      0.74      0.69       110\n",
      "\n",
      "avg / total       0.64      0.64      0.63       202\n",
      "\n",
      "gbc: Accuracy Score 76.73% (4.45%)\n",
      "gbc: Accuracy 76.72%\n",
      "gbc: Precision-Recall 72.88%\n",
      "gbc: Matthews Coefficient 52.92%\n",
      "gbc: Cohen Kappa Score 52.82%\n",
      "gbc: ROC AUC Score 76.26%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.76      0.71      0.74       370\n",
      "     high 1       0.77      0.81      0.79       442\n",
      "\n",
      "avg / total       0.77      0.77      0.77       812\n",
      "\n",
      "gbc: Accuracy 72.28%\n",
      "gbc: Precision-Recall 68.86%\n",
      "gbc: Matthews Coefficient 43.85%\n",
      "gbc: Cohen Kappa Score 43.71%\n",
      "gbc: ROC AUC Score 71.70%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.71      0.65      0.68        92\n",
      "     high 1       0.73      0.78      0.75       110\n",
      "\n",
      "avg / total       0.72      0.72      0.72       202\n",
      "\n",
      "adc: Accuracy Score 71.31% (5.47%)\n",
      "adc: Accuracy 71.31%\n",
      "adc: Precision-Recall 68.09%\n",
      "adc: Matthews Coefficient 41.89%\n",
      "adc: Cohen Kappa Score 41.78%\n",
      "adc: ROC AUC Score 70.76%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.70      0.65      0.67       370\n",
      "     high 1       0.72      0.77      0.74       442\n",
      "\n",
      "avg / total       0.71      0.71      0.71       812\n",
      "\n",
      "adc: Accuracy 73.76%\n",
      "adc: Precision-Recall 70.20%\n",
      "adc: Matthews Coefficient 46.89%\n",
      "adc: Cohen Kappa Score 46.77%\n",
      "adc: ROC AUC Score 73.24%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.73      0.67      0.70        92\n",
      "     high 1       0.74      0.79      0.77       110\n",
      "\n",
      "avg / total       0.74      0.74      0.74       202\n",
      "\n",
      "lda: Accuracy Score 69.96% (5.06%)\n",
      "lda: Accuracy 69.95%\n",
      "lda: Precision-Recall 66.62%\n",
      "lda: Matthews Coefficient 39.06%\n",
      "lda: Cohen Kappa Score 38.70%\n",
      "lda: ROC AUC Score 69.12%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.70      0.60      0.64       370\n",
      "     high 1       0.70      0.79      0.74       442\n",
      "\n",
      "avg / total       0.70      0.70      0.70       812\n",
      "\n",
      "lda: Accuracy 59.90%\n",
      "lda: Precision-Recall 59.66%\n",
      "lda: Matthews Coefficient 18.58%\n",
      "lda: Cohen Kappa Score 18.51%\n",
      "lda: ROC AUC Score 59.18%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.57      0.51      0.54        92\n",
      "     high 1       0.62      0.67      0.65       110\n",
      "\n",
      "avg / total       0.60      0.60      0.60       202\n",
      "\n",
      "qda: Accuracy Score 66.38% (5.26%)\n",
      "qda: Accuracy 66.38%\n",
      "qda: Precision-Recall 64.52%\n",
      "qda: Matthews Coefficient 32.15%\n",
      "qda: Cohen Kappa Score 32.15%\n",
      "qda: ROC AUC Score 66.06%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.63      0.62      0.63       370\n",
      "     high 1       0.69      0.70      0.69       442\n",
      "\n",
      "avg / total       0.66      0.66      0.66       812\n",
      "\n",
      "qda: Accuracy 60.89%\n",
      "qda: Precision-Recall 60.44%\n",
      "qda: Matthews Coefficient 20.83%\n",
      "qda: Cohen Kappa Score 20.80%\n",
      "qda: ROC AUC Score 60.36%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.57      0.54      0.56        92\n",
      "     high 1       0.63      0.66      0.65       110\n",
      "\n",
      "avg / total       0.61      0.61      0.61       202\n",
      "\n",
      "nb: Accuracy Score 62.32% (6.78%)\n",
      "nb: Accuracy 62.32%\n",
      "nb: Precision-Recall 61.74%\n",
      "nb: Matthews Coefficient 24.28%\n",
      "nb: Cohen Kappa Score 24.27%\n",
      "nb: ROC AUC Score 62.17%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.58      0.61      0.59       370\n",
      "     high 1       0.66      0.64      0.65       442\n",
      "\n",
      "avg / total       0.62      0.62      0.62       812\n",
      "\n",
      "nb: Accuracy 63.37%\n",
      "nb: Precision-Recall 62.01%\n",
      "nb: Matthews Coefficient 25.70%\n",
      "nb: Cohen Kappa Score 25.62%\n",
      "nb: ROC AUC Score 62.72%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.61      0.55      0.58        92\n",
      "     high 1       0.65      0.70      0.68       110\n",
      "\n",
      "avg / total       0.63      0.63      0.63       202\n",
      "\n",
      "svc_lr: Accuracy Score 61.94% (3.14%)\n",
      "svc_lr: Accuracy 61.95%\n",
      "svc_lr: Precision-Recall 59.68%\n",
      "svc_lr: Matthews Coefficient 22.97%\n",
      "svc_lr: Cohen Kappa Score 19.88%\n",
      "svc_lr: ROC AUC Score 59.52%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.67      0.32      0.44       370\n",
      "     high 1       0.60      0.87      0.71       442\n",
      "\n",
      "avg / total       0.64      0.62      0.59       812\n",
      "\n",
      "svc_lr: Accuracy 59.90%\n",
      "svc_lr: Precision-Recall 57.85%\n",
      "svc_lr: Matthews Coefficient 20.96%\n",
      "svc_lr: Cohen Kappa Score 13.71%\n",
      "svc_lr: ROC AUC Score 56.42%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.76      0.17      0.28        92\n",
      "     high 1       0.58      0.95      0.72       110\n",
      "\n",
      "avg / total       0.66      0.60      0.52       202\n",
      "\n",
      "svc_rbf: Accuracy Score 63.68% (4.53%)\n",
      "svc_rbf: Accuracy 63.67%\n",
      "svc_rbf: Precision-Recall 61.17%\n",
      "svc_rbf: Matthews Coefficient 26.21%\n",
      "svc_rbf: Cohen Kappa Score 24.38%\n",
      "svc_rbf: ROC AUC Score 61.81%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.67      0.41      0.51       370\n",
      "     high 1       0.63      0.83      0.71       442\n",
      "\n",
      "avg / total       0.64      0.64      0.62       812\n",
      "\n",
      "svc_rbf: Accuracy 62.38%\n",
      "svc_rbf: Precision-Recall 59.66%\n",
      "svc_rbf: Matthews Coefficient 25.28%\n",
      "svc_rbf: Cohen Kappa Score 20.03%\n",
      "svc_rbf: ROC AUC Score 59.50%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.74      0.27      0.40        92\n",
      "     high 1       0.60      0.92      0.73       110\n",
      "\n",
      "avg / total       0.66      0.62      0.58       202\n",
      "\n",
      "svc_poly: Accuracy Score 54.43% (0.22%)\n",
      "svc_poly: Accuracy 54.43%\n",
      "svc_poly: Precision-Recall 54.43%\n",
      "svc_poly: Matthews Coefficient 0.00%\n",
      "svc_poly: Cohen Kappa Score 0.00%\n",
      "svc_poly: ROC AUC Score 50.00%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.00      0.00      0.00       370\n",
      "     high 1       0.54      1.00      0.70       442\n",
      "\n",
      "avg / total       0.30      0.54      0.38       812\n",
      "\n",
      "svc_poly: Accuracy 54.46%\n",
      "svc_poly: Precision-Recall 54.46%\n",
      "svc_poly: Matthews Coefficient 0.00%\n",
      "svc_poly: Cohen Kappa Score 0.00%\n",
      "svc_poly: ROC AUC Score 50.00%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.00      0.00      0.00        92\n",
      "     high 1       0.54      1.00      0.71       110\n",
      "\n",
      "avg / total       0.30      0.54      0.38       202\n",
      "\n",
      "svc_sig: Accuracy Score 59.60% (2.84%)\n",
      "svc_sig: Accuracy 59.61%\n",
      "svc_sig: Precision-Recall 57.73%\n",
      "svc_sig: Matthews Coefficient 19.45%\n",
      "svc_sig: Cohen Kappa Score 13.30%\n",
      "svc_sig: ROC AUC Score 56.25%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.72      0.18      0.29       370\n",
      "     high 1       0.58      0.94      0.72       442\n",
      "\n",
      "avg / total       0.65      0.60      0.52       812\n",
      "\n",
      "svc_sig: Accuracy 54.46%\n",
      "svc_sig: Precision-Recall 54.46%\n",
      "svc_sig: Matthews Coefficient 0.00%\n",
      "svc_sig: Cohen Kappa Score 0.00%\n",
      "svc_sig: ROC AUC Score 50.00%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.00      0.00      0.00        92\n",
      "     high 1       0.54      1.00      0.71       110\n",
      "\n",
      "avg / total       0.30      0.54      0.38       202\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAEXCAYAAABYh8V/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125e25cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI2_model, y_HemoPI2_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI2_model, y_HemoPI2_model, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_model, cv_preds)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI2_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI2_validation, y_HemoPI2_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI2_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        \n",
    "fig = sns.boxplot(data=results)\n",
    "fig.set_xticklabels(names)\n",
    "fig.set_title('Comparison of Binary Classifiers on HemoPI-2 dataset with 56 sequence-based descriptors')\n",
    "plt.xlabel('Binary Classifiers')\n",
    "plt.ylabel('Model Accuracy')\n",
    "plt.show()\n",
    "#plt.savefig(path.join(figpath, \"Figure3.1_Comparison of Binary Classifiers with 200 descriptors.pdf\"))\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg: Accuracy Score 69.72% (2.09%)\n",
      "logreg: Accuracy 69.72%\n",
      "logreg: Precision-Recall 66.11%\n",
      "logreg: Matthews Coefficient 38.65%\n",
      "logreg: Cohen Kappa Score 37.75%\n",
      "logreg: ROC AUC Score 68.52%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.72      0.55      0.62       590\n",
      "     high 1       0.69      0.82      0.75       708\n",
      "\n",
      "avg / total       0.70      0.70      0.69      1298\n",
      "\n",
      "logreg: Accuracy 70.77%\n",
      "logreg: Precision-Recall 66.95%\n",
      "logreg: Matthews Coefficient 40.83%\n",
      "logreg: Cohen Kappa Score 40.04%\n",
      "logreg: ROC AUC Score 69.68%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.73      0.57      0.64       148\n",
      "     high 1       0.70      0.82      0.75       177\n",
      "\n",
      "avg / total       0.71      0.71      0.70       325\n",
      "\n",
      "knn: Accuracy Score 72.80% (4.11%)\n",
      "knn: Accuracy 72.80%\n",
      "knn: Precision-Recall 69.35%\n",
      "knn: Matthews Coefficient 44.90%\n",
      "knn: Cohen Kappa Score 44.74%\n",
      "knn: ROC AUC Score 72.20%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.72      0.66      0.69       590\n",
      "     high 1       0.73      0.79      0.76       708\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1298\n",
      "\n",
      "knn: Accuracy 65.85%\n",
      "knn: Precision-Recall 63.40%\n",
      "knn: Matthews Coefficient 30.54%\n",
      "knn: Cohen Kappa Score 30.10%\n",
      "knn: ROC AUC Score 64.82%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.65      0.53      0.59       148\n",
      "     high 1       0.66      0.76      0.71       177\n",
      "\n",
      "avg / total       0.66      0.66      0.65       325\n",
      "\n",
      "cart: Accuracy Score 68.95% (3.92%)\n",
      "cart: Accuracy 68.95%\n",
      "cart: Precision-Recall 66.62%\n",
      "cart: Matthews Coefficient 37.31%\n",
      "cart: Cohen Kappa Score 37.31%\n",
      "cart: ROC AUC Score 68.63%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.66      0.65      0.66       590\n",
      "     high 1       0.71      0.72      0.72       708\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1298\n",
      "\n",
      "cart: Accuracy 64.00%\n",
      "cart: Precision-Recall 62.74%\n",
      "cart: Matthews Coefficient 27.31%\n",
      "cart: Cohen Kappa Score 27.30%\n",
      "cart: ROC AUC Score 63.63%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.61      0.59      0.60       148\n",
      "     high 1       0.67      0.68      0.67       177\n",
      "\n",
      "avg / total       0.64      0.64      0.64       325\n",
      "\n",
      "rfc: Accuracy Score 72.41% (3.67%)\n",
      "rfc: Accuracy 72.42%\n",
      "rfc: Precision-Recall 68.29%\n",
      "rfc: Matthews Coefficient 44.26%\n",
      "rfc: Cohen Kappa Score 43.37%\n",
      "rfc: ROC AUC Score 71.30%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.75      0.59      0.66       590\n",
      "     high 1       0.71      0.84      0.77       708\n",
      "\n",
      "avg / total       0.73      0.72      0.72      1298\n",
      "\n",
      "rfc: Accuracy 66.77%\n",
      "rfc: Precision-Recall 64.09%\n",
      "rfc: Matthews Coefficient 32.46%\n",
      "rfc: Cohen Kappa Score 32.03%\n",
      "rfc: ROC AUC Score 65.78%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.66      0.55      0.60       148\n",
      "     high 1       0.67      0.77      0.72       177\n",
      "\n",
      "avg / total       0.67      0.67      0.66       325\n",
      "\n",
      "gbc: Accuracy Score 75.81% (2.56%)\n",
      "gbc: Accuracy 75.81%\n",
      "gbc: Precision-Recall 71.89%\n",
      "gbc: Matthews Coefficient 51.02%\n",
      "gbc: Cohen Kappa Score 50.81%\n",
      "gbc: ROC AUC Score 75.20%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.76      0.68      0.72       590\n",
      "     high 1       0.76      0.82      0.79       708\n",
      "\n",
      "avg / total       0.76      0.76      0.76      1298\n",
      "\n",
      "gbc: Accuracy 72.92%\n",
      "gbc: Precision-Recall 69.45%\n",
      "gbc: Matthews Coefficient 45.17%\n",
      "gbc: Cohen Kappa Score 45.05%\n",
      "gbc: ROC AUC Score 72.37%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.72      0.66      0.69       148\n",
      "     high 1       0.74      0.79      0.76       177\n",
      "\n",
      "avg / total       0.73      0.73      0.73       325\n",
      "\n",
      "adc: Accuracy Score 72.26% (3.11%)\n",
      "adc: Accuracy 72.27%\n",
      "adc: Precision-Recall 68.63%\n",
      "adc: Matthews Coefficient 43.77%\n",
      "adc: Cohen Kappa Score 43.44%\n",
      "adc: ROC AUC Score 71.48%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.72      0.63      0.67       590\n",
      "     high 1       0.72      0.80      0.76       708\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1298\n",
      "\n",
      "adc: Accuracy 71.38%\n",
      "adc: Precision-Recall 68.12%\n",
      "adc: Matthews Coefficient 42.03%\n",
      "adc: Cohen Kappa Score 41.89%\n",
      "adc: ROC AUC Score 70.80%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.70      0.64      0.67       148\n",
      "     high 1       0.72      0.77      0.75       177\n",
      "\n",
      "avg / total       0.71      0.71      0.71       325\n",
      "\n",
      "lda: Accuracy Score 70.80% (2.16%)\n",
      "lda: Accuracy 70.80%\n",
      "lda: Precision-Recall 66.88%\n",
      "lda: Matthews Coefficient 40.96%\n",
      "lda: Cohen Kappa Score 39.92%\n",
      "lda: ROC AUC Score 69.56%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.73      0.56      0.64       590\n",
      "     high 1       0.69      0.83      0.76       708\n",
      "\n",
      "avg / total       0.71      0.71      0.70      1298\n",
      "\n",
      "lda: Accuracy 70.77%\n",
      "lda: Precision-Recall 67.24%\n",
      "lda: Matthews Coefficient 40.74%\n",
      "lda: Cohen Kappa Score 40.31%\n",
      "lda: ROC AUC Score 69.90%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.71      0.60      0.65       148\n",
      "     high 1       0.70      0.80      0.75       177\n",
      "\n",
      "avg / total       0.71      0.71      0.70       325\n",
      "\n",
      "qda: Accuracy Score 65.87% (4.60%)\n",
      "qda: Accuracy 65.87%\n",
      "qda: Precision-Recall 64.04%\n",
      "qda: Matthews Coefficient 30.91%\n",
      "qda: Cohen Kappa Score 30.87%\n",
      "qda: ROC AUC Score 65.37%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.63      0.60      0.61       590\n",
      "     high 1       0.68      0.71      0.69       708\n",
      "\n",
      "avg / total       0.66      0.66      0.66      1298\n",
      "\n",
      "qda: Accuracy 59.38%\n",
      "qda: Precision-Recall 59.10%\n",
      "qda: Matthews Coefficient 17.15%\n",
      "qda: Cohen Kappa Score 16.92%\n",
      "qda: ROC AUC Score 58.34%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.57      0.47      0.51       148\n",
      "     high 1       0.61      0.70      0.65       177\n",
      "\n",
      "avg / total       0.59      0.59      0.59       325\n",
      "\n",
      "nb: Accuracy Score 64.40% (4.26%)\n",
      "nb: Accuracy 64.41%\n",
      "nb: Precision-Recall 62.83%\n",
      "nb: Matthews Coefficient 27.80%\n",
      "nb: Cohen Kappa Score 27.71%\n",
      "nb: ROC AUC Score 63.76%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.62      0.57      0.59       590\n",
      "     high 1       0.66      0.71      0.68       708\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1298\n",
      "\n",
      "nb: Accuracy 65.85%\n",
      "nb: Precision-Recall 63.98%\n",
      "nb: Matthews Coefficient 30.91%\n",
      "nb: Cohen Kappa Score 30.88%\n",
      "nb: ROC AUC Score 65.38%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.63      0.60      0.62       148\n",
      "     high 1       0.68      0.71      0.69       177\n",
      "\n",
      "avg / total       0.66      0.66      0.66       325\n",
      "\n",
      "svc_lr: Accuracy Score 65.41% (2.89%)\n",
      "svc_lr: Accuracy 65.41%\n",
      "svc_lr: Precision-Recall 62.01%\n",
      "svc_lr: Matthews Coefficient 30.94%\n",
      "svc_lr: Cohen Kappa Score 27.23%\n",
      "svc_lr: ROC AUC Score 63.05%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.74      0.37      0.49       590\n",
      "     high 1       0.63      0.89      0.74       708\n",
      "\n",
      "avg / total       0.68      0.65      0.63      1298\n",
      "\n",
      "svc_lr: Accuracy 66.46%\n",
      "svc_lr: Precision-Recall 62.81%\n",
      "svc_lr: Matthews Coefficient 33.01%\n",
      "svc_lr: Cohen Kappa Score 29.78%\n",
      "svc_lr: ROC AUC Score 64.34%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.74      0.41      0.52       148\n",
      "     high 1       0.64      0.88      0.74       177\n",
      "\n",
      "avg / total       0.69      0.66      0.64       325\n",
      "\n",
      "svc_rbf: Accuracy Score 66.26% (2.66%)\n",
      "svc_rbf: Accuracy 66.26%\n",
      "svc_rbf: Precision-Recall 62.71%\n",
      "svc_rbf: Matthews Coefficient 32.51%\n",
      "svc_rbf: Cohen Kappa Score 29.25%\n",
      "svc_rbf: ROC AUC Score 64.07%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.74      0.40      0.52       590\n",
      "     high 1       0.64      0.88      0.74       708\n",
      "\n",
      "avg / total       0.68      0.66      0.64      1298\n",
      "\n",
      "svc_rbf: Accuracy 66.15%\n",
      "svc_rbf: Precision-Recall 62.77%\n",
      "svc_rbf: Matthews Coefficient 31.88%\n",
      "svc_rbf: Cohen Kappa Score 29.42%\n",
      "svc_rbf: ROC AUC Score 64.22%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.72      0.43      0.53       148\n",
      "     high 1       0.64      0.86      0.73       177\n",
      "\n",
      "avg / total       0.68      0.66      0.64       325\n",
      "\n",
      "svc_poly: Accuracy Score 54.55% (0.14%)\n",
      "svc_poly: Accuracy 54.55%\n",
      "svc_poly: Precision-Recall 54.55%\n",
      "svc_poly: Matthews Coefficient 0.00%\n",
      "svc_poly: Cohen Kappa Score 0.00%\n",
      "svc_poly: ROC AUC Score 50.00%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.00      0.00      0.00       590\n",
      "     high 1       0.55      1.00      0.71       708\n",
      "\n",
      "avg / total       0.30      0.55      0.39      1298\n",
      "\n",
      "svc_poly: Accuracy 54.46%\n",
      "svc_poly: Precision-Recall 54.46%\n",
      "svc_poly: Matthews Coefficient 0.00%\n",
      "svc_poly: Cohen Kappa Score 0.00%\n",
      "svc_poly: ROC AUC Score 50.00%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.00      0.00      0.00       148\n",
      "     high 1       0.54      1.00      0.71       177\n",
      "\n",
      "avg / total       0.30      0.54      0.38       325\n",
      "\n",
      "svc_sig: Accuracy Score 63.41% (2.87%)\n",
      "svc_sig: Accuracy 63.41%\n",
      "svc_sig: Precision-Recall 60.45%\n",
      "svc_sig: Matthews Coefficient 27.24%\n",
      "svc_sig: Cohen Kappa Score 22.37%\n",
      "svc_sig: ROC AUC Score 60.64%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.74      0.30      0.43       590\n",
      "     high 1       0.61      0.91      0.73       708\n",
      "\n",
      "avg / total       0.67      0.63      0.59      1298\n",
      "\n",
      "svc_sig: Accuracy 63.38%\n",
      "svc_sig: Precision-Recall 60.28%\n",
      "svc_sig: Matthews Coefficient 27.94%\n",
      "svc_sig: Cohen Kappa Score 22.18%\n",
      "svc_sig: ROC AUC Score 60.52%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.76      0.28      0.41       148\n",
      "     high 1       0.61      0.93      0.73       177\n",
      "\n",
      "avg / total       0.68      0.63      0.59       325\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAEXCAYAAABYh8V/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2v8H8DvbgS285PwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12539d290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI3_model, y_HemoPI3_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI3_model, y_HemoPI3_model, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_model, cv_preds)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI3_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI3_validation, y_HemoPI3_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI3_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        \n",
    "fig = sns.boxplot(data=results)\n",
    "fig.set_xticklabels(names)\n",
    "fig.set_title('Comparison of Binary Classifiers on HemoPI-3 dataset with 56 sequence-based descriptors')\n",
    "plt.xlabel('Binary Classifiers')\n",
    "plt.ylabel('Model Accuracy')\n",
    "plt.show()\n",
    "#plt.savefig(path.join(figpath, \"Figure3.1_Comparison of Binary Classifiers with 200 descriptors.pdf\"))\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among binary classifiers for HemoPI-1, -2 and -3 datasets, GBC is the best performer with model accuracies 94/76.7/76% and validation accuracies 90.4/72.3/72.9%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering variables (descriptors) with Recursive Feature Elimination (RFE) to best models \n",
    "RFECV does not work with SVM kernel RBF (only linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_models = []\n",
    "top_models.append(('logreg', LogisticRegression(fit_intercept=True)))\n",
    "top_models.append(('rfc', RandomForestClassifier(random_state=seed)))\n",
    "top_models.append(('gbc', GradientBoostingClassifier(random_state=seed)))\n",
    "top_models.append(('lda', LinearDiscriminantAnalysis()))\n",
    "top_models.append(('svc_rbf', SVC(probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc: Accuracy Score 95.03% (2.53%)\n",
      "Optimal number of features : 31\n",
      "\n",
      "gbc: Precision-Recall 92.78%\n",
      "gbc: Matthews Coefficient 90.05%\n",
      "gbc: Cohen Kappa Score 90.05%\n",
      "gbc: ROC AUC Score 95.02%\n",
      "\n",
      "gbc: Accuracy 90.45%\n",
      "gbc: Precision-Recall 86.45%\n",
      "gbc: Matthews Coefficient 80.91%\n",
      "gbc: Cohen Kappa Score 80.91%\n",
      "gbc: ROC AUC Score 90.45%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in top_models:\n",
    "    \n",
    "    # Apply RFECV\n",
    "    rfecv_model = RFECV(model, step=1, cv=kfold)\n",
    "    rfecv = rfecv_model.fit(X_HemoPI1_model, y_HemoPI1_model)\n",
    "    X_HemoPI1_model_RFE = rfecv.transform(X_HemoPI1_model)\n",
    "    X_HemoPI1_val_RFE = rfecv.transform(X_HemoPI1_validation)\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI1_model_RFE, y_HemoPI1_model, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (rfecv.n_features_))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI1_model_RFE, y_HemoPI1_model, cv=kfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI1_val_RFE, y_HemoPI1_validation, cv=kfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc: Accuracy Score 72.79% (4.60%)\n",
      "Optimal number of features : 34\n",
      "\n",
      "rfc: Precision-Recall 70.79%\n",
      "rfc: Matthews Coefficient 45.96%\n",
      "rfc: Cohen Kappa Score 45.67%\n",
      "rfc: ROC AUC Score 73.06%\n",
      "\n",
      "rfc: Accuracy 69.80%\n",
      "rfc: Precision-Recall 68.26%\n",
      "rfc: Matthews Coefficient 40.15%\n",
      "rfc: Cohen Kappa Score 39.82%\n",
      "rfc: ROC AUC Score 70.14%\n",
      "\n",
      "gbc: Accuracy Score 77.84% (2.99%)\n",
      "Optimal number of features : 15\n",
      "\n",
      "gbc: Precision-Recall 74.21%\n",
      "gbc: Matthews Coefficient 55.22%\n",
      "gbc: Cohen Kappa Score 55.20%\n",
      "gbc: ROC AUC Score 77.52%\n",
      "\n",
      "gbc: Accuracy 73.27%\n",
      "gbc: Precision-Recall 69.84%\n",
      "gbc: Matthews Coefficient 45.90%\n",
      "gbc: Cohen Kappa Score 45.82%\n",
      "gbc: ROC AUC Score 72.79%\n",
      "\n",
      "adc: Accuracy Score 74.26% (3.39%)\n",
      "Optimal number of features : 24\n",
      "\n",
      "adc: Precision-Recall 70.56%\n",
      "adc: Matthews Coefficient 47.90%\n",
      "adc: Cohen Kappa Score 47.76%\n",
      "adc: ROC AUC Score 73.72%\n",
      "\n",
      "adc: Accuracy 65.84%\n",
      "adc: Precision-Recall 64.04%\n",
      "adc: Matthews Coefficient 30.97%\n",
      "adc: Cohen Kappa Score 30.95%\n",
      "adc: ROC AUC Score 65.43%\n",
      "\n",
      "lda: Accuracy Score 69.96% (5.21%)\n",
      "Optimal number of features : 49\n",
      "\n",
      "lda: Precision-Recall 66.54%\n",
      "lda: Matthews Coefficient 39.06%\n",
      "lda: Cohen Kappa Score 38.61%\n",
      "lda: ROC AUC Score 69.05%\n",
      "\n",
      "lda: Accuracy 61.39%\n",
      "lda: Precision-Recall 60.59%\n",
      "lda: Matthews Coefficient 21.57%\n",
      "lda: Cohen Kappa Score 21.46%\n",
      "lda: ROC AUC Score 60.63%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in top_models:\n",
    "    \n",
    "    # Apply RFECV\n",
    "    rfecv_model = RFECV(model, step=1, cv=skfold)\n",
    "    rfecv = rfecv_model.fit(X_HemoPI2_model, y_HemoPI2_model)\n",
    "    X_HemoPI2_model_RFE = rfecv.transform(X_HemoPI2_model)\n",
    "    X_HemoPI2_val_RFE = rfecv.transform(X_HemoPI2_validation)\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI2_model_RFE, y_HemoPI2_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (rfecv.n_features_))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI2_model_RFE, y_HemoPI2_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI2_val_RFE, y_HemoPI2_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc: Accuracy Score 75.03% (3.62%)\n",
      "Optimal number of features : 22\n",
      "\n",
      "rfc: Precision-Recall 72.35%\n",
      "rfc: Matthews Coefficient 49.91%\n",
      "rfc: Cohen Kappa Score 49.86%\n",
      "rfc: ROC AUC Score 75.03%\n",
      "\n",
      "rfc: Accuracy 69.23%\n",
      "rfc: Precision-Recall 67.11%\n",
      "rfc: Matthews Coefficient 38.20%\n",
      "rfc: Cohen Kappa Score 38.17%\n",
      "rfc: ROC AUC Score 69.15%\n",
      "\n",
      "gbc: Accuracy Score 75.73% (2.37%)\n",
      "Optimal number of features : 55\n",
      "\n",
      "gbc: Precision-Recall 71.83%\n",
      "gbc: Matthews Coefficient 50.87%\n",
      "gbc: Cohen Kappa Score 50.66%\n",
      "gbc: ROC AUC Score 75.13%\n",
      "\n",
      "gbc: Accuracy 72.00%\n",
      "gbc: Precision-Recall 68.71%\n",
      "gbc: Matthews Coefficient 43.31%\n",
      "gbc: Cohen Kappa Score 43.20%\n",
      "gbc: ROC AUC Score 71.47%\n",
      "\n",
      "adc: Accuracy Score 72.57% (2.72%)\n",
      "Optimal number of features : 12\n",
      "\n",
      "adc: Precision-Recall 68.95%\n",
      "adc: Matthews Coefficient 44.41%\n",
      "adc: Cohen Kappa Score 44.12%\n",
      "adc: ROC AUC Score 71.84%\n",
      "\n",
      "adc: Accuracy 68.62%\n",
      "adc: Precision-Recall 65.59%\n",
      "adc: Matthews Coefficient 36.30%\n",
      "adc: Cohen Kappa Score 35.95%\n",
      "adc: ROC AUC Score 67.75%\n",
      "\n",
      "lda: Accuracy Score 71.42% (2.77%)\n",
      "Optimal number of features : 16\n",
      "\n",
      "lda: Precision-Recall 67.15%\n",
      "lda: Matthews Coefficient 42.47%\n",
      "lda: Cohen Kappa Score 40.98%\n",
      "lda: ROC AUC Score 70.01%\n",
      "\n",
      "lda: Accuracy 72.00%\n",
      "lda: Precision-Recall 67.93%\n",
      "lda: Matthews Coefficient 43.40%\n",
      "lda: Cohen Kappa Score 42.57%\n",
      "lda: ROC AUC Score 70.92%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in top_models:\n",
    "    \n",
    "    # Apply RFECV\n",
    "    rfecv_model = RFECV(model, step=1, cv=skfold)\n",
    "    rfecv = rfecv_model.fit(X_HemoPI3_model, y_HemoPI3_model)\n",
    "    X_HemoPI3_model_RFE = rfecv.transform(X_HemoPI3_model)\n",
    "    X_HemoPI3_val_RFE = rfecv.transform(X_HemoPI3_validation)\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI3_model_RFE, y_HemoPI3_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (rfecv.n_features_))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI3_model_RFE, y_HemoPI3_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI3_val_RFE, y_HemoPI3_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering descriptors using Backward Elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_models = []\n",
    "top_models.append(('logreg', LogisticRegression(fit_intercept=True)))\n",
    "top_models.append(('rfc', RandomForestClassifier(random_state=seed)))\n",
    "top_models.append(('gbc', GradientBoostingClassifier(random_state=seed)))\n",
    "top_models.append(('lda', LinearDiscriminantAnalysis()))\n",
    "top_models.append(('svc_rbf', SVC(probability=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                3.749423e-05\n",
       "H_Eisenberg          6.752051e-01\n",
       "uH_Eisenberg         2.680693e-01\n",
       "H_GRAVY              1.224396e-03\n",
       "uH_GRAVY             6.926257e-01\n",
       "Z3_1                 9.282889e-04\n",
       "Z3_2                 6.619114e-01\n",
       "Z3_3                 9.779918e-03\n",
       " Z5_1                4.319115e-01\n",
       "Z5_2                 2.225203e-01\n",
       "Z5_3                 2.787501e-03\n",
       " Z5_4                8.416010e-01\n",
       "Z5_5                 1.043847e-01\n",
       "S_AASI               2.809502e-01\n",
       " uS_AASI             1.508249e-02\n",
       " modlas_ABHPRK       4.289635e-02\n",
       " H_argos             4.723534e-03\n",
       " uH_argos            2.956799e-01\n",
       " B_Builkiness        4.223052e-08\n",
       " uB_Builkiness       1.822707e-03\n",
       " charge_phys         6.520904e-01\n",
       " charge_acid         4.129462e-01\n",
       " Ez                  1.026665e-01\n",
       " flexibility         4.717868e-02\n",
       " u_flexibility       6.146913e-02\n",
       " Grantham            2.283128e-02\n",
       " H_HoppWoods         4.821138e-01\n",
       " uH-HoppWoods        3.788767e-01\n",
       " ISAECI              2.288481e-05\n",
       " H_Janin             3.494943e-02\n",
       " uH_Janin            2.483764e-04\n",
       " H_KyteDoolittle     1.249145e-03\n",
       " uH_KyteDoolittle    6.057716e-01\n",
       " F_Levitt            3.960281e-08\n",
       " uF_Levitt           4.583965e-01\n",
       " MSS_shape           4.730419e-03\n",
       " u_MSS_shape         1.799517e-01\n",
       " MSW                 4.485645e-03\n",
       " pepArc              4.717571e-01\n",
       " pepcats             1.812780e-01\n",
       " polarity            5.276132e-02\n",
       " u_polarity          4.438971e-01\n",
       " PPCALI              1.014230e-01\n",
       " refractivity        4.692381e-09\n",
       " u_refractivity      2.169955e-01\n",
       " t_scale             1.115177e-03\n",
       " TM_tend             7.903198e-01\n",
       " u_TM_tend           7.552169e-03\n",
       "Length               1.129501e-04\n",
       "BomanIndex           5.588781e-07\n",
       "Aromaticity          5.051210e-05\n",
       "AliphaticIndex       4.109861e-03\n",
       "InstabilityIndex     6.200567e-01\n",
       " NetCharge           1.732308e-11\n",
       " MW                  3.987295e-04\n",
       " IsoelectricPoint    5.276219e-07\n",
       " HydrophobicRatio    3.874178e-08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_1 = sm.add_constant(X_HemoPI1_model)\n",
    "\n",
    "#Fitting sm.OLS model\n",
    "model = sm.OLS(y_HemoPI1_model,X_1).fit()\n",
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z3_1', 'Z5_2', ' uS_AASI', ' modlas_ABHPRK', ' B_Builkiness', ' uB_Builkiness', ' u_flexibility', ' H_HoppWoods', ' ISAECI', ' uH_Janin', ' F_Levitt', ' MSS_shape', ' u_MSS_shape', ' refractivity', ' t_scale', ' u_TM_tend', 'Length', 'BomanIndex', 'Aromaticity', 'AliphaticIndex', ' NetCharge', ' MW', ' IsoelectricPoint']\n"
     ]
    }
   ],
   "source": [
    "cols = list(X_HemoPI1_model.columns)\n",
    "pmax = 1\n",
    "\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X_HemoPI1_model[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y_HemoPI1_model,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "selected_features_BE = cols\n",
    "print selected_features_BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_HemoPI1_model_BE = X_HemoPI1_model[selected_features_BE]\n",
    "X_HemoPI1_val_BE = X_HemoPI1_validation[selected_features_BE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc: Accuracy Score 93.67% (2.41%)\n",
      "Optimal number of features : 23\n",
      "\n",
      "rfc: Precision-Recall 91.80%\n",
      "rfc: Matthews Coefficient 87.42%\n",
      "rfc: Cohen Kappa Score 87.33%\n",
      "rfc: ROC AUC Score 93.67%\n",
      "\n",
      "rfc: Accuracy 85.91%\n",
      "rfc: Precision-Recall 81.46%\n",
      "rfc: Matthews Coefficient 71.89%\n",
      "rfc: Cohen Kappa Score 71.82%\n",
      "rfc: ROC AUC Score 85.91%\n",
      "\n",
      "gbc: Accuracy Score 94.46% (3.20%)\n",
      "Optimal number of features : 23\n",
      "\n",
      "gbc: Precision-Recall 92.13%\n",
      "gbc: Matthews Coefficient 88.92%\n",
      "gbc: Cohen Kappa Score 88.91%\n",
      "gbc: ROC AUC Score 94.46%\n",
      "\n",
      "gbc: Accuracy 89.09%\n",
      "gbc: Precision-Recall 85.71%\n",
      "gbc: Matthews Coefficient 78.30%\n",
      "gbc: Cohen Kappa Score 78.18%\n",
      "gbc: ROC AUC Score 89.09%\n",
      "\n",
      "lda: Accuracy Score 94.12% (2.89%)\n",
      "Optimal number of features : 23\n",
      "\n",
      "lda: Precision-Recall 91.01%\n",
      "lda: Matthews Coefficient 88.27%\n",
      "lda: Cohen Kappa Score 88.24%\n",
      "lda: ROC AUC Score 94.12%\n",
      "\n",
      "lda: Accuracy 93.64%\n",
      "lda: Precision-Recall 91.21%\n",
      "lda: Matthews Coefficient 87.29%\n",
      "lda: Cohen Kappa Score 87.27%\n",
      "lda: ROC AUC Score 93.64%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in top_models:\n",
    "    \n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI1_model_BE, y_HemoPI1_model, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (len(selected_features_BE)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI1_model_BE, y_HemoPI1_model, cv=kfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI1_val_BE, y_HemoPI1_validation, cv=kfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                0.576001\n",
       "H_Eisenberg          0.142720\n",
       "uH_Eisenberg         0.752683\n",
       "H_GRAVY              0.719462\n",
       "uH_GRAVY             0.217019\n",
       "Z3_1                 0.045691\n",
       "Z3_2                 0.095312\n",
       "Z3_3                 0.051957\n",
       " Z5_1                0.024312\n",
       "Z5_2                 0.002830\n",
       "Z5_3                 0.017842\n",
       " Z5_4                0.873265\n",
       "Z5_5                 0.017324\n",
       "S_AASI               0.005040\n",
       " uS_AASI             0.043334\n",
       " modlas_ABHPRK       0.192662\n",
       " H_argos             0.934322\n",
       " uH_argos            0.330768\n",
       " B_Builkiness        0.056720\n",
       " uB_Builkiness       0.107908\n",
       " charge_phys         0.987171\n",
       " charge_acid         0.029209\n",
       " Ez                  0.830124\n",
       " flexibility         0.341358\n",
       " u_flexibility       0.076846\n",
       " Grantham            0.058629\n",
       " H_HoppWoods         0.074685\n",
       " uH-HoppWoods        0.024668\n",
       " ISAECI              0.892434\n",
       " H_Janin             0.402711\n",
       " uH_Janin            0.156244\n",
       " H_KyteDoolittle     0.808418\n",
       " uH_KyteDoolittle    0.417382\n",
       " F_Levitt            0.015748\n",
       " uF_Levitt           0.103109\n",
       " MSS_shape           0.001343\n",
       " u_MSS_shape         0.320974\n",
       " MSW                 0.031540\n",
       " pepArc              0.351958\n",
       " pepcats             0.577859\n",
       " polarity            0.718220\n",
       " u_polarity          0.286327\n",
       " PPCALI              0.127387\n",
       " refractivity        0.915970\n",
       " u_refractivity      0.668651\n",
       " t_scale             0.478884\n",
       " TM_tend             0.000391\n",
       " u_TM_tend           0.050199\n",
       "Length               0.542648\n",
       "BomanIndex           0.757409\n",
       "Aromaticity          0.046684\n",
       "AliphaticIndex       0.963330\n",
       "InstabilityIndex     0.291306\n",
       " NetCharge           0.284612\n",
       " MW                  0.369755\n",
       " IsoelectricPoint    0.071640\n",
       " HydrophobicRatio    0.540659\n",
       "dtype: float64"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_1 = sm.add_constant(X_HemoPI2_model)\n",
    "\n",
    "#Fitting sm.OLS model\n",
    "model = sm.OLS(y_HemoPI2_model,X_1).fit()\n",
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uH_GRAVY', 'Z3_3', 'S_AASI', ' uS_AASI', ' B_Builkiness', ' uB_Builkiness', ' u_flexibility', ' Grantham', ' uH-HoppWoods', ' uF_Levitt', ' u_MSS_shape', ' MSW', ' TM_tend', ' u_TM_tend', ' MW', ' IsoelectricPoint']\n"
     ]
    }
   ],
   "source": [
    "cols = list(X_HemoPI2_model.columns)\n",
    "pmax = 1\n",
    "\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X_HemoPI2_model[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y_HemoPI2_model,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "selected_features_BE = cols\n",
    "print selected_features_BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_HemoPI2_model_BE = X_HemoPI2_model[selected_features_BE]\n",
    "X_HemoPI2_val_BE = X_HemoPI2_validation[selected_features_BE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc: Accuracy Score 74.88% (6.23%)\n",
      "Optimal number of features : 16\n",
      "\n",
      "rfc: Precision-Recall 72.46%\n",
      "rfc: Matthews Coefficient 49.87%\n",
      "rfc: Cohen Kappa Score 49.71%\n",
      "rfc: ROC AUC Score 75.03%\n",
      "\n",
      "rfc: Accuracy 64.85%\n",
      "rfc: Precision-Recall 63.59%\n",
      "rfc: Matthews Coefficient 29.34%\n",
      "rfc: Cohen Kappa Score 29.33%\n",
      "rfc: ROC AUC Score 64.70%\n",
      "\n",
      "gbc: Accuracy Score 74.26% (4.64%)\n",
      "Optimal number of features : 16\n",
      "\n",
      "gbc: Precision-Recall 70.45%\n",
      "gbc: Matthews Coefficient 47.89%\n",
      "gbc: Cohen Kappa Score 47.69%\n",
      "gbc: ROC AUC Score 73.65%\n",
      "\n",
      "gbc: Accuracy 68.81%\n",
      "gbc: Precision-Recall 65.99%\n",
      "gbc: Matthews Coefficient 36.77%\n",
      "gbc: Cohen Kappa Score 36.62%\n",
      "gbc: ROC AUC Score 68.16%\n",
      "\n",
      "lda: Accuracy Score 70.09% (5.35%)\n",
      "Optimal number of features : 16\n",
      "\n",
      "lda: Precision-Recall 66.54%\n",
      "lda: Matthews Coefficient 39.34%\n",
      "lda: Cohen Kappa Score 38.77%\n",
      "lda: ROC AUC Score 69.10%\n",
      "\n",
      "lda: Accuracy 65.35%\n",
      "lda: Precision-Recall 62.82%\n",
      "lda: Matthews Coefficient 29.49%\n",
      "lda: Cohen Kappa Score 28.74%\n",
      "lda: ROC AUC Score 64.09%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in top_models:\n",
    "    \n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI2_model_BE, y_HemoPI2_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (len(selected_features_BE)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI2_model_BE, y_HemoPI2_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI2_val_BE, y_HemoPI2_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                0.000134\n",
       "H_Eisenberg          0.165076\n",
       "uH_Eisenberg         0.588407\n",
       "H_GRAVY              0.325153\n",
       "uH_GRAVY             0.279928\n",
       "Z3_1                 0.229263\n",
       "Z3_2                 0.041047\n",
       "Z3_3                 0.318791\n",
       " Z5_1                0.007984\n",
       "Z5_2                 0.009601\n",
       "Z5_3                 0.216351\n",
       " Z5_4                0.008761\n",
       "Z5_5                 0.958637\n",
       "S_AASI               0.348265\n",
       " uS_AASI             0.554425\n",
       " modlas_ABHPRK       0.006019\n",
       " H_argos             0.063589\n",
       " uH_argos            0.691364\n",
       " B_Builkiness        0.607749\n",
       " uB_Builkiness       0.226105\n",
       " charge_phys         0.103523\n",
       " charge_acid         0.834881\n",
       " Ez                  0.001341\n",
       " flexibility         0.058778\n",
       " u_flexibility       0.062569\n",
       " Grantham            0.009879\n",
       " H_HoppWoods         0.539139\n",
       " uH-HoppWoods        0.321634\n",
       " ISAECI              0.027810\n",
       " H_Janin             0.216097\n",
       " uH_Janin            0.181324\n",
       " H_KyteDoolittle     0.266479\n",
       " uH_KyteDoolittle    0.382379\n",
       " F_Levitt            0.144492\n",
       " uF_Levitt           0.344235\n",
       " MSS_shape           0.000144\n",
       " u_MSS_shape         0.560649\n",
       " MSW                 0.847776\n",
       " pepArc              0.605316\n",
       " pepcats             0.853280\n",
       " polarity            0.343150\n",
       " u_polarity          0.825277\n",
       " PPCALI              0.829567\n",
       " refractivity        0.210120\n",
       " u_refractivity      0.389355\n",
       " t_scale             0.219931\n",
       " TM_tend             0.003437\n",
       " u_TM_tend           0.070041\n",
       "Length               0.854356\n",
       "BomanIndex           0.102818\n",
       "Aromaticity          0.440645\n",
       "AliphaticIndex       0.075860\n",
       "InstabilityIndex     0.008516\n",
       " NetCharge           0.145124\n",
       " MW                  0.470273\n",
       " IsoelectricPoint    0.688420\n",
       " HydrophobicRatio    0.803835\n",
       "dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_1 = sm.add_constant(X_HemoPI3_model)\n",
    "\n",
    "#Fitting sm.OLS model\n",
    "model = sm.OLS(y_HemoPI3_model,X_1).fit()\n",
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Z3_1', 'Z3_2', 'Z3_3', ' Z5_1', 'S_AASI', ' modlas_ABHPRK', ' uB_Builkiness', ' Ez', ' flexibility', ' Grantham', ' ISAECI', ' H_KyteDoolittle', ' MSS_shape', ' u_TM_tend', 'AliphaticIndex', 'InstabilityIndex', ' NetCharge', ' MW']\n"
     ]
    }
   ],
   "source": [
    "cols = list(X_HemoPI3_model.columns)\n",
    "pmax = 1\n",
    "\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X_HemoPI3_model[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y_HemoPI3_model,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "selected_features_BE = cols\n",
    "print selected_features_BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_HemoPI3_model_BE = X_HemoPI3_model[selected_features_BE]\n",
    "X_HemoPI3_val_BE = X_HemoPI3_validation[selected_features_BE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc: Accuracy Score 74.35% (2.31%)\n",
      "Optimal number of features : 18\n",
      "\n",
      "rfc: Precision-Recall 71.69%\n",
      "rfc: Matthews Coefficient 48.50%\n",
      "rfc: Cohen Kappa Score 48.46%\n",
      "rfc: ROC AUC Score 74.32%\n",
      "\n",
      "rfc: Accuracy 65.85%\n",
      "rfc: Precision-Recall 64.23%\n",
      "rfc: Matthews Coefficient 31.18%\n",
      "rfc: Cohen Kappa Score 31.18%\n",
      "rfc: ROC AUC Score 65.60%\n",
      "\n",
      "gbc: Accuracy Score 74.42% (2.38%)\n",
      "Optimal number of features : 18\n",
      "\n",
      "gbc: Precision-Recall 70.63%\n",
      "gbc: Matthews Coefficient 48.19%\n",
      "gbc: Cohen Kappa Score 47.96%\n",
      "gbc: ROC AUC Score 73.77%\n",
      "\n",
      "gbc: Accuracy 69.23%\n",
      "gbc: Precision-Recall 66.49%\n",
      "gbc: Matthews Coefficient 37.70%\n",
      "gbc: Cohen Kappa Score 37.62%\n",
      "gbc: ROC AUC Score 68.71%\n",
      "\n",
      "svc_rbf: Accuracy Score 65.41% (3.43%)\n",
      "Optimal number of features : 18\n",
      "\n",
      "svc_rbf: Precision-Recall 62.30%\n",
      "svc_rbf: Matthews Coefficient 30.16%\n",
      "svc_rbf: Cohen Kappa Score 27.76%\n",
      "svc_rbf: ROC AUC Score 63.40%\n",
      "\n",
      "svc_rbf: Accuracy 64.62%\n",
      "svc_rbf: Precision-Recall 61.25%\n",
      "svc_rbf: Matthews Coefficient 29.97%\n",
      "svc_rbf: Cohen Kappa Score 25.23%\n",
      "svc_rbf: ROC AUC Score 62.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in top_models:\n",
    "    \n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI3_model_BE, y_HemoPI3_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (len(selected_features_BE)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI3_model_BE, y_HemoPI3_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI3_val_BE, y_HemoPI3_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of the method for feature elimination, LDA is the best binary classifier for HemoPI-1 dataset while GBC is the best model with other datasets (HemoPI-2, HemoPI-3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching optimised models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Search functions for each model's hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=seed, fit_intercept=True)\n",
    "\n",
    "def logreg_param_selection(X, y, fold):\n",
    "    param_grid = { \n",
    "        #'penalty' : ['l1'],\n",
    "        'penalty' : ['l2'],\n",
    "        'C' : [0.1, 1, 10, 100, 1000],\n",
    "        'tol' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        #'solver': ['liblinear', 'saga']\n",
    "        'solver': ['newton-cg', 'lbfgs', 'sag']\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=fold)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "def rfc_param_selection(X, y, fold):\n",
    "    param_grid = { \n",
    "        'n_estimators' : filter(lambda x: x % 25 == 0, list(range(25,300))),\n",
    "        'max_depth': filter(lambda x: x % 2 == 0, list(range(2,40))),\n",
    "        'min_samples_leaf': filter(lambda x: x % 2 == 0, list(range(2,10))),\n",
    "        'max_features': [None, 'sqrt', 'log2']}\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=fold)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=seed) \n",
    "\n",
    "def gbc_param_selection(X, y, fold):\n",
    "    param_grid = { \n",
    "        'n_estimators' : filter(lambda x: x % 100 == 0, list(range(100,1000))),\n",
    "        'max_depth': filter(lambda x: x % 2 == 0, list(range(2,40))),\n",
    "        'min_samples_leaf': filter(lambda x: x % 2 == 0, list(range(2,10))),\n",
    "        'max_features': [None, 'sqrt', 'log2']}\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=gbc, param_grid=param_grid, cv=fold)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis() \n",
    "\n",
    "def lda_param_selection(X, y, fold):\n",
    "    param_grid = {'solver': ['svd', 'lsqr'], \n",
    "                  'tol' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "                 }\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=fold)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_rbf = SVC(kernel='rbf', probability=True) \n",
    "\n",
    "def svc_param_selection(X, y, fold):\n",
    "    param_grid = { \n",
    "        'C' : [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=svc_rbf, param_grid=param_grid, cv=fold)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tuning hyperparameters of binary classifiers for HemoPI-1 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all modlamp descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters were searched on institutional server Mazorka\n",
    "logreg_param_selection(X_HemoPI1_model, y_HemoPI1_model, kfold)\n",
    "rfc_param_selection(X_HemoPI1_model, y_HemoPI1_model, kfold)\n",
    "gbc_param_selection(X_HemoPI1_model, y_HemoPI1_model, kfold)\n",
    "lda_param_selection(X_HemoPI1_model, y_HemoPI1_model, kfold)\n",
    "svc_param_selection(X_HemoPI1_model, y_HemoPI1_model, kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_models = []\n",
    "opt_models.append(('logreg', LogisticRegression(C=1000, penalty='l2', solver='newton-cg', tol=0.1, random_state=seed, fit_intercept=True)))\n",
    "opt_models.append(('rfc', RandomForestClassifier(n_estimators=208, max_depth=14, min_samples_leaf=2, max_features='log2', random_state=seed, n_jobs=-1)))\n",
    "opt_models.append(('gbc', GradientBoostingClassifier(n_estimators=240, max_depth=4, min_samples_leaf=10, max_features='sqrt', random_state=seed)))\n",
    "opt_models.append(('lda', LinearDiscriminantAnalysis(solver='svd', tol=0.0001)))\n",
    "opt_models.append(('svc_rbf', SVC(gamma=1, C=1, probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg: Accuracy Score 94.57% (3.07%)\n",
      "\n",
      "logreg: Precision-Recall 92.06%\n",
      "logreg: Matthews Coefficient 89.14%\n",
      "logreg: Cohen Kappa Score 89.14%\n",
      "logreg: ROC AUC Score 94.57%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.95      0.94      0.95       442\n",
      "     high 1       0.94      0.95      0.95       442\n",
      "\n",
      "avg / total       0.95      0.95      0.95       884\n",
      "\n",
      "logreg: Accuracy 85.91%\n",
      "logreg: Precision-Recall 80.73%\n",
      "logreg: Matthews Coefficient 71.82%\n",
      "logreg: Cohen Kappa Score 71.82%\n",
      "logreg: ROC AUC Score 85.91%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.86      0.85      0.86       110\n",
      "     high 1       0.86      0.86      0.86       110\n",
      "\n",
      "avg / total       0.86      0.86      0.86       220\n",
      "\n",
      "rfc: Accuracy Score 94.91% (2.94%)\n",
      "\n",
      "rfc: Precision-Recall 92.76%\n",
      "rfc: Matthews Coefficient 89.82%\n",
      "rfc: Cohen Kappa Score 89.82%\n",
      "rfc: ROC AUC Score 94.91%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.95      0.95      0.95       442\n",
      "     high 1       0.95      0.95      0.95       442\n",
      "\n",
      "avg / total       0.95      0.95      0.95       884\n",
      "\n",
      "rfc: Accuracy 90.00%\n",
      "rfc: Precision-Recall 86.00%\n",
      "rfc: Matthews Coefficient 80.00%\n",
      "rfc: Cohen Kappa Score 80.00%\n",
      "rfc: ROC AUC Score 90.00%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.90      0.90      0.90       110\n",
      "     high 1       0.90      0.90      0.90       110\n",
      "\n",
      "avg / total       0.90      0.90      0.90       220\n",
      "\n",
      "gbc: Accuracy Score 95.93% (2.37%)\n",
      "\n",
      "gbc: Precision-Recall 94.35%\n",
      "gbc: Matthews Coefficient 91.86%\n",
      "gbc: Cohen Kappa Score 91.86%\n",
      "gbc: ROC AUC Score 95.93%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.95      0.97      0.96       442\n",
      "     high 1       0.97      0.95      0.96       442\n",
      "\n",
      "avg / total       0.96      0.96      0.96       884\n",
      "\n",
      "gbc: Accuracy 92.27%\n",
      "gbc: Precision-Recall 89.17%\n",
      "gbc: Matthews Coefficient 84.55%\n",
      "gbc: Cohen Kappa Score 84.55%\n",
      "gbc: ROC AUC Score 92.27%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.92      0.93      0.92       110\n",
      "     high 1       0.93      0.92      0.92       110\n",
      "\n",
      "avg / total       0.92      0.92      0.92       220\n",
      "\n",
      "lda: Accuracy Score 94.23% (2.74%)\n",
      "\n",
      "lda: Precision-Recall 91.12%\n",
      "lda: Matthews Coefficient 88.50%\n",
      "lda: Cohen Kappa Score 88.46%\n",
      "lda: ROC AUC Score 94.23%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.96      0.93      0.94       442\n",
      "     high 1       0.93      0.96      0.94       442\n",
      "\n",
      "avg / total       0.94      0.94      0.94       884\n",
      "\n",
      "lda: Accuracy 90.45%\n",
      "lda: Precision-Recall 87.05%\n",
      "lda: Matthews Coefficient 80.94%\n",
      "lda: Cohen Kappa Score 80.91%\n",
      "lda: ROC AUC Score 90.45%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.89      0.92      0.91       110\n",
      "     high 1       0.92      0.89      0.90       110\n",
      "\n",
      "avg / total       0.90      0.90      0.90       220\n",
      "\n",
      "svc_rbf: Accuracy Score 95.14% (1.76%)\n",
      "\n",
      "svc_rbf: Precision-Recall 92.99%\n",
      "svc_rbf: Matthews Coefficient 90.27%\n",
      "svc_rbf: Cohen Kappa Score 90.27%\n",
      "svc_rbf: ROC AUC Score 95.14%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.95      0.95      0.95       442\n",
      "     high 1       0.95      0.95      0.95       442\n",
      "\n",
      "avg / total       0.95      0.95      0.95       884\n",
      "\n",
      "svc_rbf: Accuracy 90.00%\n",
      "svc_rbf: Precision-Recall 85.44%\n",
      "svc_rbf: Matthews Coefficient 80.05%\n",
      "svc_rbf: Cohen Kappa Score 80.00%\n",
      "svc_rbf: ROC AUC Score 90.00%\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.92      0.88      0.90       110\n",
      "     high 1       0.89      0.92      0.90       110\n",
      "\n",
      "avg / total       0.90      0.90      0.90       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in opt_models:\n",
    "    \n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI1_model, y_HemoPI1_model, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    #print(\"Optimal number of features : %d\" % (len(selected_features_BE)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI1_model, y_HemoPI1_model, cv=kfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI1_validation, y_HemoPI1_validation, cv=kfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Multicollinearity (threshold - 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((884, 26), (220, 26))\n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = norm_HemoPI1_model.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.75\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "to_drop\n",
    "\n",
    "# Drop features \n",
    "trim_HemoPI1_model = norm_HemoPI1_model.drop(norm_HemoPI1_model[to_drop], axis=1)\n",
    "trim_HemoPI1_val = norm_HemoPI1_validation.drop(norm_HemoPI1_validation[to_drop], axis=1)\n",
    "print(trim_HemoPI1_model.shape, trim_HemoPI1_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Before and after optimising hyperparameters\n",
    "#top_models = []\n",
    "#top_models.append(('logreg', LogisticRegression(fit_intercept=True)))\n",
    "#top_models.append(('rfc', RandomForestClassifier(random_state=seed)))\n",
    "#top_models.append(('gbc', GradientBoostingClassifier(random_state=seed)))\n",
    "#top_models.append(('lda', LinearDiscriminantAnalysis()))\n",
    "#top_models.append(('svc_rbf', SVC(probability=True)))\n",
    "\n",
    "\n",
    "opt_models = []\n",
    "opt_models.append(('logreg', LogisticRegression(C=1000, penalty='l2', solver='newton-cg', tol=0.1, random_state=seed, fit_intercept=True)))\n",
    "opt_models.append(('rfc', RandomForestClassifier(n_estimators=208, max_depth=14, min_samples_leaf=2, max_features='log2', random_state=seed, n_jobs=-1)))\n",
    "opt_models.append(('gbc', GradientBoostingClassifier(n_estimators=240, max_depth=4, min_samples_leaf=10, max_features='sqrt', random_state=seed)))\n",
    "opt_models.append(('lda', LinearDiscriminantAnalysis(solver='svd', tol=0.0001)))\n",
    "opt_models.append(('svc_rbf', SVC(gamma=1, C=1, probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg: Accuracy Score 94.01% (3.14%)\n",
      "\n",
      "logreg: Precision-Recall 91.24%\n",
      "logreg: Matthews Coefficient 88.01%\n",
      "logreg: Cohen Kappa Score 88.01%\n",
      "logreg: ROC AUC Score 94.00%\n",
      "\n",
      "logreg: Accuracy 89.55%\n",
      "logreg: Precision-Recall 85.85%\n",
      "logreg: Matthews Coefficient 79.12%\n",
      "logreg: Cohen Kappa Score 79.09%\n",
      "logreg: ROC AUC Score 89.55%\n",
      "\n",
      "rfc: Accuracy Score 94.80% (2.58%)\n",
      "\n",
      "rfc: Precision-Recall 92.56%\n",
      "rfc: Matthews Coefficient 89.59%\n",
      "rfc: Cohen Kappa Score 89.59%\n",
      "rfc: ROC AUC Score 94.80%\n",
      "\n",
      "rfc: Accuracy 89.09%\n",
      "rfc: Precision-Recall 85.11%\n",
      "rfc: Matthews Coefficient 78.19%\n",
      "rfc: Cohen Kappa Score 78.18%\n",
      "rfc: ROC AUC Score 89.09%\n",
      "\n",
      "gbc: Accuracy Score 96.50% (2.53%)\n",
      "\n",
      "gbc: Precision-Recall 95.01%\n",
      "gbc: Matthews Coefficient 92.99%\n",
      "gbc: Cohen Kappa Score 92.99%\n",
      "gbc: ROC AUC Score 96.49%\n",
      "\n",
      "gbc: Accuracy 92.73%\n",
      "gbc: Precision-Recall 89.62%\n",
      "gbc: Matthews Coefficient 85.45%\n",
      "gbc: Cohen Kappa Score 85.45%\n",
      "gbc: ROC AUC Score 92.73%\n",
      "\n",
      "lda: Accuracy Score 93.44% (2.76%)\n",
      "\n",
      "lda: Precision-Recall 90.17%\n",
      "lda: Matthews Coefficient 86.90%\n",
      "lda: Cohen Kappa Score 86.88%\n",
      "lda: ROC AUC Score 93.44%\n",
      "\n",
      "lda: Accuracy 90.00%\n",
      "lda: Precision-Recall 85.71%\n",
      "lda: Matthews Coefficient 80.01%\n",
      "lda: Cohen Kappa Score 80.00%\n",
      "lda: ROC AUC Score 90.00%\n",
      "\n",
      "svc_rbf: Accuracy Score 95.14% (1.43%)\n",
      "\n",
      "svc_rbf: Precision-Recall 93.46%\n",
      "svc_rbf: Matthews Coefficient 90.30%\n",
      "svc_rbf: Cohen Kappa Score 90.27%\n",
      "svc_rbf: ROC AUC Score 95.14%\n",
      "\n",
      "svc_rbf: Accuracy 87.27%\n",
      "svc_rbf: Precision-Recall 82.04%\n",
      "svc_rbf: Matthews Coefficient 74.59%\n",
      "svc_rbf: Cohen Kappa Score 74.55%\n",
      "svc_rbf: ROC AUC Score 87.27%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in opt_models:\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, trim_HemoPI1_model, y_HemoPI1_model, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, trim_HemoPI1_model, y_HemoPI1_model, cv=kfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, trim_HemoPI1_val, y_HemoPI1_validation, cv=kfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With RFE-selected descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_models = []\n",
    "#opt_models.append(('logreg', LogisticRegression(C=1000, penalty='l2', solver='lbfgs', tol=0.1, random_state=seed, fit_intercept=True)))\n",
    "opt_models.append(('rfc', RandomForestClassifier(n_estimators=48, max_depth=6, min_samples_leaf=4, max_features='log2', random_state=seed, n_jobs=-1)))\n",
    "opt_models.append(('gbc', GradientBoostingClassifier(n_estimators=32, max_depth=16, min_samples_leaf=10, max_features='sqrt', random_state=seed)))\n",
    "opt_models.append(('lda', LinearDiscriminantAnalysis(solver='svd', tol=0.0001)))\n",
    "#opt_models.append(('svc_rbf', SVC(gamma=0.1, C=10, probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc: Accuracy Score 95.25% (2.30%)\n",
      "Optimal number of features : 51\n",
      "\n",
      "rfc: Precision-Recall 93.01%\n",
      "rfc: Matthews Coefficient 90.50%\n",
      "rfc: Cohen Kappa Score 90.50%\n",
      "rfc: ROC AUC Score 95.25%\n",
      "\n",
      "rfc: Accuracy 90.91%\n",
      "rfc: Precision-Recall 87.19%\n",
      "rfc: Matthews Coefficient 81.82%\n",
      "rfc: Cohen Kappa Score 81.82%\n",
      "rfc: ROC AUC Score 90.91%\n",
      "\n",
      "gbc: Accuracy Score 95.14% (3.42%)\n",
      "Optimal number of features : 25\n",
      "\n",
      "gbc: Precision-Recall 92.99%\n",
      "gbc: Matthews Coefficient 90.27%\n",
      "gbc: Cohen Kappa Score 90.27%\n",
      "gbc: ROC AUC Score 95.14%\n",
      "\n",
      "gbc: Accuracy 90.00%\n",
      "gbc: Precision-Recall 86.30%\n",
      "gbc: Matthews Coefficient 80.01%\n",
      "gbc: Cohen Kappa Score 80.00%\n",
      "gbc: ROC AUC Score 90.00%\n",
      "\n",
      "lda: Accuracy Score 95.14% (2.77%)\n",
      "Optimal number of features : 18\n",
      "\n",
      "lda: Precision-Recall 92.62%\n",
      "lda: Matthews Coefficient 90.28%\n",
      "lda: Cohen Kappa Score 90.27%\n",
      "lda: ROC AUC Score 95.14%\n",
      "\n",
      "lda: Accuracy 94.55%\n",
      "lda: Precision-Recall 92.48%\n",
      "lda: Matthews Coefficient 89.11%\n",
      "lda: Cohen Kappa Score 89.09%\n",
      "lda: ROC AUC Score 94.55%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in opt_models:\n",
    "    \n",
    "    rfecv_model = RFECV(model, step=1, cv=kfold)\n",
    "    rfecv = rfecv_model.fit(X_HemoPI1_model, y_HemoPI1_model)\n",
    "    X_HemoPI1_model_RFE = rfecv.transform(X_HemoPI1_model)\n",
    "    X_HemoPI1_val_RFE = rfecv.transform(X_HemoPI1_validation)\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI1_model_RFE, y_HemoPI1_model, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % ((rfecv.n_features_)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI1_model_RFE, y_HemoPI1_model, cv=kfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI1_val_RFE, y_HemoPI1_validation, cv=kfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With BE-selected descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc: Accuracy Score 95.48% (2.62%)\n",
      "Optimal number of features : 18\n",
      "\n",
      "gbc: Precision-Recall 93.51%\n",
      "gbc: Matthews Coefficient 90.95%\n",
      "gbc: Cohen Kappa Score 90.95%\n",
      "gbc: ROC AUC Score 95.48%\n",
      "\n",
      "gbc: Accuracy 91.82%\n",
      "gbc: Precision-Recall 89.06%\n",
      "gbc: Matthews Coefficient 83.69%\n",
      "gbc: Cohen Kappa Score 83.64%\n",
      "gbc: ROC AUC Score 91.82%\n",
      "\n",
      "adc: Accuracy Score 92.65% (3.28%)\n",
      "Optimal number of features : 18\n",
      "\n",
      "adc: Precision-Recall 89.55%\n",
      "adc: Matthews Coefficient 85.29%\n",
      "adc: Cohen Kappa Score 85.29%\n",
      "adc: ROC AUC Score 92.65%\n",
      "\n",
      "adc: Accuracy 90.91%\n",
      "adc: Precision-Recall 86.89%\n",
      "adc: Matthews Coefficient 81.83%\n",
      "adc: Cohen Kappa Score 81.82%\n",
      "adc: ROC AUC Score 90.91%\n",
      "\n",
      "lda: Accuracy Score 94.57% (2.52%)\n",
      "Optimal number of features : 18\n",
      "\n",
      "lda: Precision-Recall 91.54%\n",
      "lda: Matthews Coefficient 89.19%\n",
      "lda: Cohen Kappa Score 89.14%\n",
      "lda: ROC AUC Score 94.57%\n",
      "\n",
      "lda: Accuracy 92.27%\n",
      "lda: Precision-Recall 88.85%\n",
      "lda: Matthews Coefficient 84.55%\n",
      "lda: Cohen Kappa Score 84.55%\n",
      "lda: ROC AUC Score 92.27%\n",
      "\n",
      "svc_rbf: Accuracy Score 94.24% (2.49%)\n",
      "Optimal number of features : 18\n",
      "\n",
      "svc_rbf: Precision-Recall 91.46%\n",
      "svc_rbf: Matthews Coefficient 88.47%\n",
      "svc_rbf: Cohen Kappa Score 88.46%\n",
      "svc_rbf: ROC AUC Score 94.23%\n",
      "\n",
      "svc_rbf: Accuracy 90.00%\n",
      "svc_rbf: Precision-Recall 84.67%\n",
      "svc_rbf: Matthews Coefficient 80.33%\n",
      "svc_rbf: Cohen Kappa Score 80.00%\n",
      "svc_rbf: ROC AUC Score 90.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in opt_models:\n",
    "    \n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI1_model_BE, y_HemoPI1_model, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (len(selected_features_BE)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI1_model_BE, y_HemoPI1_model, cv=kfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI1_val_BE, y_HemoPI1_validation, cv=kfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning hyperparameters of binary classifiers for HemoPI-2 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all modlamp descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters were searched on institutional server Mazorka\n",
    "logreg_param_selection(X_HemoPI2_model, y_HemoPI2_model, skfold)\n",
    "rfc_param_selection(X_HemoPI2_model, y_HemoPI2_model, skfold)\n",
    "gbc_param_selection(X_HemoPI2_model, y_HemoPI2_model, skfold)\n",
    "lda_param_selection(X_HemoPI2_model, y_HemoPI2_model, skfold)\n",
    "svc_param_selection(X_HemoPI2_model, y_HemoPI2_model, skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_models = []\n",
    "opt_models.append(('gbc', GradientBoostingClassifier(random_state=seed)))\n",
    "opt_models.append(('logreg', LogisticRegression(C=1000, penalty='l2', solver='lbfgs', tol=0.1, random_state=seed, fit_intercept=True)))\n",
    "opt_models.append(('rfc', RandomForestClassifier(n_estimators=144, max_depth=16, min_samples_leaf=2, max_features='log2', random_state=seed, n_jobs=-1)))\n",
    "opt_models.append(('gbc', GradientBoostingClassifier(n_estimators=112, max_depth=4, min_samples_leaf=2, max_features='sqrt', random_state=seed)))\n",
    "opt_models.append(('lda', LinearDiscriminantAnalysis(solver='svd', tol=0.2)))\n",
    "opt_models.append(('svc_rbf', SVC(gamma=0.1, C=1000, probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg: Accuracy Score 70.71% (6.95%)\n",
      "logreg: Precision-Recall 67.51%\n",
      "logreg: Matthews Coefficient 40.62%\n",
      "logreg: Cohen Kappa Score 40.47%\n",
      "logreg: ROC AUC Score 70.08%\n",
      "\n",
      "logreg: Accuracy 60.89%\n",
      "logreg: Precision-Recall 60.37%\n",
      "logreg: Matthews Coefficient 20.71%\n",
      "logreg: Cohen Kappa Score 20.66%\n",
      "logreg: ROC AUC Score 60.27%\n",
      "\n",
      "rfc: Accuracy Score 76.86% (3.82%)\n",
      "rfc: Precision-Recall 73.20%\n",
      "rfc: Matthews Coefficient 53.20%\n",
      "rfc: Cohen Kappa Score 53.16%\n",
      "rfc: ROC AUC Score 76.49%\n",
      "\n",
      "rfc: Accuracy 69.80%\n",
      "rfc: Precision-Recall 66.11%\n",
      "rfc: Matthews Coefficient 38.86%\n",
      "rfc: Cohen Kappa Score 37.96%\n",
      "rfc: ROC AUC Score 68.63%\n",
      "\n",
      "gbc: Accuracy Score 77.72% (4.13%)\n",
      "gbc: Precision-Recall 74.03%\n",
      "gbc: Matthews Coefficient 54.95%\n",
      "gbc: Cohen Kappa Score 54.92%\n",
      "gbc: ROC AUC Score 77.37%\n",
      "\n",
      "gbc: Accuracy 74.26%\n",
      "gbc: Precision-Recall 70.40%\n",
      "gbc: Matthews Coefficient 47.88%\n",
      "gbc: Cohen Kappa Score 47.64%\n",
      "gbc: ROC AUC Score 73.61%\n",
      "\n",
      "lda: Accuracy Score 68.48% (5.48%)\n",
      "lda: Precision-Recall 65.43%\n",
      "lda: Matthews Coefficient 36.01%\n",
      "lda: Cohen Kappa Score 35.62%\n",
      "lda: ROC AUC Score 67.58%\n",
      "\n",
      "lda: Accuracy 63.37%\n",
      "lda: Precision-Recall 61.93%\n",
      "lda: Matthews Coefficient 25.61%\n",
      "lda: Cohen Kappa Score 25.48%\n",
      "lda: ROC AUC Score 62.63%\n",
      "\n",
      "svc_rbf: Accuracy Score 77.71% (4.31%)\n",
      "svc_rbf: Precision-Recall 74.17%\n",
      "svc_rbf: Matthews Coefficient 54.99%\n",
      "svc_rbf: Cohen Kappa Score 54.98%\n",
      "svc_rbf: ROC AUC Score 77.43%\n",
      "\n",
      "svc_rbf: Accuracy 65.35%\n",
      "svc_rbf: Precision-Recall 63.92%\n",
      "svc_rbf: Matthews Coefficient 30.27%\n",
      "svc_rbf: Cohen Kappa Score 30.26%\n",
      "svc_rbf: ROC AUC Score 65.16%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in opt_models:\n",
    "    \n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI2_model, y_HemoPI2_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI2_model, y_HemoPI2_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI2_validation, y_HemoPI2_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multicollinearity (threshold 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((812, 27), (202, 27))\n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix2 = norm_HemoPI2_model.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix2.where(np.triu(np.ones(corr_matrix2.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.75\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "to_drop\n",
    "\n",
    "# Drop features \n",
    "trim_HemoPI2_model = norm_HemoPI2_model.drop(norm_HemoPI2_model[to_drop], axis=1)\n",
    "trim_HemoPI2_val = norm_HemoPI2_validation.drop(norm_HemoPI2_validation[to_drop], axis=1)\n",
    "print(trim_HemoPI2_model.shape, trim_HemoPI2_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top_models = []\n",
    "#top_models.append(('logreg', LogisticRegression(fit_intercept=True)))\n",
    "#top_models.append(('rfc', RandomForestClassifier(random_state=seed)))\n",
    "#top_models.append(('gbc', GradientBoostingClassifier(random_state=seed)))\n",
    "#top_models.append(('lda', LinearDiscriminantAnalysis()))\n",
    "#top_models.append(('svc_rbf', SVC(probability=True)))\n",
    "\n",
    "opt_models = []\n",
    "opt_models.append(('logreg', LogisticRegression(C=100, penalty='l2', solver='sag', tol=0.1, random_state=seed, fit_intercept=True)))\n",
    "opt_models.append(('rfc', RandomForestClassifier(n_estimators=48, max_depth=18, min_samples_leaf=2, max_features='log2', random_state=seed, n_jobs=-1)))\n",
    "opt_models.append(('gbc', GradientBoostingClassifier(n_estimators=80, max_depth=18, min_samples_leaf=8, max_features=None, random_state=seed)))\n",
    "opt_models.append(('lda', LinearDiscriminantAnalysis(solver='svd', tol=0.0001)))\n",
    "opt_models.append(('svc_rbf', SVC(gamma=1, C=1000, probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg: Accuracy Score 67.25% (4.78%)\n",
      "\n",
      "logreg: Precision-Recall 64.60%\n",
      "logreg: Matthews Coefficient 33.49%\n",
      "logreg: Cohen Kappa Score 33.23%\n",
      "logreg: ROC AUC Score 66.43%\n",
      "\n",
      "logreg: Accuracy 61.88%\n",
      "logreg: Precision-Recall 60.96%\n",
      "logreg: Matthews Coefficient 22.63%\n",
      "logreg: Cohen Kappa Score 22.53%\n",
      "logreg: ROC AUC Score 61.18%\n",
      "\n",
      "rfc: Accuracy Score 76.73% (3.52%)\n",
      "\n",
      "rfc: Precision-Recall 73.10%\n",
      "rfc: Matthews Coefficient 52.96%\n",
      "rfc: Cohen Kappa Score 52.92%\n",
      "rfc: ROC AUC Score 76.37%\n",
      "\n",
      "rfc: Accuracy 71.29%\n",
      "rfc: Precision-Recall 67.91%\n",
      "rfc: Matthews Coefficient 41.81%\n",
      "rfc: Cohen Kappa Score 41.60%\n",
      "rfc: ROC AUC Score 70.61%\n",
      "\n",
      "gbc: Accuracy Score 78.58% (4.73%)\n",
      "\n",
      "gbc: Precision-Recall 74.87%\n",
      "gbc: Matthews Coefficient 56.70%\n",
      "gbc: Cohen Kappa Score 56.67%\n",
      "gbc: ROC AUC Score 78.25%\n",
      "\n",
      "gbc: Accuracy 71.29%\n",
      "gbc: Precision-Recall 67.67%\n",
      "gbc: Matthews Coefficient 41.81%\n",
      "gbc: Cohen Kappa Score 41.38%\n",
      "gbc: ROC AUC Score 70.43%\n",
      "\n",
      "lda: Accuracy Score 68.36% (5.56%)\n",
      "\n",
      "lda: Precision-Recall 65.32%\n",
      "lda: Matthews Coefficient 35.75%\n",
      "lda: Cohen Kappa Score 35.36%\n",
      "lda: ROC AUC Score 67.45%\n",
      "\n",
      "lda: Accuracy 63.37%\n",
      "lda: Precision-Recall 62.01%\n",
      "lda: Matthews Coefficient 25.70%\n",
      "lda: Cohen Kappa Score 25.62%\n",
      "lda: ROC AUC Score 62.72%\n",
      "\n",
      "svc_rbf: Accuracy Score 72.05% (4.57%)\n",
      "\n",
      "svc_rbf: Precision-Recall 69.27%\n",
      "svc_rbf: Matthews Coefficient 43.68%\n",
      "svc_rbf: Cohen Kappa Score 43.68%\n",
      "svc_rbf: ROC AUC Score 71.86%\n",
      "\n",
      "svc_rbf: Accuracy 69.80%\n",
      "svc_rbf: Precision-Recall 67.27%\n",
      "svc_rbf: Matthews Coefficient 39.07%\n",
      "svc_rbf: Cohen Kappa Score 39.07%\n",
      "svc_rbf: ROC AUC Score 69.52%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in opt_models: #top_models:\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, trim_HemoPI2_model, y_HemoPI2_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, trim_HemoPI2_model, y_HemoPI2_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, trim_HemoPI2_val, y_HemoPI2_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With RFE-selected descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_models = []\n",
    "#top_models.append(('logreg', LogisticRegression(fit_intercept=True)))\n",
    "#top_models.append(('rfc', RandomForestClassifier(random_state=seed)))\n",
    "#top_models.append(('gbc', GradientBoostingClassifier(random_state=seed)))\n",
    "#top_models.append(('lda', LinearDiscriminantAnalysis()))\n",
    "#top_models.append(('svc_rbf', SVC(probability=True)))\n",
    "\n",
    "\n",
    "opt_models = []\n",
    "opt_models.append(('logreg', LogisticRegression(C=1000, penalty='l2', solver='lbfgs', tol=0.1, random_state=seed, fit_intercept=True)))\n",
    "opt_models.append(('rfc', RandomForestClassifier(n_estimators=128, max_depth=14, min_samples_leaf=2, max_features=None, random_state=seed, n_jobs=-1)))\n",
    "opt_models.append(('gbc', GradientBoostingClassifier(n_estimators=128, max_depth=4, min_samples_leaf=10, max_features=None, random_state=seed)))\n",
    "opt_models.append(('lda', LinearDiscriminantAnalysis(solver='svd', tol=0.1)))\n",
    "opt_models.append(('svc_rbf', SVC(gamma=0.1, C=10, probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc: Accuracy Score 72.79% (4.60%)\n",
      "Optimal number of features : 34\n",
      "\n",
      "rfc: Precision-Recall 70.79%\n",
      "rfc: Matthews Coefficient 45.96%\n",
      "rfc: Cohen Kappa Score 45.67%\n",
      "rfc: ROC AUC Score 73.06%\n",
      "\n",
      "rfc: Accuracy 69.80%\n",
      "rfc: Precision-Recall 68.26%\n",
      "rfc: Matthews Coefficient 40.15%\n",
      "rfc: Cohen Kappa Score 39.82%\n",
      "rfc: ROC AUC Score 70.14%\n",
      "\n",
      "gbc: Accuracy Score 77.84% (2.99%)\n",
      "Optimal number of features : 15\n",
      "\n",
      "gbc: Precision-Recall 74.21%\n",
      "gbc: Matthews Coefficient 55.22%\n",
      "gbc: Cohen Kappa Score 55.20%\n",
      "gbc: ROC AUC Score 77.52%\n",
      "\n",
      "gbc: Accuracy 73.27%\n",
      "gbc: Precision-Recall 69.84%\n",
      "gbc: Matthews Coefficient 45.90%\n",
      "gbc: Cohen Kappa Score 45.82%\n",
      "gbc: ROC AUC Score 72.79%\n",
      "\n",
      "lda: Accuracy Score 69.96% (5.21%)\n",
      "Optimal number of features : 49\n",
      "\n",
      "lda: Precision-Recall 66.54%\n",
      "lda: Matthews Coefficient 39.06%\n",
      "lda: Cohen Kappa Score 38.61%\n",
      "lda: ROC AUC Score 69.05%\n",
      "\n",
      "lda: Accuracy 61.39%\n",
      "lda: Precision-Recall 60.59%\n",
      "lda: Matthews Coefficient 21.57%\n",
      "lda: Cohen Kappa Score 21.46%\n",
      "lda: ROC AUC Score 60.63%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in top_models: #opt_models:\n",
    "    \n",
    "    rfecv_model = RFECV(model, step=1, cv=skfold)\n",
    "    rfecv = rfecv_model.fit(X_HemoPI2_model, y_HemoPI2_model)\n",
    "    X_HemoPI2_model_RFE = rfecv.transform(X_HemoPI2_model)\n",
    "    X_HemoPI2_val_RFE = rfecv.transform(X_HemoPI2_validation)\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI2_model_RFE, y_HemoPI2_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (rfecv.n_features_))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI2_model_RFE, y_HemoPI2_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI2_val_RFE, y_HemoPI2_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With BE-selected descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda: Accuracy Score 70.09% (5.35%)\n",
      "Optimal number of features : 18\n",
      "\n",
      "lda: Precision-Recall 66.54%\n",
      "lda: Matthews Coefficient 39.34%\n",
      "lda: Cohen Kappa Score 38.77%\n",
      "lda: ROC AUC Score 69.10%\n",
      "\n",
      "lda: Accuracy 65.35%\n",
      "lda: Precision-Recall 62.82%\n",
      "lda: Matthews Coefficient 29.49%\n",
      "lda: Cohen Kappa Score 28.74%\n",
      "lda: ROC AUC Score 64.09%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in top_models: #opt_models:\n",
    "    \n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI2_model_BE, y_HemoPI2_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (len(selected_features_BE)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI2_model_BE, y_HemoPI2_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI2_val_BE, y_HemoPI2_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tuning hyperparameters of binary classifiers for HemoPI-3 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all 56 modlamp descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_param_selection(X_HemoPI3_model, y_HemoPI3_model, skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbc_param_selection(X_HemoPI3_model, y_HemoPI3_model, skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_param_selection(X_HemoPI3_model, y_HemoPI3_model, skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_param_selection(X_HemoPI3_model, y_HemoPI3_model, skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_models = []\n",
    "opt_models.append(('logreg', LogisticRegression(C=1000, penalty='l2', solver='newton-cg', tol=0.1, random_state=seed, fit_intercept=True)))\n",
    "opt_models.append(('rfc', RandomForestClassifier(n_estimators=176, max_depth=20, min_samples_leaf=2, max_features='log2', random_state=seed, n_jobs=-1)))\n",
    "opt_models.append(('gbc', GradientBoostingClassifier(n_estimators=192, max_depth=18, min_samples_leaf=10, max_features='log2', random_state=seed)))\n",
    "opt_models.append(('lda', LinearDiscriminantAnalysis(solver='svd', tol=0.0001)))\n",
    "opt_models.append(('svc_rbf', SVC(gamma=0.1, C=10, probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg: Accuracy Score 70.88% (2.12%)\n",
      "\n",
      "logreg: Precision-Recall 67.16%\n",
      "logreg: Matthews Coefficient 40.99%\n",
      "logreg: Cohen Kappa Score 40.29%\n",
      "logreg: ROC AUC Score 69.82%\n",
      "\n",
      "logreg: Accuracy 70.77%\n",
      "logreg: Precision-Recall 67.54%\n",
      "logreg: Matthews Coefficient 40.76%\n",
      "logreg: Cohen Kappa Score 40.58%\n",
      "logreg: ROC AUC Score 70.12%\n",
      "\n",
      "rfc: Accuracy Score 77.96% (3.24%)\n",
      "\n",
      "rfc: Precision-Recall 74.04%\n",
      "rfc: Matthews Coefficient 55.42%\n",
      "rfc: Cohen Kappa Score 55.29%\n",
      "rfc: ROC AUC Score 77.47%\n",
      "\n",
      "rfc: Accuracy 70.15%\n",
      "rfc: Precision-Recall 66.75%\n",
      "rfc: Matthews Coefficient 39.47%\n",
      "rfc: Cohen Kappa Score 39.05%\n",
      "rfc: ROC AUC Score 69.28%\n",
      "\n",
      "gbc: Accuracy Score 80.04% (2.52%)\n",
      "\n",
      "gbc: Precision-Recall 76.42%\n",
      "gbc: Matthews Coefficient 59.68%\n",
      "gbc: Cohen Kappa Score 59.65%\n",
      "gbc: ROC AUC Score 79.75%\n",
      "\n",
      "gbc: Accuracy 71.69%\n",
      "gbc: Precision-Recall 68.33%\n",
      "gbc: Matthews Coefficient 42.65%\n",
      "gbc: Cohen Kappa Score 42.48%\n",
      "gbc: ROC AUC Score 71.08%\n",
      "\n",
      "lda: Accuracy Score 70.80% (2.16%)\n",
      "\n",
      "lda: Precision-Recall 66.88%\n",
      "lda: Matthews Coefficient 40.96%\n",
      "lda: Cohen Kappa Score 39.92%\n",
      "lda: ROC AUC Score 69.56%\n",
      "\n",
      "lda: Accuracy 70.77%\n",
      "lda: Precision-Recall 67.24%\n",
      "lda: Matthews Coefficient 40.74%\n",
      "lda: Cohen Kappa Score 40.31%\n",
      "lda: ROC AUC Score 69.90%\n",
      "\n",
      "svc_rbf: Accuracy Score 72.96% (2.45%)\n",
      "\n",
      "svc_rbf: Precision-Recall 68.36%\n",
      "svc_rbf: Matthews Coefficient 45.77%\n",
      "svc_rbf: Cohen Kappa Score 44.16%\n",
      "svc_rbf: ROC AUC Score 71.57%\n",
      "\n",
      "svc_rbf: Accuracy 72.00%\n",
      "svc_rbf: Precision-Recall 68.00%\n",
      "svc_rbf: Matthews Coefficient 43.36%\n",
      "svc_rbf: Cohen Kappa Score 42.63%\n",
      "svc_rbf: ROC AUC Score 70.97%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in opt_models:\n",
    "    \n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI3_model, y_HemoPI3_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI3_model, y_HemoPI3_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI3_validation, y_HemoPI3_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multicollinearity (threshold 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1298, 28), (325, 28))\n"
     ]
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix3 = norm_HemoPI3_model.corr()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix3.where(np.triu(np.ones(corr_matrix3.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.75\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "to_drop\n",
    "\n",
    "# Drop features \n",
    "trim_HemoPI3_model = norm_HemoPI3_model.drop(norm_HemoPI3_model[to_drop], axis=1)\n",
    "trim_HemoPI3_val = norm_HemoPI3_validation.drop(norm_HemoPI3_validation[to_drop], axis=1)\n",
    "print(trim_HemoPI3_model.shape, trim_HemoPI3_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top_models = []\n",
    "#top_models.append(('logreg', LogisticRegression(fit_intercept=True)))\n",
    "#top_models.append(('rfc', RandomForestClassifier(random_state=seed)))\n",
    "#top_models.append(('gbc', GradientBoostingClassifier(random_state=seed)))\n",
    "#top_models.append(('lda', LinearDiscriminantAnalysis()))\n",
    "#top_models.append(('svc_rbf', SVC(probability=True)))\n",
    "\n",
    "\n",
    "opt_models = []\n",
    "opt_models.append(('logreg', LogisticRegression(C=1, penalty='l2', solver='newton-cg', tol=0.1, random_state=seed, fit_intercept=True)))\n",
    "opt_models.append(('rfc', RandomForestClassifier(n_estimators=96, max_depth=12, min_samples_leaf=2, max_features='sqrt', random_state=seed, n_jobs=-1)))\n",
    "opt_models.append(('gbc', GradientBoostingClassifier(n_estimators=96, max_depth=20, min_samples_leaf=8, max_features='log2', random_state=seed)))\n",
    "opt_models.append(('lda', LinearDiscriminantAnalysis(solver='svd', tol=0.2)))\n",
    "opt_models.append(('svc_rbf', SVC(gamma=0.1, C=10, probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg: Accuracy Score 69.57% (2.65%)\n",
      "\n",
      "logreg: Precision-Recall 65.99%\n",
      "logreg: Matthews Coefficient 38.32%\n",
      "logreg: Cohen Kappa Score 37.44%\n",
      "logreg: ROC AUC Score 68.36%\n",
      "\n",
      "logreg: Accuracy 70.46%\n",
      "logreg: Precision-Recall 66.89%\n",
      "logreg: Matthews Coefficient 40.12%\n",
      "logreg: Cohen Kappa Score 39.58%\n",
      "logreg: ROC AUC Score 69.50%\n",
      "\n",
      "rfc: Accuracy Score 73.19% (2.48%)\n",
      "\n",
      "rfc: Precision-Recall 70.67%\n",
      "rfc: Matthews Coefficient 46.21%\n",
      "rfc: Cohen Kappa Score 46.16%\n",
      "rfc: ROC AUC Score 73.18%\n",
      "\n",
      "rfc: Accuracy 66.46%\n",
      "rfc: Precision-Recall 65.05%\n",
      "rfc: Matthews Coefficient 32.87%\n",
      "rfc: Cohen Kappa Score 32.79%\n",
      "rfc: ROC AUC Score 66.50%\n",
      "\n",
      "gbc: Accuracy Score 76.20% (2.20%)\n",
      "\n",
      "gbc: Precision-Recall 72.43%\n",
      "gbc: Matthews Coefficient 51.82%\n",
      "gbc: Cohen Kappa Score 51.70%\n",
      "gbc: ROC AUC Score 75.69%\n",
      "\n",
      "gbc: Accuracy 72.00%\n",
      "gbc: Precision-Recall 68.97%\n",
      "gbc: Matthews Coefficient 43.41%\n",
      "gbc: Cohen Kappa Score 43.39%\n",
      "gbc: ROC AUC Score 71.64%\n",
      "\n",
      "lda: Accuracy Score 70.34% (2.65%)\n",
      "\n",
      "lda: Precision-Recall 66.48%\n",
      "lda: Matthews Coefficient 40.02%\n",
      "lda: Cohen Kappa Score 38.92%\n",
      "lda: ROC AUC Score 69.05%\n",
      "\n",
      "lda: Accuracy 73.85%\n",
      "lda: Precision-Recall 69.67%\n",
      "lda: Matthews Coefficient 47.12%\n",
      "lda: Cohen Kappa Score 46.53%\n",
      "lda: ROC AUC Score 72.94%\n",
      "\n",
      "svc_rbf: Accuracy Score 65.26% (3.21%)\n",
      "\n",
      "svc_rbf: Precision-Recall 62.34%\n",
      "svc_rbf: Matthews Coefficient 29.58%\n",
      "svc_rbf: Cohen Kappa Score 27.69%\n",
      "svc_rbf: ROC AUC Score 63.42%\n",
      "\n",
      "svc_rbf: Accuracy 66.46%\n",
      "svc_rbf: Precision-Recall 63.10%\n",
      "svc_rbf: Matthews Coefficient 32.33%\n",
      "svc_rbf: Cohen Kappa Score 30.26%\n",
      "svc_rbf: ROC AUC Score 64.67%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in top_models: #opt_models:\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, trim_HemoPI3_model, y_HemoPI3_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, trim_HemoPI3_model, y_HemoPI3_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, trim_HemoPI3_val, y_HemoPI3_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"\")\n",
    "    #target_names = ['low 0', 'high 1']\n",
    "    #print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With RFE-selected descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_models = []\n",
    "#opt_models.append(('logreg', LogisticRegression(C=1000, penalty='l2', solver='lbfgs', tol=0.1, random_state=seed, fit_intercept=True)))\n",
    "opt_models.append(('rfc', RandomForestClassifier(n_estimators=160, max_depth=18, min_samples_leaf=2, max_features='sqrt', random_state=seed, n_jobs=-1)))\n",
    "#opt_models.append(('gbc', GradientBoostingClassifier(n_estimators=160, max_depth=12, min_samples_leaf=8, max_features='sqrt', random_state=seed)))\n",
    "#opt_models.append(('lda', LinearDiscriminantAnalysis(solver='svd', tol=0.0001)))\n",
    "#opt_models.append(('svc_rbf', SVC(gamma=0.1, C=10, probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc: Accuracy Score 77.58% (2.65%)\n",
      "Optimal number of features : 32\n",
      "\n",
      "rfc: Precision-Recall 73.47%\n",
      "rfc: Matthews Coefficient 54.64%\n",
      "rfc: Cohen Kappa Score 54.41%\n",
      "rfc: ROC AUC Score 76.98%\n",
      "\n",
      "rfc: Accuracy 72.00%\n",
      "rfc: Precision-Recall 68.31%\n",
      "rfc: Matthews Coefficient 43.26%\n",
      "rfc: Cohen Kappa Score 42.89%\n",
      "rfc: ROC AUC Score 71.19%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in opt_models: #top_models: \n",
    "    \n",
    "    rfecv_model = RFECV(model, step=1, cv=skfold)\n",
    "    rfecv = rfecv_model.fit(X_HemoPI3_model, y_HemoPI3_model)\n",
    "    X_HemoPI3_model_RFE = rfecv.transform(X_HemoPI3_model)\n",
    "    X_HemoPI3_val_RFE = rfecv.transform(X_HemoPI3_validation)\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI3_model_RFE, y_HemoPI3_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (rfecv.n_features_))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI3_model_RFE, y_HemoPI3_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI3_val_RFE, y_HemoPI3_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With BE-selected descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_models = []\n",
    "opt_models.append(('gbc', GradientBoostingClassifier(n_estimators=200, max_depth=20, min_samples_leaf=6, max_features='sqrt', random_state=seed)))\n",
    "opt_models.append(('adc', AdaBoostClassifier(n_estimators=400, learning_rate=0.1, random_state=seed)))\n",
    "opt_models.append(('lda', LinearDiscriminantAnalysis(solver='svd', tol=0.0001)))\n",
    "opt_models.append(('svc_rbf', SVC(gamma=5, C=200, probability=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda: Accuracy Score 71.95% (3.15%)\n",
      "Optimal number of features : 18\n",
      "\n",
      "lda: Precision-Recall 67.79%\n",
      "lda: Matthews Coefficient 43.39%\n",
      "lda: Cohen Kappa Score 42.31%\n",
      "lda: ROC AUC Score 70.73%\n",
      "\n",
      "lda: Accuracy 70.15%\n",
      "lda: Precision-Recall 66.68%\n",
      "lda: Matthews Coefficient 39.48%\n",
      "lda: Cohen Kappa Score 38.98%\n",
      "lda: ROC AUC Score 69.22%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in top_models: #opt_models:\n",
    "    \n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI3_model_BE, y_HemoPI3_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (len(selected_features_BE)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI3_model_BE, y_HemoPI3_model, cv=skfold)\n",
    "    #print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI3_val_BE, y_HemoPI3_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion \n",
    "Best optimised models were obtained using either the full extend of descriptors or less descriptors after applying multicollinearity (0,75) or recursive feature elimination.\n",
    "\n",
    "We identified the top3 models for each dataset - overall grandient boosting binary classifiers are the top performers with modlamp descriptors. We re-create, save (pickle) each model as well as save the probabilities for model and validation datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HemoPI-1 dataset\n",
    "\n",
    "model 1: LinearDiscriminantAnalysis(solver='svd', tol=0.0001) with 18 RFECV modlampdescriptors - 95.1/94.6% accuracies\n",
    "\n",
    "model 2: GradientBoostingClassifier(n_estimators=240, max_depth=4, min_samples_leaf=10, max_features='sqrt', random_state=seed) with 26 modlampdescriptors - 96.5/92.7% accuracies\n",
    "\n",
    "model 3: GradientBoostingClassifier(n_estimators=208, max_depth=4, min_samples_leaf=10, max_features='sqrt', random_state=seed) with 56 modlampdescriptors - 96.0/92.3% accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: Model and validation predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001)\n",
      "(884, 18)\n"
     ]
    }
   ],
   "source": [
    "model1_hpi1 = LinearDiscriminantAnalysis(solver='svd', tol=0.0001)\n",
    "\n",
    "rfecv_model = RFECV(model1_hpi1, step=1, cv=kfold)\n",
    "rfecv = rfecv_model.fit(X_HemoPI1_model, y_HemoPI1_model)\n",
    "X_HemoPI1_model_RFE = rfecv.transform(X_HemoPI1_model)\n",
    "X_HemoPI1_val_RFE = rfecv.transform(X_HemoPI1_validation)\n",
    "    \n",
    "print(model1_hpi1.fit(X_HemoPI1_model_RFE, y_HemoPI1_model))\n",
    "print(X_HemoPI1_model_RFE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle and save model\n",
    "import pickle\n",
    "# now you can save it to a file\n",
    "with open('./Models/model1_hpi1.pkl', 'wb') as f:\n",
    "    pickle.dump(model1_hpi1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save model set results into dataframe\n",
    "class_df = pd.DataFrame(model1_hpi1.predict(X_HemoPI1_model_RFE))\n",
    "probs_df = pd.DataFrame(model1_hpi1.predict_proba(X_HemoPI1_model_RFE))\n",
    "\n",
    "model1_hpi1_df = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model1_hpi1_df.index = X_HemoPI1_model.index\n",
    "model1_hpi1_df.columns = ['model1_class_preds', 'model1_probability_0', 'model1_probability_1']\n",
    "\n",
    "#Save validation set results into dataframe\n",
    "class_df2 = pd.DataFrame(model1_hpi1.predict(X_HemoPI1_val_RFE))\n",
    "probs_df2 = pd.DataFrame(model1_hpi1.predict_proba(X_HemoPI1_val_RFE))\n",
    "\n",
    "model1_hpi1_df2 = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model1_hpi1_df2.index = X_HemoPI1_validation.index\n",
    "model1_hpi1_df2.columns = ['model1_class_preds', 'model1_probability_0', 'model1_probability_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2: Model and validation predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "              max_features='sqrt', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=10, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=240,\n",
      "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "((884, 26), (220, 26))\n"
     ]
    }
   ],
   "source": [
    "model2_hpi1 = GradientBoostingClassifier(n_estimators=240, max_depth=4, min_samples_leaf=10, max_features='sqrt', random_state=seed)\n",
    "\n",
    "corr_matrix = norm_HemoPI1_model.corr()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "X_HemoPI1_model_trim = norm_HemoPI1_model.drop(norm_HemoPI1_model[to_drop], axis=1)\n",
    "X_HemoPI1_val_trim = norm_HemoPI1_validation.drop(norm_HemoPI1_validation[to_drop], axis=1)\n",
    "\n",
    "print(model2_hpi1.fit(X_HemoPI1_model_trim, y_HemoPI1_model))\n",
    "print(X_HemoPI1_model_trim.shape, X_HemoPI1_val_trim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Models/model2_hpi1.pkl', 'wb') as f:\n",
    "    pickle.dump(model2_hpi1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save model set results into dataframe\n",
    "class_df = pd.DataFrame(model2_hpi1.predict(X_HemoPI1_model_trim))\n",
    "probs_df = pd.DataFrame(model2_hpi1.predict_proba(X_HemoPI1_model_trim))\n",
    "\n",
    "model2_hpi1_df = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model2_hpi1_df.index = X_HemoPI1_model.index\n",
    "model2_hpi1_df.columns = ['model2_class_preds', 'model2_probability_0', 'model2_probability_1']\n",
    "\n",
    "#Save validation set results into dataframe\n",
    "class_df2 = pd.DataFrame(model2_hpi1.predict(X_HemoPI1_val_trim))\n",
    "probs_df2 = pd.DataFrame(model2_hpi1.predict_proba(X_HemoPI1_val_trim))\n",
    "\n",
    "model2_hpi1_df2 = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model2_hpi1_df2.index = X_HemoPI1_validation.index\n",
    "model2_hpi1_df2.columns = ['model2_class_preds', 'model2_probability_0', 'model2_probability_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3: Model and validation predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "              max_features='sqrt', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=10, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=208,\n",
      "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "((884, 56), (220, 56))\n"
     ]
    }
   ],
   "source": [
    "model3_hpi1 = GradientBoostingClassifier(n_estimators=208, max_depth=4, min_samples_leaf=10, max_features='sqrt', random_state=seed)\n",
    "\n",
    "print(model3_hpi1.fit(X_HemoPI1_model, y_HemoPI1_model))\n",
    "print(X_HemoPI1_model.shape, X_HemoPI1_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Models/model3_hpi1.pkl', 'wb') as f:\n",
    "    pickle.dump(model3_hpi1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save model set results into dataframe\n",
    "class_df = pd.DataFrame(model3_hpi1.predict(X_HemoPI1_model))\n",
    "probs_df = pd.DataFrame(model3_hpi1.predict_proba(X_HemoPI1_model))\n",
    "\n",
    "model3_hpi1_df = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model3_hpi1_df.index = X_HemoPI1_model.index\n",
    "model3_hpi1_df.columns = ['model3_class_preds', 'model3_probability_0', 'model3_probability_1']\n",
    "\n",
    "#Save validation set results into dataframe\n",
    "class_df2 = pd.DataFrame(model3_hpi1.predict(X_HemoPI1_validation))\n",
    "probs_df2 = pd.DataFrame(model3_hpi1.predict_proba(X_HemoPI1_validation))\n",
    "\n",
    "model3_hpi1_df2 = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model3_hpi1_df2.index = X_HemoPI1_validation.index\n",
    "model3_hpi1_df2.columns = ['model3_class_preds', 'model3_probability_0', 'model3_probability_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1_class_preds</th>\n",
       "      <th>model1_probability_0</th>\n",
       "      <th>model1_probability_1</th>\n",
       "      <th>model2_class_preds</th>\n",
       "      <th>model2_probability_0</th>\n",
       "      <th>model2_probability_1</th>\n",
       "      <th>model3_class_preds</th>\n",
       "      <th>model3_probability_0</th>\n",
       "      <th>model3_probability_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>peptide_pv_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.492460</td>\n",
       "      <td>5.075397e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.993218</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.995688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.038235</td>\n",
       "      <td>9.617648e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.999883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>9.999161e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>9.999716e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.999973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>9.999903e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>9.998725e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.038490</td>\n",
       "      <td>9.615098e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.997024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>9.994430e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>9.979673e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.835863</td>\n",
       "      <td>0.164137</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187168</td>\n",
       "      <td>0.812832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>9.998136e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.999873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009280</td>\n",
       "      <td>9.907203e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014572</td>\n",
       "      <td>0.985428</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.998145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>9.946608e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.888333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.998227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033640</td>\n",
       "      <td>9.663601e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.052621</td>\n",
       "      <td>0.947379</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.998919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113787</td>\n",
       "      <td>8.862129e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.999248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.997551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>9.968744e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.998104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.104984</td>\n",
       "      <td>8.950160e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.999780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.219420</td>\n",
       "      <td>7.805796e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.999966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>9.998710e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.999978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>9.789513e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007311</td>\n",
       "      <td>0.992689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>9.999938e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.999987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999935e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.070046</td>\n",
       "      <td>9.299540e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>0.994359</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.996953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_23</th>\n",
       "      <td>1</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>9.808677e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.996204</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.993832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998815</td>\n",
       "      <td>1.184528e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920973</td>\n",
       "      <td>0.079027</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974328</td>\n",
       "      <td>0.025672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>9.510584e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.999941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>9.998907e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>0.965115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>0.985705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>9.962859e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>0.992672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.998778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>5.444606e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.998411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.999747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>9.963823e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.999881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_30</th>\n",
       "      <td>1</td>\n",
       "      <td>0.150784</td>\n",
       "      <td>8.492155e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.298198</td>\n",
       "      <td>0.701802</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261761</td>\n",
       "      <td>0.738239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_81</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.503752e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997595</td>\n",
       "      <td>0.002405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_82</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>5.131583e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997395</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998488</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_83</th>\n",
       "      <td>0</td>\n",
       "      <td>0.981829</td>\n",
       "      <td>1.817129e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969120</td>\n",
       "      <td>0.030880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.812641</td>\n",
       "      <td>0.187359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_84</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999280</td>\n",
       "      <td>7.202273e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_85</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997923</td>\n",
       "      <td>2.076802e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_86</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.701919e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_87</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.176916e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_88</th>\n",
       "      <td>0</td>\n",
       "      <td>0.938168</td>\n",
       "      <td>6.183160e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985386</td>\n",
       "      <td>0.014614</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997330</td>\n",
       "      <td>0.002670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_89</th>\n",
       "      <td>0</td>\n",
       "      <td>0.585989</td>\n",
       "      <td>4.140108e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999322</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997776</td>\n",
       "      <td>0.002224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_90</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990656</td>\n",
       "      <td>9.343637e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_91</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>2.374943e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_92</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999781</td>\n",
       "      <td>2.189267e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_93</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>8.400483e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>0.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_94</th>\n",
       "      <td>0</td>\n",
       "      <td>0.955501</td>\n",
       "      <td>4.449872e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999273</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_95</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999416</td>\n",
       "      <td>5.843992e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_96</th>\n",
       "      <td>0</td>\n",
       "      <td>0.878660</td>\n",
       "      <td>1.213398e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999230</td>\n",
       "      <td>0.000770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_97</th>\n",
       "      <td>0</td>\n",
       "      <td>0.980295</td>\n",
       "      <td>1.970481e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162640</td>\n",
       "      <td>0.837360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.783335</td>\n",
       "      <td>0.216665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_98</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998795</td>\n",
       "      <td>1.204927e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999890</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_99</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991627</td>\n",
       "      <td>8.372955e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219298</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.993463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_100</th>\n",
       "      <td>0</td>\n",
       "      <td>0.980128</td>\n",
       "      <td>1.987153e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_101</th>\n",
       "      <td>0</td>\n",
       "      <td>0.981270</td>\n",
       "      <td>1.873019e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_102</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998636</td>\n",
       "      <td>1.364096e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999664</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999853</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_103</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997317</td>\n",
       "      <td>2.683383e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090032</td>\n",
       "      <td>0.909968</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204020</td>\n",
       "      <td>0.795980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_104</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.829838e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_105</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>1.503353e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_106</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997638</td>\n",
       "      <td>2.361856e-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_107</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999182</td>\n",
       "      <td>8.181820e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996468</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>0.000916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_108</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999935</td>\n",
       "      <td>6.535997e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_109</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999337</td>\n",
       "      <td>6.630091e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999738</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998951</td>\n",
       "      <td>0.001049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_110</th>\n",
       "      <td>0</td>\n",
       "      <td>0.986480</td>\n",
       "      <td>1.351990e-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model1_class_preds  model1_probability_0  \\\n",
       "# ID                                                       \n",
       "peptide_pv_1                     1              0.492460   \n",
       "peptide_pv_2                     1              0.038235   \n",
       "peptide_pv_3                     1              0.000084   \n",
       "peptide_pv_4                     1              0.000028   \n",
       "peptide_pv_5                     1              0.000010   \n",
       "peptide_pv_6                     1              0.000128   \n",
       "peptide_pv_7                     1              0.038490   \n",
       "peptide_pv_8                     1              0.000557   \n",
       "peptide_pv_9                     1              0.002033   \n",
       "peptide_pv_10                    1              0.000186   \n",
       "peptide_pv_11                    1              0.009280   \n",
       "peptide_pv_12                    1              0.005339   \n",
       "peptide_pv_13                    1              0.033640   \n",
       "peptide_pv_14                    1              0.113787   \n",
       "peptide_pv_15                    1              0.003126   \n",
       "peptide_pv_16                    1              0.104984   \n",
       "peptide_pv_17                    1              0.219420   \n",
       "peptide_pv_18                    1              0.000129   \n",
       "peptide_pv_19                    1              0.021049   \n",
       "peptide_pv_20                    1              0.000006   \n",
       "peptide_pv_21                    1              0.000007   \n",
       "peptide_pv_22                    1              0.070046   \n",
       "peptide_pv_23                    1              0.019132   \n",
       "peptide_pv_24                    0              0.998815   \n",
       "peptide_pv_25                    1              0.048942   \n",
       "peptide_pv_26                    1              0.000109   \n",
       "peptide_pv_27                    1              0.003714   \n",
       "peptide_pv_28                    1              0.455539   \n",
       "peptide_pv_29                    1              0.003618   \n",
       "peptide_pv_30                    1              0.150784   \n",
       "...                            ...                   ...   \n",
       "peptide_nv_81                    0              0.999985   \n",
       "peptide_nv_82                    0              0.999487   \n",
       "peptide_nv_83                    0              0.981829   \n",
       "peptide_nv_84                    0              0.999280   \n",
       "peptide_nv_85                    0              0.997923   \n",
       "peptide_nv_86                    0              1.000000   \n",
       "peptide_nv_87                    0              1.000000   \n",
       "peptide_nv_88                    0              0.938168   \n",
       "peptide_nv_89                    0              0.585989   \n",
       "peptide_nv_90                    0              0.990656   \n",
       "peptide_nv_91                    0              0.999763   \n",
       "peptide_nv_92                    0              0.999781   \n",
       "peptide_nv_93                    0              0.999160   \n",
       "peptide_nv_94                    0              0.955501   \n",
       "peptide_nv_95                    0              0.999416   \n",
       "peptide_nv_96                    0              0.878660   \n",
       "peptide_nv_97                    0              0.980295   \n",
       "peptide_nv_98                    0              0.998795   \n",
       "peptide_nv_99                    0              0.991627   \n",
       "peptide_nv_100                   0              0.980128   \n",
       "peptide_nv_101                   0              0.981270   \n",
       "peptide_nv_102                   0              0.998636   \n",
       "peptide_nv_103                   0              0.997317   \n",
       "peptide_nv_104                   0              1.000000   \n",
       "peptide_nv_105                   0              0.999850   \n",
       "peptide_nv_106                   0              0.997638   \n",
       "peptide_nv_107                   0              0.999182   \n",
       "peptide_nv_108                   0              0.999935   \n",
       "peptide_nv_109                   0              0.999337   \n",
       "peptide_nv_110                   0              0.986480   \n",
       "\n",
       "                model1_probability_1  model2_class_preds  \\\n",
       "# ID                                                       \n",
       "peptide_pv_1            5.075397e-01                   1   \n",
       "peptide_pv_2            9.617648e-01                   1   \n",
       "peptide_pv_3            9.999161e-01                   1   \n",
       "peptide_pv_4            9.999716e-01                   1   \n",
       "peptide_pv_5            9.999903e-01                   1   \n",
       "peptide_pv_6            9.998725e-01                   1   \n",
       "peptide_pv_7            9.615098e-01                   1   \n",
       "peptide_pv_8            9.994430e-01                   1   \n",
       "peptide_pv_9            9.979673e-01                   0   \n",
       "peptide_pv_10           9.998136e-01                   1   \n",
       "peptide_pv_11           9.907203e-01                   1   \n",
       "peptide_pv_12           9.946608e-01                   1   \n",
       "peptide_pv_13           9.663601e-01                   1   \n",
       "peptide_pv_14           8.862129e-01                   1   \n",
       "peptide_pv_15           9.968744e-01                   1   \n",
       "peptide_pv_16           8.950160e-01                   1   \n",
       "peptide_pv_17           7.805796e-01                   1   \n",
       "peptide_pv_18           9.998710e-01                   1   \n",
       "peptide_pv_19           9.789513e-01                   1   \n",
       "peptide_pv_20           9.999938e-01                   1   \n",
       "peptide_pv_21           9.999935e-01                   1   \n",
       "peptide_pv_22           9.299540e-01                   1   \n",
       "peptide_pv_23           9.808677e-01                   1   \n",
       "peptide_pv_24           1.184528e-03                   0   \n",
       "peptide_pv_25           9.510584e-01                   1   \n",
       "peptide_pv_26           9.998907e-01                   1   \n",
       "peptide_pv_27           9.962859e-01                   1   \n",
       "peptide_pv_28           5.444606e-01                   1   \n",
       "peptide_pv_29           9.963823e-01                   1   \n",
       "peptide_pv_30           8.492155e-01                   1   \n",
       "...                              ...                 ...   \n",
       "peptide_nv_81           1.503752e-05                   0   \n",
       "peptide_nv_82           5.131583e-04                   0   \n",
       "peptide_nv_83           1.817129e-02                   0   \n",
       "peptide_nv_84           7.202273e-04                   0   \n",
       "peptide_nv_85           2.076802e-03                   0   \n",
       "peptide_nv_86           2.701919e-08                   0   \n",
       "peptide_nv_87           4.176916e-07                   0   \n",
       "peptide_nv_88           6.183160e-02                   0   \n",
       "peptide_nv_89           4.140108e-01                   0   \n",
       "peptide_nv_90           9.343637e-03                   0   \n",
       "peptide_nv_91           2.374943e-04                   0   \n",
       "peptide_nv_92           2.189267e-04                   0   \n",
       "peptide_nv_93           8.400483e-04                   0   \n",
       "peptide_nv_94           4.449872e-02                   0   \n",
       "peptide_nv_95           5.843992e-04                   0   \n",
       "peptide_nv_96           1.213398e-01                   0   \n",
       "peptide_nv_97           1.970481e-02                   1   \n",
       "peptide_nv_98           1.204927e-03                   0   \n",
       "peptide_nv_99           8.372955e-03                   1   \n",
       "peptide_nv_100          1.987153e-02                   0   \n",
       "peptide_nv_101          1.873019e-02                   0   \n",
       "peptide_nv_102          1.364096e-03                   0   \n",
       "peptide_nv_103          2.683383e-03                   1   \n",
       "peptide_nv_104          4.829838e-08                   0   \n",
       "peptide_nv_105          1.503353e-04                   0   \n",
       "peptide_nv_106          2.361856e-03                   0   \n",
       "peptide_nv_107          8.181820e-04                   0   \n",
       "peptide_nv_108          6.535997e-05                   0   \n",
       "peptide_nv_109          6.630091e-04                   0   \n",
       "peptide_nv_110          1.351990e-02                   0   \n",
       "\n",
       "                model2_probability_0  model2_probability_1  \\\n",
       "# ID                                                         \n",
       "peptide_pv_1                0.006782              0.993218   \n",
       "peptide_pv_2                0.000091              0.999909   \n",
       "peptide_pv_3                0.000029              0.999971   \n",
       "peptide_pv_4                0.000158              0.999842   \n",
       "peptide_pv_5                0.000112              0.999888   \n",
       "peptide_pv_6                0.000053              0.999947   \n",
       "peptide_pv_7                0.000249              0.999751   \n",
       "peptide_pv_8                0.000004              0.999996   \n",
       "peptide_pv_9                0.835863              0.164137   \n",
       "peptide_pv_10               0.000051              0.999949   \n",
       "peptide_pv_11               0.014572              0.985428   \n",
       "peptide_pv_12               0.111667              0.888333   \n",
       "peptide_pv_13               0.052621              0.947379   \n",
       "peptide_pv_14               0.000752              0.999248   \n",
       "peptide_pv_15               0.000025              0.999975   \n",
       "peptide_pv_16               0.001173              0.998827   \n",
       "peptide_pv_17               0.000153              0.999847   \n",
       "peptide_pv_18               0.000069              0.999931   \n",
       "peptide_pv_19               0.000194              0.999806   \n",
       "peptide_pv_20               0.000036              0.999964   \n",
       "peptide_pv_21               0.000035              0.999965   \n",
       "peptide_pv_22               0.005641              0.994359   \n",
       "peptide_pv_23               0.003796              0.996204   \n",
       "peptide_pv_24               0.920973              0.079027   \n",
       "peptide_pv_25               0.000415              0.999585   \n",
       "peptide_pv_26               0.034885              0.965115   \n",
       "peptide_pv_27               0.007328              0.992672   \n",
       "peptide_pv_28               0.001589              0.998411   \n",
       "peptide_pv_29               0.000251              0.999749   \n",
       "peptide_pv_30               0.298198              0.701802   \n",
       "...                              ...                   ...   \n",
       "peptide_nv_81               0.999731              0.000269   \n",
       "peptide_nv_82               0.997395              0.002605   \n",
       "peptide_nv_83               0.969120              0.030880   \n",
       "peptide_nv_84               0.999993              0.000007   \n",
       "peptide_nv_85               0.999981              0.000019   \n",
       "peptide_nv_86               0.999986              0.000014   \n",
       "peptide_nv_87               0.999969              0.000031   \n",
       "peptide_nv_88               0.985386              0.014614   \n",
       "peptide_nv_89               0.999322              0.000678   \n",
       "peptide_nv_90               0.999848              0.000152   \n",
       "peptide_nv_91               0.999878              0.000122   \n",
       "peptide_nv_92               0.999957              0.000043   \n",
       "peptide_nv_93               0.999480              0.000520   \n",
       "peptide_nv_94               0.999273              0.000727   \n",
       "peptide_nv_95               0.999983              0.000017   \n",
       "peptide_nv_96               0.999873              0.000127   \n",
       "peptide_nv_97               0.162640              0.837360   \n",
       "peptide_nv_98               0.999890              0.000110   \n",
       "peptide_nv_99               0.219298              0.780702   \n",
       "peptide_nv_100              0.999882              0.000118   \n",
       "peptide_nv_101              0.999684              0.000316   \n",
       "peptide_nv_102              0.999664              0.000336   \n",
       "peptide_nv_103              0.090032              0.909968   \n",
       "peptide_nv_104              0.999994              0.000006   \n",
       "peptide_nv_105              0.999972              0.000028   \n",
       "peptide_nv_106              0.999986              0.000014   \n",
       "peptide_nv_107              0.996468              0.003532   \n",
       "peptide_nv_108              0.999987              0.000013   \n",
       "peptide_nv_109              0.999738              0.000262   \n",
       "peptide_nv_110              0.998687              0.001313   \n",
       "\n",
       "                model3_class_preds  model3_probability_0  model3_probability_1  \n",
       "# ID                                                                            \n",
       "peptide_pv_1                     1              0.004312              0.995688  \n",
       "peptide_pv_2                     1              0.000117              0.999883  \n",
       "peptide_pv_3                     1              0.000010              0.999990  \n",
       "peptide_pv_4                     1              0.000027              0.999973  \n",
       "peptide_pv_5                     1              0.000018              0.999982  \n",
       "peptide_pv_6                     1              0.000021              0.999979  \n",
       "peptide_pv_7                     1              0.002976              0.997024  \n",
       "peptide_pv_8                     1              0.000013              0.999987  \n",
       "peptide_pv_9                     1              0.187168              0.812832  \n",
       "peptide_pv_10                    1              0.000127              0.999873  \n",
       "peptide_pv_11                    1              0.001855              0.998145  \n",
       "peptide_pv_12                    1              0.001773              0.998227  \n",
       "peptide_pv_13                    1              0.001081              0.998919  \n",
       "peptide_pv_14                    1              0.002449              0.997551  \n",
       "peptide_pv_15                    1              0.001896              0.998104  \n",
       "peptide_pv_16                    1              0.000220              0.999780  \n",
       "peptide_pv_17                    1              0.000034              0.999966  \n",
       "peptide_pv_18                    1              0.000022              0.999978  \n",
       "peptide_pv_19                    1              0.007311              0.992689  \n",
       "peptide_pv_20                    1              0.000013              0.999987  \n",
       "peptide_pv_21                    1              0.000015              0.999985  \n",
       "peptide_pv_22                    1              0.003047              0.996953  \n",
       "peptide_pv_23                    1              0.006168              0.993832  \n",
       "peptide_pv_24                    0              0.974328              0.025672  \n",
       "peptide_pv_25                    1              0.000059              0.999941  \n",
       "peptide_pv_26                    1              0.014295              0.985705  \n",
       "peptide_pv_27                    1              0.001222              0.998778  \n",
       "peptide_pv_28                    1              0.000253              0.999747  \n",
       "peptide_pv_29                    1              0.000119              0.999881  \n",
       "peptide_pv_30                    1              0.261761              0.738239  \n",
       "...                            ...                   ...                   ...  \n",
       "peptide_nv_81                    0              0.997595              0.002405  \n",
       "peptide_nv_82                    0              0.998488              0.001512  \n",
       "peptide_nv_83                    0              0.812641              0.187359  \n",
       "peptide_nv_84                    0              0.999977              0.000023  \n",
       "peptide_nv_85                    0              0.999952              0.000048  \n",
       "peptide_nv_86                    0              0.999979              0.000021  \n",
       "peptide_nv_87                    0              0.999959              0.000041  \n",
       "peptide_nv_88                    0              0.997330              0.002670  \n",
       "peptide_nv_89                    0              0.997776              0.002224  \n",
       "peptide_nv_90                    0              0.999896              0.000104  \n",
       "peptide_nv_91                    0              0.999946              0.000054  \n",
       "peptide_nv_92                    0              0.999966              0.000034  \n",
       "peptide_nv_93                    0              0.999918              0.000082  \n",
       "peptide_nv_94                    0              0.999794              0.000206  \n",
       "peptide_nv_95                    0              0.999986              0.000014  \n",
       "peptide_nv_96                    0              0.999230              0.000770  \n",
       "peptide_nv_97                    0              0.783335              0.216665  \n",
       "peptide_nv_98                    0              0.999951              0.000049  \n",
       "peptide_nv_99                    1              0.006537              0.993463  \n",
       "peptide_nv_100                   0              0.999779              0.000221  \n",
       "peptide_nv_101                   0              0.999850              0.000150  \n",
       "peptide_nv_102                   0              0.999853              0.000147  \n",
       "peptide_nv_103                   1              0.204020              0.795980  \n",
       "peptide_nv_104                   0              0.999986              0.000014  \n",
       "peptide_nv_105                   0              0.999838              0.000162  \n",
       "peptide_nv_106                   0              0.999981              0.000019  \n",
       "peptide_nv_107                   0              0.999084              0.000916  \n",
       "peptide_nv_108                   0              0.999946              0.000054  \n",
       "peptide_nv_109                   0              0.998951              0.001049  \n",
       "peptide_nv_110                   0              0.999382              0.000618  \n",
       "\n",
       "[220 rows x 9 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge model dataframes\n",
    "models_hpi1 = [model1_hpi1_df, model2_hpi1_df, model3_hpi1_df]\n",
    "\n",
    "results_models_hpi1 = pd.concat(models_hpi1, axis=1, join='inner')\n",
    "results_models_hpi1.index = model1_hpi1_df.index\n",
    "results_models_hpi1\n",
    "\n",
    "# Merge validation dataframes\n",
    "validations_hpi1 = [model1_hpi1_df2, model2_hpi1_df2, model3_hpi1_df2]\n",
    "\n",
    "results_validations_hpi1 = pd.concat(validations_hpi1, axis=1, join='inner')\n",
    "results_validations_hpi1.index = model1_hpi1_df2.index\n",
    "results_validations_hpi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create consensus columns\n",
    "results_models_hpi1['consensus_class_preds'] = results_models_hpi1[['model1_class_preds', 'model2_class_preds', 'model3_class_preds']].mean(axis=1).astype(int)\n",
    "results_models_hpi1['consensus_probability_0'] = results_models_hpi1[['model1_probability_0', 'model2_probability_0', 'model3_probability_0']].mean(axis=1)\n",
    "results_models_hpi1['consensus_probability_1'] = results_models_hpi1[['model1_probability_1', 'model2_probability_1', 'model3_probability_1']].mean(axis=1)\n",
    "\n",
    "results_validations_hpi1['consensus_class_preds'] = results_validations_hpi1[['model1_class_preds', 'model2_class_preds', 'model3_class_preds']].mean(axis=1).astype(int)\n",
    "results_validations_hpi1['consensus_probability_0'] = results_validations_hpi1[['model1_probability_0', 'model2_probability_0', 'model3_probability_0']].mean(axis=1)\n",
    "results_validations_hpi1['consensus_probability_1'] = results_validations_hpi1[['model1_probability_1', 'model2_probability_1', 'model3_probability_1']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_models_hpi1.to_csv('./Results/predictions_models_HemoPI1.csv')\n",
    "results_validations_hpi1.to_csv('./Results/predictions_validations_HemoPI1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HemoPI-2 dataset\n",
    "\n",
    "model 1: GradientBoostingClassifier(n_estimators=112, max_depth=4, min_samples_leaf=2, max_features='sqrt', random_state=seed) with 56 modlampdescriptors - 77.7/74.3% accuracies\n",
    "\n",
    "model 2: GradientBoostingClassifier(random_state=seed) with 15 RFECV modlampdescriptors - 77.8/73.3% accuracies\n",
    "\n",
    "model 3: GradientBoostingClassifier(random_state=seed) with 56 modlampdescriptors - 76.7/72.3% accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: Model and validation predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "              max_features='sqrt', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=2, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=112,\n",
      "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "(812, 56)\n"
     ]
    }
   ],
   "source": [
    "model1_hpi2 =  GradientBoostingClassifier(n_estimators=112, max_depth=4, min_samples_leaf=2, max_features='sqrt', random_state=seed)\n",
    "\n",
    "print(model1_hpi2.fit(X_HemoPI2_model, y_HemoPI2_model))\n",
    "print(X_HemoPI2_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Models/model1_hpi2.pkl', 'wb') as f:\n",
    "    pickle.dump(model1_hpi2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save model set results into dataframe\n",
    "class_df = pd.DataFrame(model1_hpi2.predict(X_HemoPI2_model))\n",
    "probs_df = pd.DataFrame(model1_hpi2.predict_proba(X_HemoPI2_model))\n",
    "\n",
    "model1_hpi2_df = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model1_hpi2_df.index = X_HemoPI2_model.index\n",
    "model1_hpi2_df.columns = ['model1_class_preds', 'model1_probability_0', 'model1_probability_1']\n",
    "\n",
    "#Save validation set results into dataframe\n",
    "class_df2 = pd.DataFrame(model1_hpi2.predict(X_HemoPI2_validation))\n",
    "probs_df2 = pd.DataFrame(model1_hpi2.predict_proba(X_HemoPI2_validation))\n",
    "\n",
    "model1_hpi2_df2 = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model1_hpi2_df2.index = X_HemoPI2_validation.index\n",
    "model1_hpi2_df2.columns = ['model1_class_preds', 'model1_probability_0', 'model1_probability_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2: Model and validation predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "(812, 15)\n"
     ]
    }
   ],
   "source": [
    "model2_hpi2 = GradientBoostingClassifier(random_state=seed)\n",
    "\n",
    "rfecv_model = RFECV(model2_hpi2, step=1, cv=skfold)\n",
    "rfecv = rfecv_model.fit(X_HemoPI2_model, y_HemoPI2_model)\n",
    "X_HemoPI2_model_RFE = rfecv.transform(X_HemoPI2_model)\n",
    "X_HemoPI2_val_RFE = rfecv.transform(X_HemoPI2_validation)\n",
    "\n",
    "print(model2_hpi2.fit(X_HemoPI2_model_RFE, y_HemoPI2_model))\n",
    "print(X_HemoPI2_model_RFE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Models/model2_hpi2.pkl', 'wb') as f:\n",
    "    pickle.dump(model2_hpi2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save model set results into dataframe\n",
    "class_df = pd.DataFrame(model2_hpi2.predict(X_HemoPI2_model_RFE))\n",
    "probs_df = pd.DataFrame(model2_hpi2.predict_proba(X_HemoPI2_model_RFE))\n",
    "\n",
    "model2_hpi2_df = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model2_hpi2_df.index = X_HemoPI2_model.index\n",
    "model2_hpi2_df.columns = ['model2_class_preds', 'model2_probability_0', 'model2_probability_1']\n",
    "\n",
    "#Save validation set results into dataframe\n",
    "class_df2 = pd.DataFrame(model2_hpi2.predict(X_HemoPI2_val_RFE))\n",
    "probs_df2 = pd.DataFrame(model2_hpi2.predict_proba(X_HemoPI2_val_RFE))\n",
    "\n",
    "model2_hpi2_df2 = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model2_hpi2_df2.index = X_HemoPI2_validation.index\n",
    "model2_hpi2_df2.columns = ['model2_class_preds', 'model2_probability_0', 'model2_probability_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3: Model and validation predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3_hpi2 = GradientBoostingClassifier(random_state=seed)\n",
    "model3_hpi2.fit(X_HemoPI2_model, y_HemoPI2_model)\n",
    "\n",
    "with open('./Models/model3_hpi2.pkl', 'wb') as f:\n",
    "    pickle.dump(model3_hpi2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save model set results into dataframe\n",
    "class_df = pd.DataFrame(model3_hpi2.predict(X_HemoPI2_model))\n",
    "probs_df = pd.DataFrame(model3_hpi2.predict_proba(X_HemoPI2_model))\n",
    "\n",
    "model3_hpi2_df = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model3_hpi2_df.index = X_HemoPI2_model.index\n",
    "model3_hpi2_df.columns = ['model3_class_preds', 'model3_probability_0', 'model3_probability_1']\n",
    "\n",
    "#Save validation set results into dataframe\n",
    "class_df2 = pd.DataFrame(model3_hpi2.predict(X_HemoPI2_validation))\n",
    "probs_df2 = pd.DataFrame(model3_hpi2.predict_proba(X_HemoPI2_validation))\n",
    "\n",
    "model3_hpi2_df2 = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model3_hpi2_df2.index = X_HemoPI2_validation.index\n",
    "model3_hpi2_df2.columns = ['model3_class_preds', 'model3_probability_0', 'model3_probability_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1_class_preds</th>\n",
       "      <th>model1_probability_0</th>\n",
       "      <th>model1_probability_1</th>\n",
       "      <th>model2_class_preds</th>\n",
       "      <th>model2_probability_0</th>\n",
       "      <th>model2_probability_1</th>\n",
       "      <th>model3_class_preds</th>\n",
       "      <th>model3_probability_0</th>\n",
       "      <th>model3_probability_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>peptide_pv_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.180664</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121939</td>\n",
       "      <td>0.878061</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425659</td>\n",
       "      <td>0.574341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.188377</td>\n",
       "      <td>0.811623</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111635</td>\n",
       "      <td>0.888365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131263</td>\n",
       "      <td>0.868737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.515808</td>\n",
       "      <td>0.484192</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652476</td>\n",
       "      <td>0.347524</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688241</td>\n",
       "      <td>0.311759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.034770</td>\n",
       "      <td>0.965230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041512</td>\n",
       "      <td>0.958488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.041337</td>\n",
       "      <td>0.958663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.055106</td>\n",
       "      <td>0.944894</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050929</td>\n",
       "      <td>0.949071</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044059</td>\n",
       "      <td>0.955941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.030672</td>\n",
       "      <td>0.969328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119268</td>\n",
       "      <td>0.880732</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071487</td>\n",
       "      <td>0.928513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.320251</td>\n",
       "      <td>0.679749</td>\n",
       "      <td>1</td>\n",
       "      <td>0.473491</td>\n",
       "      <td>0.526509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.363196</td>\n",
       "      <td>0.636804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.140724</td>\n",
       "      <td>0.859276</td>\n",
       "      <td>1</td>\n",
       "      <td>0.286062</td>\n",
       "      <td>0.713938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.193829</td>\n",
       "      <td>0.806171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.227765</td>\n",
       "      <td>0.772235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483652</td>\n",
       "      <td>0.516348</td>\n",
       "      <td>1</td>\n",
       "      <td>0.385809</td>\n",
       "      <td>0.614191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.088689</td>\n",
       "      <td>0.911311</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145979</td>\n",
       "      <td>0.854021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127801</td>\n",
       "      <td>0.872199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.527580</td>\n",
       "      <td>0.472420</td>\n",
       "      <td>0</td>\n",
       "      <td>0.809602</td>\n",
       "      <td>0.190398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607605</td>\n",
       "      <td>0.392395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.042826</td>\n",
       "      <td>0.957174</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037182</td>\n",
       "      <td>0.962818</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091262</td>\n",
       "      <td>0.908738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.026388</td>\n",
       "      <td>0.973612</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.982407</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044344</td>\n",
       "      <td>0.955656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.072262</td>\n",
       "      <td>0.927738</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028328</td>\n",
       "      <td>0.971672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.978378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066931</td>\n",
       "      <td>0.933069</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035776</td>\n",
       "      <td>0.964224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174694</td>\n",
       "      <td>0.825306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.245049</td>\n",
       "      <td>0.754951</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111635</td>\n",
       "      <td>0.888365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131263</td>\n",
       "      <td>0.868737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.090151</td>\n",
       "      <td>0.909849</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118921</td>\n",
       "      <td>0.881079</td>\n",
       "      <td>1</td>\n",
       "      <td>0.168183</td>\n",
       "      <td>0.831817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.037113</td>\n",
       "      <td>0.962887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176970</td>\n",
       "      <td>0.823030</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064158</td>\n",
       "      <td>0.935842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.388479</td>\n",
       "      <td>0.611521</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070794</td>\n",
       "      <td>0.929206</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259885</td>\n",
       "      <td>0.740115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.198269</td>\n",
       "      <td>0.801731</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799628</td>\n",
       "      <td>0.200372</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152343</td>\n",
       "      <td>0.847657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.194164</td>\n",
       "      <td>0.805836</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156656</td>\n",
       "      <td>0.843344</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044269</td>\n",
       "      <td>0.955731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.378111</td>\n",
       "      <td>0.621889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.106288</td>\n",
       "      <td>0.893712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119874</td>\n",
       "      <td>0.880126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.868917</td>\n",
       "      <td>0.131083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738135</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581113</td>\n",
       "      <td>0.418887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.438859</td>\n",
       "      <td>0.561141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526406</td>\n",
       "      <td>0.473594</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398372</td>\n",
       "      <td>0.601628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.235487</td>\n",
       "      <td>0.764513</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156656</td>\n",
       "      <td>0.843344</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044269</td>\n",
       "      <td>0.955731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.988113</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012615</td>\n",
       "      <td>0.987385</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>0.986582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.050472</td>\n",
       "      <td>0.949528</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058189</td>\n",
       "      <td>0.941811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234841</td>\n",
       "      <td>0.765159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.117348</td>\n",
       "      <td>0.882652</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423231</td>\n",
       "      <td>0.576769</td>\n",
       "      <td>1</td>\n",
       "      <td>0.205124</td>\n",
       "      <td>0.794876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025602</td>\n",
       "      <td>0.974398</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044296</td>\n",
       "      <td>0.955704</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030937</td>\n",
       "      <td>0.969063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_pv_30</th>\n",
       "      <td>1</td>\n",
       "      <td>0.080943</td>\n",
       "      <td>0.919057</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227439</td>\n",
       "      <td>0.772561</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169253</td>\n",
       "      <td>0.830747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_63</th>\n",
       "      <td>0</td>\n",
       "      <td>0.606824</td>\n",
       "      <td>0.393176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.744255</td>\n",
       "      <td>0.255745</td>\n",
       "      <td>0</td>\n",
       "      <td>0.746801</td>\n",
       "      <td>0.253199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_64</th>\n",
       "      <td>0</td>\n",
       "      <td>0.742194</td>\n",
       "      <td>0.257806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.844613</td>\n",
       "      <td>0.155387</td>\n",
       "      <td>1</td>\n",
       "      <td>0.487788</td>\n",
       "      <td>0.512212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_65</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066564</td>\n",
       "      <td>0.933436</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023582</td>\n",
       "      <td>0.976418</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111896</td>\n",
       "      <td>0.888104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_66</th>\n",
       "      <td>1</td>\n",
       "      <td>0.190253</td>\n",
       "      <td>0.809747</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078422</td>\n",
       "      <td>0.921578</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122405</td>\n",
       "      <td>0.877595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_67</th>\n",
       "      <td>0</td>\n",
       "      <td>0.743163</td>\n",
       "      <td>0.256837</td>\n",
       "      <td>0</td>\n",
       "      <td>0.804984</td>\n",
       "      <td>0.195016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.535972</td>\n",
       "      <td>0.464028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_68</th>\n",
       "      <td>0</td>\n",
       "      <td>0.905975</td>\n",
       "      <td>0.094025</td>\n",
       "      <td>0</td>\n",
       "      <td>0.867922</td>\n",
       "      <td>0.132078</td>\n",
       "      <td>0</td>\n",
       "      <td>0.855680</td>\n",
       "      <td>0.144320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_69</th>\n",
       "      <td>0</td>\n",
       "      <td>0.865861</td>\n",
       "      <td>0.134139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712033</td>\n",
       "      <td>0.287967</td>\n",
       "      <td>0</td>\n",
       "      <td>0.876242</td>\n",
       "      <td>0.123758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_70</th>\n",
       "      <td>1</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>0.976553</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060282</td>\n",
       "      <td>0.939718</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054136</td>\n",
       "      <td>0.945864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_71</th>\n",
       "      <td>0</td>\n",
       "      <td>0.735497</td>\n",
       "      <td>0.264503</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671050</td>\n",
       "      <td>0.328950</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610077</td>\n",
       "      <td>0.389923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_72</th>\n",
       "      <td>0</td>\n",
       "      <td>0.844868</td>\n",
       "      <td>0.155132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775898</td>\n",
       "      <td>0.224102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854985</td>\n",
       "      <td>0.145015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_73</th>\n",
       "      <td>1</td>\n",
       "      <td>0.422415</td>\n",
       "      <td>0.577585</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524425</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581796</td>\n",
       "      <td>0.418204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_74</th>\n",
       "      <td>1</td>\n",
       "      <td>0.134374</td>\n",
       "      <td>0.865626</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053270</td>\n",
       "      <td>0.946730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070847</td>\n",
       "      <td>0.929153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_75</th>\n",
       "      <td>0</td>\n",
       "      <td>0.701080</td>\n",
       "      <td>0.298920</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246584</td>\n",
       "      <td>0.753416</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396644</td>\n",
       "      <td>0.603356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_76</th>\n",
       "      <td>1</td>\n",
       "      <td>0.335085</td>\n",
       "      <td>0.664915</td>\n",
       "      <td>0</td>\n",
       "      <td>0.554022</td>\n",
       "      <td>0.445978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550841</td>\n",
       "      <td>0.449159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_77</th>\n",
       "      <td>0</td>\n",
       "      <td>0.927120</td>\n",
       "      <td>0.072880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975485</td>\n",
       "      <td>0.024515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.831747</td>\n",
       "      <td>0.168253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_78</th>\n",
       "      <td>0</td>\n",
       "      <td>0.544041</td>\n",
       "      <td>0.455959</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686413</td>\n",
       "      <td>0.313587</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738332</td>\n",
       "      <td>0.261668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_79</th>\n",
       "      <td>1</td>\n",
       "      <td>0.054414</td>\n",
       "      <td>0.945586</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075016</td>\n",
       "      <td>0.924984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122004</td>\n",
       "      <td>0.877996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_80</th>\n",
       "      <td>0</td>\n",
       "      <td>0.567021</td>\n",
       "      <td>0.432979</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096926</td>\n",
       "      <td>0.903074</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277188</td>\n",
       "      <td>0.722812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_81</th>\n",
       "      <td>0</td>\n",
       "      <td>0.816652</td>\n",
       "      <td>0.183348</td>\n",
       "      <td>0</td>\n",
       "      <td>0.696011</td>\n",
       "      <td>0.303989</td>\n",
       "      <td>0</td>\n",
       "      <td>0.828898</td>\n",
       "      <td>0.171102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_82</th>\n",
       "      <td>1</td>\n",
       "      <td>0.228890</td>\n",
       "      <td>0.771110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.148176</td>\n",
       "      <td>0.851824</td>\n",
       "      <td>1</td>\n",
       "      <td>0.131783</td>\n",
       "      <td>0.868217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_83</th>\n",
       "      <td>1</td>\n",
       "      <td>0.211965</td>\n",
       "      <td>0.788035</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266898</td>\n",
       "      <td>0.733102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161839</td>\n",
       "      <td>0.838161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_84</th>\n",
       "      <td>1</td>\n",
       "      <td>0.080904</td>\n",
       "      <td>0.919096</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049725</td>\n",
       "      <td>0.950275</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103165</td>\n",
       "      <td>0.896835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_85</th>\n",
       "      <td>1</td>\n",
       "      <td>0.110472</td>\n",
       "      <td>0.889528</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044473</td>\n",
       "      <td>0.955527</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_86</th>\n",
       "      <td>0</td>\n",
       "      <td>0.525248</td>\n",
       "      <td>0.474752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526390</td>\n",
       "      <td>0.473610</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518303</td>\n",
       "      <td>0.481697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_87</th>\n",
       "      <td>0</td>\n",
       "      <td>0.772947</td>\n",
       "      <td>0.227053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.964965</td>\n",
       "      <td>0.035035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905917</td>\n",
       "      <td>0.094083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_88</th>\n",
       "      <td>1</td>\n",
       "      <td>0.055564</td>\n",
       "      <td>0.944436</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030453</td>\n",
       "      <td>0.969547</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051888</td>\n",
       "      <td>0.948112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_89</th>\n",
       "      <td>1</td>\n",
       "      <td>0.040785</td>\n",
       "      <td>0.959215</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016390</td>\n",
       "      <td>0.983610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022625</td>\n",
       "      <td>0.977375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_90</th>\n",
       "      <td>0</td>\n",
       "      <td>0.643693</td>\n",
       "      <td>0.356307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450495</td>\n",
       "      <td>0.549505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197512</td>\n",
       "      <td>0.802488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_91</th>\n",
       "      <td>1</td>\n",
       "      <td>0.120718</td>\n",
       "      <td>0.879282</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347904</td>\n",
       "      <td>0.652096</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450482</td>\n",
       "      <td>0.549518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_nv_92</th>\n",
       "      <td>1</td>\n",
       "      <td>0.185183</td>\n",
       "      <td>0.814817</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250492</td>\n",
       "      <td>0.749508</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495665</td>\n",
       "      <td>0.504335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model1_class_preds  model1_probability_0  model1_probability_1  \\\n",
       "# ID                                                                            \n",
       "peptide_pv_1                    1              0.180664              0.819336   \n",
       "peptide_pv_2                    1              0.188377              0.811623   \n",
       "peptide_pv_3                    0              0.515808              0.484192   \n",
       "peptide_pv_4                    1              0.034770              0.965230   \n",
       "peptide_pv_5                    1              0.055106              0.944894   \n",
       "peptide_pv_6                    1              0.030672              0.969328   \n",
       "peptide_pv_7                    1              0.320251              0.679749   \n",
       "peptide_pv_8                    1              0.140724              0.859276   \n",
       "peptide_pv_9                    1              0.227765              0.772235   \n",
       "peptide_pv_10                   1              0.088689              0.911311   \n",
       "peptide_pv_11                   0              0.527580              0.472420   \n",
       "peptide_pv_12                   1              0.042826              0.957174   \n",
       "peptide_pv_13                   1              0.026388              0.973612   \n",
       "peptide_pv_14                   1              0.072262              0.927738   \n",
       "peptide_pv_15                   1              0.066931              0.933069   \n",
       "peptide_pv_16                   1              0.245049              0.754951   \n",
       "peptide_pv_17                   1              0.090151              0.909849   \n",
       "peptide_pv_18                   1              0.037113              0.962887   \n",
       "peptide_pv_19                   1              0.388479              0.611521   \n",
       "peptide_pv_20                   1              0.198269              0.801731   \n",
       "peptide_pv_21                   1              0.194164              0.805836   \n",
       "peptide_pv_22                   1              0.378111              0.621889   \n",
       "peptide_pv_23                   0              0.868917              0.131083   \n",
       "peptide_pv_24                   1              0.438859              0.561141   \n",
       "peptide_pv_25                   1              0.235487              0.764513   \n",
       "peptide_pv_26                   1              0.011887              0.988113   \n",
       "peptide_pv_27                   1              0.050472              0.949528   \n",
       "peptide_pv_28                   1              0.117348              0.882652   \n",
       "peptide_pv_29                   1              0.025602              0.974398   \n",
       "peptide_pv_30                   1              0.080943              0.919057   \n",
       "...                           ...                   ...                   ...   \n",
       "peptide_nv_63                   0              0.606824              0.393176   \n",
       "peptide_nv_64                   0              0.742194              0.257806   \n",
       "peptide_nv_65                   1              0.066564              0.933436   \n",
       "peptide_nv_66                   1              0.190253              0.809747   \n",
       "peptide_nv_67                   0              0.743163              0.256837   \n",
       "peptide_nv_68                   0              0.905975              0.094025   \n",
       "peptide_nv_69                   0              0.865861              0.134139   \n",
       "peptide_nv_70                   1              0.023447              0.976553   \n",
       "peptide_nv_71                   0              0.735497              0.264503   \n",
       "peptide_nv_72                   0              0.844868              0.155132   \n",
       "peptide_nv_73                   1              0.422415              0.577585   \n",
       "peptide_nv_74                   1              0.134374              0.865626   \n",
       "peptide_nv_75                   0              0.701080              0.298920   \n",
       "peptide_nv_76                   1              0.335085              0.664915   \n",
       "peptide_nv_77                   0              0.927120              0.072880   \n",
       "peptide_nv_78                   0              0.544041              0.455959   \n",
       "peptide_nv_79                   1              0.054414              0.945586   \n",
       "peptide_nv_80                   0              0.567021              0.432979   \n",
       "peptide_nv_81                   0              0.816652              0.183348   \n",
       "peptide_nv_82                   1              0.228890              0.771110   \n",
       "peptide_nv_83                   1              0.211965              0.788035   \n",
       "peptide_nv_84                   1              0.080904              0.919096   \n",
       "peptide_nv_85                   1              0.110472              0.889528   \n",
       "peptide_nv_86                   0              0.525248              0.474752   \n",
       "peptide_nv_87                   0              0.772947              0.227053   \n",
       "peptide_nv_88                   1              0.055564              0.944436   \n",
       "peptide_nv_89                   1              0.040785              0.959215   \n",
       "peptide_nv_90                   0              0.643693              0.356307   \n",
       "peptide_nv_91                   1              0.120718              0.879282   \n",
       "peptide_nv_92                   1              0.185183              0.814817   \n",
       "\n",
       "               model2_class_preds  model2_probability_0  model2_probability_1  \\\n",
       "# ID                                                                            \n",
       "peptide_pv_1                    1              0.121939              0.878061   \n",
       "peptide_pv_2                    1              0.111635              0.888365   \n",
       "peptide_pv_3                    0              0.652476              0.347524   \n",
       "peptide_pv_4                    1              0.041512              0.958488   \n",
       "peptide_pv_5                    1              0.050929              0.949071   \n",
       "peptide_pv_6                    1              0.119268              0.880732   \n",
       "peptide_pv_7                    1              0.473491              0.526509   \n",
       "peptide_pv_8                    1              0.286062              0.713938   \n",
       "peptide_pv_9                    1              0.483652              0.516348   \n",
       "peptide_pv_10                   1              0.145979              0.854021   \n",
       "peptide_pv_11                   0              0.809602              0.190398   \n",
       "peptide_pv_12                   1              0.037182              0.962818   \n",
       "peptide_pv_13                   1              0.017593              0.982407   \n",
       "peptide_pv_14                   1              0.028328              0.971672   \n",
       "peptide_pv_15                   1              0.035776              0.964224   \n",
       "peptide_pv_16                   1              0.111635              0.888365   \n",
       "peptide_pv_17                   1              0.118921              0.881079   \n",
       "peptide_pv_18                   1              0.176970              0.823030   \n",
       "peptide_pv_19                   1              0.070794              0.929206   \n",
       "peptide_pv_20                   0              0.799628              0.200372   \n",
       "peptide_pv_21                   1              0.156656              0.843344   \n",
       "peptide_pv_22                   1              0.106288              0.893712   \n",
       "peptide_pv_23                   0              0.738135              0.261865   \n",
       "peptide_pv_24                   0              0.526406              0.473594   \n",
       "peptide_pv_25                   1              0.156656              0.843344   \n",
       "peptide_pv_26                   1              0.012615              0.987385   \n",
       "peptide_pv_27                   1              0.058189              0.941811   \n",
       "peptide_pv_28                   1              0.423231              0.576769   \n",
       "peptide_pv_29                   1              0.044296              0.955704   \n",
       "peptide_pv_30                   1              0.227439              0.772561   \n",
       "...                           ...                   ...                   ...   \n",
       "peptide_nv_63                   0              0.744255              0.255745   \n",
       "peptide_nv_64                   0              0.844613              0.155387   \n",
       "peptide_nv_65                   1              0.023582              0.976418   \n",
       "peptide_nv_66                   1              0.078422              0.921578   \n",
       "peptide_nv_67                   0              0.804984              0.195016   \n",
       "peptide_nv_68                   0              0.867922              0.132078   \n",
       "peptide_nv_69                   0              0.712033              0.287967   \n",
       "peptide_nv_70                   1              0.060282              0.939718   \n",
       "peptide_nv_71                   0              0.671050              0.328950   \n",
       "peptide_nv_72                   0              0.775898              0.224102   \n",
       "peptide_nv_73                   0              0.524425              0.475575   \n",
       "peptide_nv_74                   1              0.053270              0.946730   \n",
       "peptide_nv_75                   1              0.246584              0.753416   \n",
       "peptide_nv_76                   0              0.554022              0.445978   \n",
       "peptide_nv_77                   0              0.975485              0.024515   \n",
       "peptide_nv_78                   0              0.686413              0.313587   \n",
       "peptide_nv_79                   1              0.075016              0.924984   \n",
       "peptide_nv_80                   1              0.096926              0.903074   \n",
       "peptide_nv_81                   0              0.696011              0.303989   \n",
       "peptide_nv_82                   1              0.148176              0.851824   \n",
       "peptide_nv_83                   1              0.266898              0.733102   \n",
       "peptide_nv_84                   1              0.049725              0.950275   \n",
       "peptide_nv_85                   1              0.044473              0.955527   \n",
       "peptide_nv_86                   0              0.526390              0.473610   \n",
       "peptide_nv_87                   0              0.964965              0.035035   \n",
       "peptide_nv_88                   1              0.030453              0.969547   \n",
       "peptide_nv_89                   1              0.016390              0.983610   \n",
       "peptide_nv_90                   1              0.450495              0.549505   \n",
       "peptide_nv_91                   1              0.347904              0.652096   \n",
       "peptide_nv_92                   1              0.250492              0.749508   \n",
       "\n",
       "               model3_class_preds  model3_probability_0  model3_probability_1  \n",
       "# ID                                                                           \n",
       "peptide_pv_1                    1              0.425659              0.574341  \n",
       "peptide_pv_2                    1              0.131263              0.868737  \n",
       "peptide_pv_3                    0              0.688241              0.311759  \n",
       "peptide_pv_4                    1              0.041337              0.958663  \n",
       "peptide_pv_5                    1              0.044059              0.955941  \n",
       "peptide_pv_6                    1              0.071487              0.928513  \n",
       "peptide_pv_7                    1              0.363196              0.636804  \n",
       "peptide_pv_8                    1              0.193829              0.806171  \n",
       "peptide_pv_9                    1              0.385809              0.614191  \n",
       "peptide_pv_10                   1              0.127801              0.872199  \n",
       "peptide_pv_11                   0              0.607605              0.392395  \n",
       "peptide_pv_12                   1              0.091262              0.908738  \n",
       "peptide_pv_13                   1              0.044344              0.955656  \n",
       "peptide_pv_14                   1              0.021622              0.978378  \n",
       "peptide_pv_15                   1              0.174694              0.825306  \n",
       "peptide_pv_16                   1              0.131263              0.868737  \n",
       "peptide_pv_17                   1              0.168183              0.831817  \n",
       "peptide_pv_18                   1              0.064158              0.935842  \n",
       "peptide_pv_19                   1              0.259885              0.740115  \n",
       "peptide_pv_20                   1              0.152343              0.847657  \n",
       "peptide_pv_21                   1              0.044269              0.955731  \n",
       "peptide_pv_22                   1              0.119874              0.880126  \n",
       "peptide_pv_23                   0              0.581113              0.418887  \n",
       "peptide_pv_24                   1              0.398372              0.601628  \n",
       "peptide_pv_25                   1              0.044269              0.955731  \n",
       "peptide_pv_26                   1              0.013418              0.986582  \n",
       "peptide_pv_27                   1              0.234841              0.765159  \n",
       "peptide_pv_28                   1              0.205124              0.794876  \n",
       "peptide_pv_29                   1              0.030937              0.969063  \n",
       "peptide_pv_30                   1              0.169253              0.830747  \n",
       "...                           ...                   ...                   ...  \n",
       "peptide_nv_63                   0              0.746801              0.253199  \n",
       "peptide_nv_64                   1              0.487788              0.512212  \n",
       "peptide_nv_65                   1              0.111896              0.888104  \n",
       "peptide_nv_66                   1              0.122405              0.877595  \n",
       "peptide_nv_67                   0              0.535972              0.464028  \n",
       "peptide_nv_68                   0              0.855680              0.144320  \n",
       "peptide_nv_69                   0              0.876242              0.123758  \n",
       "peptide_nv_70                   1              0.054136              0.945864  \n",
       "peptide_nv_71                   0              0.610077              0.389923  \n",
       "peptide_nv_72                   0              0.854985              0.145015  \n",
       "peptide_nv_73                   0              0.581796              0.418204  \n",
       "peptide_nv_74                   1              0.070847              0.929153  \n",
       "peptide_nv_75                   1              0.396644              0.603356  \n",
       "peptide_nv_76                   0              0.550841              0.449159  \n",
       "peptide_nv_77                   0              0.831747              0.168253  \n",
       "peptide_nv_78                   0              0.738332              0.261668  \n",
       "peptide_nv_79                   1              0.122004              0.877996  \n",
       "peptide_nv_80                   1              0.277188              0.722812  \n",
       "peptide_nv_81                   0              0.828898              0.171102  \n",
       "peptide_nv_82                   1              0.131783              0.868217  \n",
       "peptide_nv_83                   1              0.161839              0.838161  \n",
       "peptide_nv_84                   1              0.103165              0.896835  \n",
       "peptide_nv_85                   1              0.096000              0.904000  \n",
       "peptide_nv_86                   0              0.518303              0.481697  \n",
       "peptide_nv_87                   0              0.905917              0.094083  \n",
       "peptide_nv_88                   1              0.051888              0.948112  \n",
       "peptide_nv_89                   1              0.022625              0.977375  \n",
       "peptide_nv_90                   1              0.197512              0.802488  \n",
       "peptide_nv_91                   1              0.450482              0.549518  \n",
       "peptide_nv_92                   1              0.495665              0.504335  \n",
       "\n",
       "[202 rows x 9 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge model dataframes\n",
    "models_hpi2 = [model1_hpi2_df, model2_hpi2_df, model3_hpi2_df]\n",
    "\n",
    "results_models_hpi2 = pd.concat(models_hpi2, axis=1, join='inner')\n",
    "results_models_hpi2.index = model1_hpi2_df.index\n",
    "results_models_hpi2\n",
    "\n",
    "# Merge validation dataframes\n",
    "validations_hpi2 = [model1_hpi2_df2, model2_hpi2_df2, model3_hpi2_df2]\n",
    "\n",
    "results_validations_hpi2 = pd.concat(validations_hpi2, axis=1, join='inner')\n",
    "results_validations_hpi2.index = model1_hpi2_df2.index\n",
    "results_validations_hpi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create consensus columns\n",
    "results_models_hpi2['consensus_class_preds'] = results_models_hpi2[['model1_class_preds', 'model2_class_preds', 'model3_class_preds']].mean(axis=1).astype(int)\n",
    "results_models_hpi2['consensus_probability_0'] = results_models_hpi2[['model1_probability_0', 'model2_probability_0', 'model3_probability_0']].mean(axis=1)\n",
    "results_models_hpi2['consensus_probability_1'] = results_models_hpi2[['model1_probability_1', 'model2_probability_1', 'model3_probability_1']].mean(axis=1)\n",
    "\n",
    "results_validations_hpi2['consensus_class_preds'] = results_validations_hpi2[['model1_class_preds', 'model2_class_preds', 'model3_class_preds']].mean(axis=1).astype(int)\n",
    "results_validations_hpi2['consensus_probability_0'] = results_validations_hpi2[['model1_probability_0', 'model2_probability_0', 'model3_probability_0']].mean(axis=1)\n",
    "results_validations_hpi2['consensus_probability_1'] = results_validations_hpi2[['model1_probability_1', 'model2_probability_1', 'model3_probability_1']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_models_hpi2.to_csv('./Results/predictions_models_HemoPI2.csv')\n",
    "results_validations_hpi2.to_csv('./Results/predictions_validations_HemoPI2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HemoPI-3 dataset\n",
    "\n",
    "model 1: GradientBoostingClassifier(n_estimators=192, max_depth=18, min_samples_leaf=10, max_features='log2', random_state=seed) with 56 modlampdescriptors - 80.0/71.7% accuracies\n",
    "\n",
    "model 2: GradientBoostingClassifier(n_estimators=160, max_depth=12, min_samples_leaf=8, max_features='sqrt', random_state=seed) with 34 RFECV modlampdescriptors - 79.0/72.0% accuracies\n",
    "\n",
    "model 3: GradientBoostingClassifier(n_estimators=96, max_depth=20, min_samples_leaf=8, max_features='log2', random_state=seed) with 28 modlampdescriptors (after multicollinearity 0.75) - 78.0/72.6% accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: Model and validation predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=18,\n",
      "              max_features='log2', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=10, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=192,\n",
      "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "(1298, 56)\n"
     ]
    }
   ],
   "source": [
    "model1_hpi3 = GradientBoostingClassifier(n_estimators=192, max_depth=18, min_samples_leaf=10, max_features='log2', random_state=seed)\n",
    "print(model1_hpi3.fit(X_HemoPI3_model, y_HemoPI3_model))\n",
    "print(X_HemoPI3_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Models/model1_hpi3.pkl', 'wb') as f:\n",
    "    pickle.dump(model1_hpi3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save model set results into dataframe\n",
    "class_df = pd.DataFrame(model1_hpi3.predict(X_HemoPI3_model))\n",
    "probs_df = pd.DataFrame(model1_hpi3.predict_proba(X_HemoPI3_model))\n",
    "\n",
    "model1_hpi3_df = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model1_hpi3_df.index = X_HemoPI3_model.index\n",
    "model1_hpi3_df.columns = ['model1_class_preds', 'model1_probability_0', 'model1_probability_1']\n",
    "\n",
    "#Save validation set results into dataframe\n",
    "class_df2 = pd.DataFrame(model1_hpi3.predict(X_HemoPI3_validation))\n",
    "probs_df2 = pd.DataFrame(model1_hpi3.predict_proba(X_HemoPI3_validation))\n",
    "\n",
    "model1_hpi3_df2 = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model1_hpi3_df2.index = X_HemoPI3_validation.index\n",
    "model1_hpi3_df2.columns = ['model1_class_preds', 'model1_probability_0', 'model1_probability_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2: Model and validation predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=12,\n",
      "              max_features='sqrt', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=8, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=160,\n",
      "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "(1298, 40)\n"
     ]
    }
   ],
   "source": [
    "model2_hpi3 = GradientBoostingClassifier(n_estimators=160, max_depth=12, min_samples_leaf=8, max_features='sqrt', random_state=seed)\n",
    "\n",
    "rfecv_model = RFECV(model2_hpi3, step=1, cv=skfold)\n",
    "rfecv = rfecv_model.fit(X_HemoPI3_model, y_HemoPI3_model)\n",
    "X_HemoPI3_model_RFE = rfecv.transform(X_HemoPI3_model)\n",
    "X_HemoPI3_val_RFE = rfecv.transform(X_HemoPI3_validation)\n",
    "\n",
    "print(model2_hpi3.fit(X_HemoPI3_model_RFE, y_HemoPI3_model))\n",
    "print(X_HemoPI3_model_RFE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Models/model2_hpi3.pkl', 'wb') as f:\n",
    "    pickle.dump(model2_hpi3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save model set results into dataframe\n",
    "class_df = pd.DataFrame(model2_hpi3.predict(X_HemoPI3_model_RFE))\n",
    "probs_df = pd.DataFrame(model2_hpi3.predict_proba(X_HemoPI3_model_RFE))\n",
    "\n",
    "model2_hpi3_df = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model2_hpi3_df.index = X_HemoPI3_model.index\n",
    "model2_hpi3_df.columns = ['model2_class_preds', 'model2_probability_0', 'model2_probability_1']\n",
    "\n",
    "#Save validation set results into dataframe\n",
    "class_df2 = pd.DataFrame(model2_hpi3.predict(X_HemoPI3_val_RFE))\n",
    "probs_df2 = pd.DataFrame(model2_hpi3.predict_proba(X_HemoPI3_val_RFE))\n",
    "\n",
    "model2_hpi3_df2 = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model2_hpi3_df2.index = X_HemoPI3_validation.index\n",
    "model2_hpi3_df2.columns = ['model2_class_preds', 'model2_probability_0', 'model2_probability_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3: Model and validation predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=20,\n",
      "              max_features='log2', max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=8, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=96,\n",
      "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "((1298, 28), (325, 28))\n"
     ]
    }
   ],
   "source": [
    "model3_hpi3 = GradientBoostingClassifier(n_estimators=96, max_depth=20, min_samples_leaf=8, max_features='log2', random_state=seed)\n",
    "\n",
    "corr_matrix = norm_HemoPI3_model.corr()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "X_HemoPI3_model_trim = norm_HemoPI3_model.drop(norm_HemoPI3_model[to_drop], axis=1)\n",
    "X_HemoPI3_val_trim = norm_HemoPI3_validation.drop(norm_HemoPI3_validation[to_drop], axis=1)\n",
    "\n",
    "print(model3_hpi3.fit(X_HemoPI3_model_trim, y_HemoPI3_model))\n",
    "print(X_HemoPI3_model_trim.shape, X_HemoPI3_val_trim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./Models/model3_hpi3.pkl', 'wb') as f:\n",
    "    pickle.dump(model3_hpi3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save model set results into dataframe\n",
    "class_df = pd.DataFrame(model3_hpi3.predict(X_HemoPI3_model_trim))\n",
    "probs_df = pd.DataFrame(model3_hpi3.predict_proba(X_HemoPI3_model_trim))\n",
    "\n",
    "model3_hpi3_df = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model3_hpi3_df.index = X_HemoPI3_model.index\n",
    "model3_hpi3_df.columns = ['model3_class_preds', 'model3_probability_0', 'model3_probability_1']\n",
    "\n",
    "#Save validation set results into dataframe\n",
    "class_df2 = pd.DataFrame(model3_hpi3.predict(X_HemoPI3_val_trim))\n",
    "probs_df2 = pd.DataFrame(model3_hpi3.predict_proba(X_HemoPI3_val_trim))\n",
    "\n",
    "model3_hpi3_df2 = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model3_hpi3_df2.index = X_HemoPI3_validation.index\n",
    "model3_hpi3_df2.columns = ['model3_class_preds', 'model3_probability_0', 'model3_probability_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1_class_preds</th>\n",
       "      <th>model1_probability_0</th>\n",
       "      <th>model1_probability_1</th>\n",
       "      <th>model2_class_preds</th>\n",
       "      <th>model2_probability_0</th>\n",
       "      <th>model2_probability_1</th>\n",
       "      <th>model3_class_preds</th>\n",
       "      <th>model3_probability_0</th>\n",
       "      <th>model3_probability_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>peptide_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.994255</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990837</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.486335</td>\n",
       "      <td>0.513665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.071282</td>\n",
       "      <td>0.928718</td>\n",
       "      <td>1</td>\n",
       "      <td>0.193164</td>\n",
       "      <td>0.806836</td>\n",
       "      <td>1</td>\n",
       "      <td>0.151618</td>\n",
       "      <td>0.848382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986103</td>\n",
       "      <td>0.013897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.967855</td>\n",
       "      <td>0.032145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.898059</td>\n",
       "      <td>0.101941</td>\n",
       "      <td>1</td>\n",
       "      <td>0.295901</td>\n",
       "      <td>0.704099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.908693</td>\n",
       "      <td>0.091307</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829962</td>\n",
       "      <td>0.170038</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086612</td>\n",
       "      <td>0.913388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.996892</td>\n",
       "      <td>0.003108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979857</td>\n",
       "      <td>0.020143</td>\n",
       "      <td>1</td>\n",
       "      <td>0.488138</td>\n",
       "      <td>0.511862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.966782</td>\n",
       "      <td>0.033218</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916809</td>\n",
       "      <td>0.083191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.809808</td>\n",
       "      <td>0.190192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.995089</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985882</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>0</td>\n",
       "      <td>0.820404</td>\n",
       "      <td>0.179596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998971</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995857</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.881563</td>\n",
       "      <td>0.118437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.830049</td>\n",
       "      <td>0.169951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734740</td>\n",
       "      <td>0.265260</td>\n",
       "      <td>1</td>\n",
       "      <td>0.372562</td>\n",
       "      <td>0.627438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.538913</td>\n",
       "      <td>0.461087</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624676</td>\n",
       "      <td>0.375324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326006</td>\n",
       "      <td>0.673994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998793</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917379</td>\n",
       "      <td>0.082621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957397</td>\n",
       "      <td>0.042603</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210904</td>\n",
       "      <td>0.789096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.995948</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985014</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932273</td>\n",
       "      <td>0.067727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.969838</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965388</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>0</td>\n",
       "      <td>0.731320</td>\n",
       "      <td>0.268680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.290697</td>\n",
       "      <td>0.709303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.816889</td>\n",
       "      <td>0.183111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110133</td>\n",
       "      <td>0.889867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.269063</td>\n",
       "      <td>0.730937</td>\n",
       "      <td>0</td>\n",
       "      <td>0.591871</td>\n",
       "      <td>0.408129</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088218</td>\n",
       "      <td>0.911782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.490289</td>\n",
       "      <td>0.509711</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943062</td>\n",
       "      <td>0.056938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079338</td>\n",
       "      <td>0.920662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.639348</td>\n",
       "      <td>0.360652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.570148</td>\n",
       "      <td>0.429852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098242</td>\n",
       "      <td>0.901758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.896204</td>\n",
       "      <td>0.103796</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969337</td>\n",
       "      <td>0.030663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.253289</td>\n",
       "      <td>0.746711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991973</td>\n",
       "      <td>0.008027</td>\n",
       "      <td>0</td>\n",
       "      <td>0.972254</td>\n",
       "      <td>0.027746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727956</td>\n",
       "      <td>0.272044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.792489</td>\n",
       "      <td>0.207511</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695781</td>\n",
       "      <td>0.304219</td>\n",
       "      <td>0</td>\n",
       "      <td>0.657882</td>\n",
       "      <td>0.342118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.688804</td>\n",
       "      <td>0.311196</td>\n",
       "      <td>1</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624013</td>\n",
       "      <td>0.375987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.326583</td>\n",
       "      <td>0.673417</td>\n",
       "      <td>0</td>\n",
       "      <td>0.622455</td>\n",
       "      <td>0.377545</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046360</td>\n",
       "      <td>0.953640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.834425</td>\n",
       "      <td>0.165575</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>0</td>\n",
       "      <td>0.934467</td>\n",
       "      <td>0.065533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.119486</td>\n",
       "      <td>0.880514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460681</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858341</td>\n",
       "      <td>0.141659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.742224</td>\n",
       "      <td>0.257776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899439</td>\n",
       "      <td>0.100561</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062437</td>\n",
       "      <td>0.937563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.900976</td>\n",
       "      <td>0.099024</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959208</td>\n",
       "      <td>0.040792</td>\n",
       "      <td>1</td>\n",
       "      <td>0.442216</td>\n",
       "      <td>0.557784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.648850</td>\n",
       "      <td>0.351150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736779</td>\n",
       "      <td>0.263221</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174157</td>\n",
       "      <td>0.825843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_30</th>\n",
       "      <td>1</td>\n",
       "      <td>0.145206</td>\n",
       "      <td>0.854794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.303386</td>\n",
       "      <td>0.696614</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043767</td>\n",
       "      <td>0.956233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_119</th>\n",
       "      <td>0</td>\n",
       "      <td>0.671340</td>\n",
       "      <td>0.328660</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227841</td>\n",
       "      <td>0.772159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527742</td>\n",
       "      <td>0.472258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_120</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998386</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0</td>\n",
       "      <td>0.946235</td>\n",
       "      <td>0.053765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960794</td>\n",
       "      <td>0.039206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_121</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999208</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956225</td>\n",
       "      <td>0.043775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_122</th>\n",
       "      <td>1</td>\n",
       "      <td>0.062931</td>\n",
       "      <td>0.937069</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066166</td>\n",
       "      <td>0.933834</td>\n",
       "      <td>1</td>\n",
       "      <td>0.143810</td>\n",
       "      <td>0.856190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_123</th>\n",
       "      <td>0</td>\n",
       "      <td>0.969844</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.958184</td>\n",
       "      <td>0.041816</td>\n",
       "      <td>0</td>\n",
       "      <td>0.978317</td>\n",
       "      <td>0.021683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_124</th>\n",
       "      <td>1</td>\n",
       "      <td>0.470710</td>\n",
       "      <td>0.529290</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533777</td>\n",
       "      <td>0.466223</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545850</td>\n",
       "      <td>0.454150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_125</th>\n",
       "      <td>0</td>\n",
       "      <td>0.946089</td>\n",
       "      <td>0.053911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923806</td>\n",
       "      <td>0.076194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759491</td>\n",
       "      <td>0.240509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_126</th>\n",
       "      <td>1</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>0.979122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433398</td>\n",
       "      <td>0.566602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_127</th>\n",
       "      <td>1</td>\n",
       "      <td>0.357578</td>\n",
       "      <td>0.642422</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858093</td>\n",
       "      <td>0.141907</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048406</td>\n",
       "      <td>0.951594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_128</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998088</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992945</td>\n",
       "      <td>0.007055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_129</th>\n",
       "      <td>0</td>\n",
       "      <td>0.993018</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990420</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955106</td>\n",
       "      <td>0.044894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_130</th>\n",
       "      <td>0</td>\n",
       "      <td>0.955079</td>\n",
       "      <td>0.044921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.785774</td>\n",
       "      <td>0.214226</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441091</td>\n",
       "      <td>0.558909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_131</th>\n",
       "      <td>1</td>\n",
       "      <td>0.085215</td>\n",
       "      <td>0.914785</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115133</td>\n",
       "      <td>0.884867</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358853</td>\n",
       "      <td>0.641147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_132</th>\n",
       "      <td>0</td>\n",
       "      <td>0.719407</td>\n",
       "      <td>0.280593</td>\n",
       "      <td>0</td>\n",
       "      <td>0.959104</td>\n",
       "      <td>0.040896</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948833</td>\n",
       "      <td>0.051167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_133</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0.996292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.966285</td>\n",
       "      <td>1</td>\n",
       "      <td>0.062930</td>\n",
       "      <td>0.937070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_134</th>\n",
       "      <td>0</td>\n",
       "      <td>0.979983</td>\n",
       "      <td>0.020017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.782573</td>\n",
       "      <td>0.217427</td>\n",
       "      <td>0</td>\n",
       "      <td>0.579188</td>\n",
       "      <td>0.420812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_135</th>\n",
       "      <td>0</td>\n",
       "      <td>0.749587</td>\n",
       "      <td>0.250413</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687840</td>\n",
       "      <td>0.312160</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355179</td>\n",
       "      <td>0.644821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_136</th>\n",
       "      <td>0</td>\n",
       "      <td>0.871401</td>\n",
       "      <td>0.128599</td>\n",
       "      <td>0</td>\n",
       "      <td>0.763016</td>\n",
       "      <td>0.236984</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700339</td>\n",
       "      <td>0.299661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_137</th>\n",
       "      <td>0</td>\n",
       "      <td>0.692916</td>\n",
       "      <td>0.307084</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341878</td>\n",
       "      <td>0.658122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.554129</td>\n",
       "      <td>0.445871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_138</th>\n",
       "      <td>0</td>\n",
       "      <td>0.867723</td>\n",
       "      <td>0.132277</td>\n",
       "      <td>0</td>\n",
       "      <td>0.873337</td>\n",
       "      <td>0.126663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740976</td>\n",
       "      <td>0.259024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_139</th>\n",
       "      <td>0</td>\n",
       "      <td>0.751948</td>\n",
       "      <td>0.248052</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402236</td>\n",
       "      <td>0.597764</td>\n",
       "      <td>1</td>\n",
       "      <td>0.304687</td>\n",
       "      <td>0.695313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_140</th>\n",
       "      <td>0</td>\n",
       "      <td>0.904065</td>\n",
       "      <td>0.095935</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144557</td>\n",
       "      <td>0.855443</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609712</td>\n",
       "      <td>0.390288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_141</th>\n",
       "      <td>1</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.992086</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.996254</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.992655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_142</th>\n",
       "      <td>0</td>\n",
       "      <td>0.988194</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>0</td>\n",
       "      <td>0.756823</td>\n",
       "      <td>0.243177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542486</td>\n",
       "      <td>0.457514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_143</th>\n",
       "      <td>0</td>\n",
       "      <td>0.935189</td>\n",
       "      <td>0.064811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974633</td>\n",
       "      <td>0.025367</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909343</td>\n",
       "      <td>0.090657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_144</th>\n",
       "      <td>1</td>\n",
       "      <td>0.143320</td>\n",
       "      <td>0.856680</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340385</td>\n",
       "      <td>0.659615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.632259</td>\n",
       "      <td>0.367741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_145</th>\n",
       "      <td>0</td>\n",
       "      <td>0.763370</td>\n",
       "      <td>0.236630</td>\n",
       "      <td>0</td>\n",
       "      <td>0.929403</td>\n",
       "      <td>0.070597</td>\n",
       "      <td>0</td>\n",
       "      <td>0.796413</td>\n",
       "      <td>0.203587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_146</th>\n",
       "      <td>0</td>\n",
       "      <td>0.994947</td>\n",
       "      <td>0.005053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983336</td>\n",
       "      <td>0.016664</td>\n",
       "      <td>0</td>\n",
       "      <td>0.963110</td>\n",
       "      <td>0.036890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_147</th>\n",
       "      <td>1</td>\n",
       "      <td>0.358727</td>\n",
       "      <td>0.641273</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190652</td>\n",
       "      <td>0.809348</td>\n",
       "      <td>0</td>\n",
       "      <td>0.827192</td>\n",
       "      <td>0.172808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peptide_148</th>\n",
       "      <td>0</td>\n",
       "      <td>0.802009</td>\n",
       "      <td>0.197991</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508462</td>\n",
       "      <td>0.491538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519933</td>\n",
       "      <td>0.480067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             model1_class_preds  model1_probability_0  model1_probability_1  \\\n",
       "# ID                                                                          \n",
       "peptide_1                     0              0.994255              0.005745   \n",
       "peptide_2                     1              0.071282              0.928718   \n",
       "peptide_3                     0              0.999915              0.000085   \n",
       "peptide_4                     0              0.967855              0.032145   \n",
       "peptide_5                     0              0.908693              0.091307   \n",
       "peptide_6                     0              0.996892              0.003108   \n",
       "peptide_7                     0              0.966782              0.033218   \n",
       "peptide_8                     0              0.995089              0.004911   \n",
       "peptide_9                     0              0.998971              0.001029   \n",
       "peptide_10                    0              0.830049              0.169951   \n",
       "peptide_11                    0              0.538913              0.461087   \n",
       "peptide_12                    0              0.999411              0.000589   \n",
       "peptide_13                    0              0.938272              0.061728   \n",
       "peptide_14                    0              0.995948              0.004052   \n",
       "peptide_15                    0              0.969838              0.030162   \n",
       "peptide_16                    1              0.290697              0.709303   \n",
       "peptide_17                    1              0.269063              0.730937   \n",
       "peptide_18                    1              0.490289              0.509711   \n",
       "peptide_19                    0              0.639348              0.360652   \n",
       "peptide_20                    0              0.896204              0.103796   \n",
       "peptide_21                    0              0.991973              0.008027   \n",
       "peptide_22                    0              0.792489              0.207511   \n",
       "peptide_23                    0              0.688804              0.311196   \n",
       "peptide_24                    1              0.326583              0.673417   \n",
       "peptide_25                    0              0.834425              0.165575   \n",
       "peptide_26                    1              0.119486              0.880514   \n",
       "peptide_27                    0              0.742224              0.257776   \n",
       "peptide_28                    0              0.900976              0.099024   \n",
       "peptide_29                    0              0.648850              0.351150   \n",
       "peptide_30                    1              0.145206              0.854794   \n",
       "...                         ...                   ...                   ...   \n",
       "peptide_119                   0              0.671340              0.328660   \n",
       "peptide_120                   0              0.998386              0.001614   \n",
       "peptide_121                   0              0.999208              0.000792   \n",
       "peptide_122                   1              0.062931              0.937069   \n",
       "peptide_123                   0              0.969844              0.030156   \n",
       "peptide_124                   1              0.470710              0.529290   \n",
       "peptide_125                   0              0.946089              0.053911   \n",
       "peptide_126                   1              0.300000              0.700000   \n",
       "peptide_127                   1              0.357578              0.642422   \n",
       "peptide_128                   0              0.998088              0.001912   \n",
       "peptide_129                   0              0.993018              0.006982   \n",
       "peptide_130                   0              0.955079              0.044921   \n",
       "peptide_131                   1              0.085215              0.914785   \n",
       "peptide_132                   0              0.719407              0.280593   \n",
       "peptide_133                   1              0.003708              0.996292   \n",
       "peptide_134                   0              0.979983              0.020017   \n",
       "peptide_135                   0              0.749587              0.250413   \n",
       "peptide_136                   0              0.871401              0.128599   \n",
       "peptide_137                   0              0.692916              0.307084   \n",
       "peptide_138                   0              0.867723              0.132277   \n",
       "peptide_139                   0              0.751948              0.248052   \n",
       "peptide_140                   0              0.904065              0.095935   \n",
       "peptide_141                   1              0.007914              0.992086   \n",
       "peptide_142                   0              0.988194              0.011806   \n",
       "peptide_143                   0              0.935189              0.064811   \n",
       "peptide_144                   1              0.143320              0.856680   \n",
       "peptide_145                   0              0.763370              0.236630   \n",
       "peptide_146                   0              0.994947              0.005053   \n",
       "peptide_147                   1              0.358727              0.641273   \n",
       "peptide_148                   0              0.802009              0.197991   \n",
       "\n",
       "             model2_class_preds  model2_probability_0  model2_probability_1  \\\n",
       "# ID                                                                          \n",
       "peptide_1                     0              0.990837              0.009163   \n",
       "peptide_2                     1              0.193164              0.806836   \n",
       "peptide_3                     0              0.999435              0.000565   \n",
       "peptide_4                     0              0.898059              0.101941   \n",
       "peptide_5                     0              0.829962              0.170038   \n",
       "peptide_6                     0              0.979857              0.020143   \n",
       "peptide_7                     0              0.916809              0.083191   \n",
       "peptide_8                     0              0.985882              0.014118   \n",
       "peptide_9                     0              0.995857              0.004143   \n",
       "peptide_10                    0              0.734740              0.265260   \n",
       "peptide_11                    0              0.624676              0.375324   \n",
       "peptide_12                    0              0.998793              0.001207   \n",
       "peptide_13                    0              0.957397              0.042603   \n",
       "peptide_14                    0              0.985014              0.014986   \n",
       "peptide_15                    0              0.965388              0.034612   \n",
       "peptide_16                    0              0.816889              0.183111   \n",
       "peptide_17                    0              0.591871              0.408129   \n",
       "peptide_18                    0              0.943062              0.056938   \n",
       "peptide_19                    0              0.570148              0.429852   \n",
       "peptide_20                    0              0.969337              0.030663   \n",
       "peptide_21                    0              0.972254              0.027746   \n",
       "peptide_22                    0              0.695781              0.304219   \n",
       "peptide_23                    1              0.330000              0.670000   \n",
       "peptide_24                    0              0.622455              0.377545   \n",
       "peptide_25                    0              0.913295              0.086705   \n",
       "peptide_26                    1              0.460681              0.539319   \n",
       "peptide_27                    0              0.899439              0.100561   \n",
       "peptide_28                    0              0.959208              0.040792   \n",
       "peptide_29                    0              0.736779              0.263221   \n",
       "peptide_30                    1              0.303386              0.696614   \n",
       "...                         ...                   ...                   ...   \n",
       "peptide_119                   1              0.227841              0.772159   \n",
       "peptide_120                   0              0.946235              0.053765   \n",
       "peptide_121                   0              0.999436              0.000564   \n",
       "peptide_122                   1              0.066166              0.933834   \n",
       "peptide_123                   0              0.958184              0.041816   \n",
       "peptide_124                   0              0.533777              0.466223   \n",
       "peptide_125                   0              0.923806              0.076194   \n",
       "peptide_126                   1              0.020878              0.979122   \n",
       "peptide_127                   0              0.858093              0.141907   \n",
       "peptide_128                   0              0.986842              0.013158   \n",
       "peptide_129                   0              0.990420              0.009580   \n",
       "peptide_130                   0              0.785774              0.214226   \n",
       "peptide_131                   1              0.115133              0.884867   \n",
       "peptide_132                   0              0.959104              0.040896   \n",
       "peptide_133                   1              0.033715              0.966285   \n",
       "peptide_134                   0              0.782573              0.217427   \n",
       "peptide_135                   0              0.687840              0.312160   \n",
       "peptide_136                   0              0.763016              0.236984   \n",
       "peptide_137                   1              0.341878              0.658122   \n",
       "peptide_138                   0              0.873337              0.126663   \n",
       "peptide_139                   1              0.402236              0.597764   \n",
       "peptide_140                   1              0.144557              0.855443   \n",
       "peptide_141                   1              0.003746              0.996254   \n",
       "peptide_142                   0              0.756823              0.243177   \n",
       "peptide_143                   0              0.974633              0.025367   \n",
       "peptide_144                   1              0.340385              0.659615   \n",
       "peptide_145                   0              0.929403              0.070597   \n",
       "peptide_146                   0              0.983336              0.016664   \n",
       "peptide_147                   1              0.190652              0.809348   \n",
       "peptide_148                   0              0.508462              0.491538   \n",
       "\n",
       "             model3_class_preds  model3_probability_0  model3_probability_1  \n",
       "# ID                                                                         \n",
       "peptide_1                     1              0.486335              0.513665  \n",
       "peptide_2                     1              0.151618              0.848382  \n",
       "peptide_3                     0              0.986103              0.013897  \n",
       "peptide_4                     1              0.295901              0.704099  \n",
       "peptide_5                     1              0.086612              0.913388  \n",
       "peptide_6                     1              0.488138              0.511862  \n",
       "peptide_7                     0              0.809808              0.190192  \n",
       "peptide_8                     0              0.820404              0.179596  \n",
       "peptide_9                     0              0.881563              0.118437  \n",
       "peptide_10                    1              0.372562              0.627438  \n",
       "peptide_11                    1              0.326006              0.673994  \n",
       "peptide_12                    0              0.917379              0.082621  \n",
       "peptide_13                    1              0.210904              0.789096  \n",
       "peptide_14                    0              0.932273              0.067727  \n",
       "peptide_15                    0              0.731320              0.268680  \n",
       "peptide_16                    1              0.110133              0.889867  \n",
       "peptide_17                    1              0.088218              0.911782  \n",
       "peptide_18                    1              0.079338              0.920662  \n",
       "peptide_19                    1              0.098242              0.901758  \n",
       "peptide_20                    1              0.253289              0.746711  \n",
       "peptide_21                    0              0.727956              0.272044  \n",
       "peptide_22                    0              0.657882              0.342118  \n",
       "peptide_23                    0              0.624013              0.375987  \n",
       "peptide_24                    1              0.046360              0.953640  \n",
       "peptide_25                    0              0.934467              0.065533  \n",
       "peptide_26                    0              0.858341              0.141659  \n",
       "peptide_27                    1              0.062437              0.937563  \n",
       "peptide_28                    1              0.442216              0.557784  \n",
       "peptide_29                    1              0.174157              0.825843  \n",
       "peptide_30                    1              0.043767              0.956233  \n",
       "...                         ...                   ...                   ...  \n",
       "peptide_119                   0              0.527742              0.472258  \n",
       "peptide_120                   0              0.960794              0.039206  \n",
       "peptide_121                   0              0.956225              0.043775  \n",
       "peptide_122                   1              0.143810              0.856190  \n",
       "peptide_123                   0              0.978317              0.021683  \n",
       "peptide_124                   0              0.545850              0.454150  \n",
       "peptide_125                   0              0.759491              0.240509  \n",
       "peptide_126                   1              0.433398              0.566602  \n",
       "peptide_127                   1              0.048406              0.951594  \n",
       "peptide_128                   0              0.992945              0.007055  \n",
       "peptide_129                   0              0.955106              0.044894  \n",
       "peptide_130                   1              0.441091              0.558909  \n",
       "peptide_131                   1              0.358853              0.641147  \n",
       "peptide_132                   0              0.948833              0.051167  \n",
       "peptide_133                   1              0.062930              0.937070  \n",
       "peptide_134                   0              0.579188              0.420812  \n",
       "peptide_135                   1              0.355179              0.644821  \n",
       "peptide_136                   0              0.700339              0.299661  \n",
       "peptide_137                   0              0.554129              0.445871  \n",
       "peptide_138                   0              0.740976              0.259024  \n",
       "peptide_139                   1              0.304687              0.695313  \n",
       "peptide_140                   0              0.609712              0.390288  \n",
       "peptide_141                   1              0.007345              0.992655  \n",
       "peptide_142                   0              0.542486              0.457514  \n",
       "peptide_143                   0              0.909343              0.090657  \n",
       "peptide_144                   0              0.632259              0.367741  \n",
       "peptide_145                   0              0.796413              0.203587  \n",
       "peptide_146                   0              0.963110              0.036890  \n",
       "peptide_147                   0              0.827192              0.172808  \n",
       "peptide_148                   0              0.519933              0.480067  \n",
       "\n",
       "[325 rows x 9 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge model dataframes\n",
    "models_hpi3 = [model1_hpi3_df, model2_hpi3_df, model3_hpi3_df]\n",
    "\n",
    "results_models_hpi3 = pd.concat(models_hpi3, axis=1, join='inner')\n",
    "results_models_hpi3.index = model1_hpi3_df.index\n",
    "results_models_hpi3\n",
    "\n",
    "# Merge validation dataframes\n",
    "validations_hpi3 = [model1_hpi3_df2, model2_hpi3_df2, model3_hpi3_df2]\n",
    "\n",
    "results_validations_hpi3 = pd.concat(validations_hpi3, axis=1, join='inner')\n",
    "results_validations_hpi3.index = model1_hpi3_df2.index\n",
    "results_validations_hpi3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create consensus columns\n",
    "results_models_hpi3['consensus_class_preds'] = results_models_hpi3[['model1_class_preds', 'model2_class_preds', 'model3_class_preds']].mean(axis=1).astype(int)\n",
    "results_models_hpi3['consensus_probability_0'] = results_models_hpi3[['model1_probability_0', 'model2_probability_0', 'model3_probability_0']].mean(axis=1)\n",
    "results_models_hpi3['consensus_probability_1'] = results_models_hpi3[['model1_probability_1', 'model2_probability_1', 'model3_probability_1']].mean(axis=1)\n",
    "\n",
    "results_validations_hpi3['consensus_class_preds'] = results_validations_hpi3[['model1_class_preds', 'model2_class_preds', 'model3_class_preds']].mean(axis=1).astype(int)\n",
    "results_validations_hpi3['consensus_probability_0'] = results_validations_hpi3[['model1_probability_0', 'model2_probability_0', 'model3_probability_0']].mean(axis=1)\n",
    "results_validations_hpi3['consensus_probability_1'] = results_validations_hpi3[['model1_probability_1', 'model2_probability_1', 'model3_probability_1']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_models_hpi3.to_csv('./Results/predictions_models_HemoPI3.csv')\n",
    "results_validations_hpi3.to_csv('./Results/predictions_validations_HemoPI3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Importances for top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'Model 2 HemoPI-1'\n",
    "importances = model2_hpi1.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [X_HemoPI1_model.columns[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Feature Importances (Model 1.2)\")\n",
    "plt.bar(range(X_HemoPI1_model_trim.shape[1]), importances[indices])\n",
    "plt.xticks(range(X_HemoPI1_model_trim.shape[1]), names, rotation=90)\n",
    "plt.ylim(0, 0.15)\n",
    "plt.savefig(path.join(figpath, \"Feature Importances (Model 1.2).pdf\"))\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'Model 3 HemoPI-1'\n",
    "importances = model3_hpi1.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [X_HemoPI1_model.columns[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Feature Importances (Model 1.3)\")\n",
    "plt.bar(range(X_HemoPI1_model.shape[1]), importances[indices])\n",
    "plt.xticks(range(X_HemoPI1_model.shape[1]), names, rotation=90)\n",
    "plt.ylim(0, 0.15)\n",
    "plt.savefig(path.join(figpath, \"Feature Importances (Model 1.3).pdf\"))\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'Model 1 HemoPI-2'\n",
    "importances = model1_hpi2.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [X_HemoPI2_model.columns[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Feature Importances (Model 2.1)\")\n",
    "plt.bar(range(X_HemoPI2_model.shape[1]), importances[indices])\n",
    "plt.xticks(range(X_HemoPI2_model.shape[1]), names, rotation=90)\n",
    "plt.ylim(0, 0.15)\n",
    "plt.savefig(path.join(figpath, \"Feature Importances (Model 2.1).pdf\"))\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'Model 2 HemoPI-2'\n",
    "importances = model2_hpi2.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [X_HemoPI2_model.columns[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Feature Importances (Model 2.2)\")\n",
    "plt.bar(range(X_HemoPI2_model_RFE.shape[1]), importances[indices])\n",
    "plt.xticks(range(X_HemoPI2_model_RFE.shape[1]), names, rotation=90)\n",
    "plt.ylim(0, 0.15)\n",
    "plt.savefig(path.join(figpath, \"Feature Importances (Model 2.2).pdf\"))\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'Model 3 HemoPI-2'\n",
    "importances = model3_hpi2.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [X_HemoPI2_model.columns[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Feature Importances (Model 2.3)\")\n",
    "plt.bar(range(X_HemoPI2_model.shape[1]), importances[indices])\n",
    "plt.xticks(range(X_HemoPI2_model.shape[1]), names, rotation=90)\n",
    "plt.ylim(0, 0.15)\n",
    "plt.savefig(path.join(figpath, \"Feature Importances (Model 2.3).pdf\"))\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'Model 1 HemoPI-3'\n",
    "importances = model1_hpi3.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [X_HemoPI3_model.columns[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Feature Importances (Model 3.1)\")\n",
    "plt.bar(range(X_HemoPI3_model.shape[1]), importances[indices])\n",
    "plt.xticks(range(X_HemoPI3_model.shape[1]), names, rotation=90)\n",
    "plt.ylim(0, 0.15)\n",
    "plt.savefig(path.join(figpath, \"Feature Importances (Model 3.1).pdf\"))\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'Model 2 HemoPI-3'\n",
    "importances = model2_hpi3.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [X_HemoPI3_model.columns[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Feature Importances (Model 3.2)\")\n",
    "plt.bar(range(X_HemoPI3_model_RFE.shape[1]), importances[indices])\n",
    "plt.xticks(range(X_HemoPI3_model_RFE.shape[1]), names, rotation=90)\n",
    "plt.ylim(0, 0.15)\n",
    "plt.savefig(path.join(figpath, \"Feature Importances (Model 3.2).pdf\"))\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'Model 3 HemoPI-3'\n",
    "importances = model3_hpi3.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [X_HemoPI3_model.columns[i] for i in indices]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Feature Importances (Model 3.3)\")\n",
    "plt.bar(range(X_HemoPI3_model_trim.shape[1]), importances[indices])\n",
    "plt.xticks(range(X_HemoPI3_model_trim.shape[1]), names, rotation=90)\n",
    "plt.ylim(0, 0.15)\n",
    "plt.savefig(path.join(figpath, \"Feature Importances (Model 3.3).pdf\"))\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions on total APD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load test dataset\n",
    "pepdesc_totalAPD = pd.read_csv('./Descriptors/pep_descriptors_totalAPD.csv', index_col=0)\n",
    "globdesc_totalAPD = pd.read_csv('./Descriptors/global_descriptors_totalAPD.csv', index_col=0)\n",
    "total_APD = pepdesc_totalAPD.join(globdesc_totalAPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3081, 58)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_APD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3081, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicated columns\n",
    "cleaned_total_APD = total_APD.drop(['Sequence',' Sequence'], axis=1)\n",
    "cleaned_total_APD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_total_APD.to_csv('./Descriptors/properties_totalAPD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize test dataset based on model dataset\n",
    "def normalize(df, df2):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df2[feature_name].max()\n",
    "        min_value = df2[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_totalAPD_hpi1 = normalize(cleaned_total_APD, cleaned_HemoPI1_model)\n",
    "X_totalAPD_hpi2 = normalize(cleaned_total_APD, cleaned_HemoPI2_model)\n",
    "X_totalAPD_hpi3 = normalize(cleaned_total_APD, cleaned_HemoPI3_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3081, 26)\n",
      "(3081, 18)\n",
      "(3081, 27)\n",
      "(3081, 15)\n",
      "(3081, 28)\n",
      "(3081, 40)\n"
     ]
    }
   ],
   "source": [
    "## Reduced total APD datasets\n",
    "## HemoPI-1 models\n",
    "\n",
    "corr_matrix1 = norm_HemoPI1_model.corr()\n",
    "upper = corr_matrix1.where(np.triu(np.ones(corr_matrix1.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "X_HemoPI1_model_trim = norm_HemoPI1_model.drop(norm_HemoPI1_model[to_drop], axis=1)\n",
    "X_totalAPD_hpi1_trim = X_totalAPD_hpi1[list(X_HemoPI1_model_trim.columns)]\n",
    "print(X_totalAPD_hpi1_trim.shape)\n",
    "\n",
    "rfecv_model = RFECV(model1_hpi1, step=1, cv=kfold)\n",
    "rfecv = rfecv_model.fit(X_HemoPI1_model, y_HemoPI1_model)\n",
    "X_HemoPI1_model_RFE = rfecv.transform(X_HemoPI1_model)\n",
    "X_totalAPD_hpi1_RFE = rfecv.transform(X_totalAPD_hpi1)\n",
    "print(X_totalAPD_hpi1_RFE.shape)\n",
    "\n",
    "## HemoPI-2 models\n",
    "\n",
    "corr_matrix2 = norm_HemoPI2_model.corr()\n",
    "upper = corr_matrix2.where(np.triu(np.ones(corr_matrix2.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "X_HemoPI2_model_trim = norm_HemoPI2_model.drop(norm_HemoPI2_model[to_drop], axis=1)\n",
    "X_totalAPD_hpi2_trim = X_totalAPD_hpi2[list(X_HemoPI2_model_trim.columns)]\n",
    "print(X_totalAPD_hpi2_trim.shape)\n",
    "\n",
    "rfecv_model = RFECV(model2_hpi2, step=1, cv=skfold)\n",
    "rfecv = rfecv_model.fit(X_HemoPI2_model, y_HemoPI2_model)\n",
    "X_HemoPI2_model_RFE = rfecv.transform(X_HemoPI2_model)\n",
    "X_totalAPD_hpi2_RFE = rfecv.transform(X_totalAPD_hpi2)\n",
    "print(X_totalAPD_hpi2_RFE.shape)\n",
    "\n",
    "## HemoPI-3 models\n",
    "\n",
    "corr_matrix3 = norm_HemoPI3_model.corr()\n",
    "upper = corr_matrix3.where(np.triu(np.ones(corr_matrix3.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "X_HemoPI3_model_trim = norm_HemoPI3_model.drop(norm_HemoPI3_model[to_drop], axis=1)\n",
    "X_totalAPD_hpi3_trim = X_totalAPD_hpi3[list(X_HemoPI3_model_trim.columns)]\n",
    "print(X_totalAPD_hpi3_trim.shape)\n",
    "\n",
    "rfecv_model = RFECV(model2_hpi3, step=1, cv=skfold)\n",
    "rfecv = rfecv_model.fit(X_HemoPI3_model, y_HemoPI3_model)\n",
    "X_HemoPI3_model_RFE = rfecv.transform(X_HemoPI3_model)\n",
    "X_totalAPD_hpi3_RFE = rfecv.transform(X_totalAPD_hpi3)\n",
    "print(X_totalAPD_hpi3_RFE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1_class_preds</th>\n",
       "      <th>model1_probability_0</th>\n",
       "      <th>model1_probability_1</th>\n",
       "      <th>model2_class_preds</th>\n",
       "      <th>model2_probability_0</th>\n",
       "      <th>model2_probability_1</th>\n",
       "      <th>model3_class_preds</th>\n",
       "      <th>model3_probability_0</th>\n",
       "      <th>model3_probability_1</th>\n",
       "      <th>consensus_class_preds</th>\n",
       "      <th>consensus_probability_0</th>\n",
       "      <th>consensus_probability_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AP00001</th>\n",
       "      <td>1</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>0.956252</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097511</td>\n",
       "      <td>0.902489</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358041</td>\n",
       "      <td>0.641959</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166433</td>\n",
       "      <td>0.833567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00002</th>\n",
       "      <td>0</td>\n",
       "      <td>0.963566</td>\n",
       "      <td>0.036434</td>\n",
       "      <td>1</td>\n",
       "      <td>0.427008</td>\n",
       "      <td>0.572992</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666258</td>\n",
       "      <td>0.333742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685611</td>\n",
       "      <td>0.314389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00003</th>\n",
       "      <td>1</td>\n",
       "      <td>0.093772</td>\n",
       "      <td>0.906228</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907247</td>\n",
       "      <td>0.092753</td>\n",
       "      <td>0</td>\n",
       "      <td>0.886021</td>\n",
       "      <td>0.113979</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629013</td>\n",
       "      <td>0.370987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00004</th>\n",
       "      <td>1</td>\n",
       "      <td>0.461297</td>\n",
       "      <td>0.538703</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481127</td>\n",
       "      <td>0.518873</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960292</td>\n",
       "      <td>0.039708</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634239</td>\n",
       "      <td>0.365761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00005</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500031</td>\n",
       "      <td>0.499969</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673249</td>\n",
       "      <td>0.326751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.847562</td>\n",
       "      <td>0.152438</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673614</td>\n",
       "      <td>0.326386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00006</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999537</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997622</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998543</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998567</td>\n",
       "      <td>0.001433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00007</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999531</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998976</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999075</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999194</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00008</th>\n",
       "      <td>1</td>\n",
       "      <td>0.244919</td>\n",
       "      <td>0.755081</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.999804</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.999495</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081873</td>\n",
       "      <td>0.918127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00009</th>\n",
       "      <td>1</td>\n",
       "      <td>0.336728</td>\n",
       "      <td>0.663272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.997980</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.987999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116916</td>\n",
       "      <td>0.883084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00010</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.995900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013449</td>\n",
       "      <td>0.986551</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006023</td>\n",
       "      <td>0.993977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00011</th>\n",
       "      <td>1</td>\n",
       "      <td>0.494182</td>\n",
       "      <td>0.505818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829636</td>\n",
       "      <td>0.170364</td>\n",
       "      <td>0</td>\n",
       "      <td>0.981536</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>0</td>\n",
       "      <td>0.768451</td>\n",
       "      <td>0.231549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00012</th>\n",
       "      <td>1</td>\n",
       "      <td>0.057286</td>\n",
       "      <td>0.942714</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310572</td>\n",
       "      <td>0.689428</td>\n",
       "      <td>1</td>\n",
       "      <td>0.224292</td>\n",
       "      <td>0.775708</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197383</td>\n",
       "      <td>0.802617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00013</th>\n",
       "      <td>1</td>\n",
       "      <td>0.046192</td>\n",
       "      <td>0.953808</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033722</td>\n",
       "      <td>0.966278</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.939900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046671</td>\n",
       "      <td>0.953329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00014</th>\n",
       "      <td>1</td>\n",
       "      <td>0.024413</td>\n",
       "      <td>0.975587</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.999050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.996242</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009707</td>\n",
       "      <td>0.990293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00015</th>\n",
       "      <td>1</td>\n",
       "      <td>0.022976</td>\n",
       "      <td>0.977024</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.998993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.995876</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.990631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00016</th>\n",
       "      <td>1</td>\n",
       "      <td>0.024831</td>\n",
       "      <td>0.975169</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.996874</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004383</td>\n",
       "      <td>0.995617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010780</td>\n",
       "      <td>0.989220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00017</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>0.978748</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.998248</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.995701</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009101</td>\n",
       "      <td>0.990899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00018</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021953</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.998793</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>0.992204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00019</th>\n",
       "      <td>1</td>\n",
       "      <td>0.030301</td>\n",
       "      <td>0.969699</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.999191</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.997765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.988885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00020</th>\n",
       "      <td>1</td>\n",
       "      <td>0.036425</td>\n",
       "      <td>0.963575</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064704</td>\n",
       "      <td>0.935296</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042117</td>\n",
       "      <td>0.957883</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047749</td>\n",
       "      <td>0.952251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00021</th>\n",
       "      <td>1</td>\n",
       "      <td>0.091004</td>\n",
       "      <td>0.908996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175768</td>\n",
       "      <td>0.824232</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153925</td>\n",
       "      <td>0.846075</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140232</td>\n",
       "      <td>0.859768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00022</th>\n",
       "      <td>1</td>\n",
       "      <td>0.104554</td>\n",
       "      <td>0.895446</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058327</td>\n",
       "      <td>0.941673</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018432</td>\n",
       "      <td>0.981568</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.939562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00023</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020926</td>\n",
       "      <td>0.979074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854049</td>\n",
       "      <td>0.145951</td>\n",
       "      <td>0</td>\n",
       "      <td>0.994496</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623157</td>\n",
       "      <td>0.376843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00024</th>\n",
       "      <td>0</td>\n",
       "      <td>0.994449</td>\n",
       "      <td>0.005551</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997927</td>\n",
       "      <td>0.002073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00025</th>\n",
       "      <td>0</td>\n",
       "      <td>0.993466</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999245</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997503</td>\n",
       "      <td>0.002497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00026</th>\n",
       "      <td>1</td>\n",
       "      <td>0.028238</td>\n",
       "      <td>0.971762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.999943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>0.990516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00027</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.999782</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.998673</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.999426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00028</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016286</td>\n",
       "      <td>0.983714</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182140</td>\n",
       "      <td>0.817860</td>\n",
       "      <td>0</td>\n",
       "      <td>0.773661</td>\n",
       "      <td>0.226339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324029</td>\n",
       "      <td>0.675971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00029</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006771</td>\n",
       "      <td>0.993229</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.999291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.996710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00030</th>\n",
       "      <td>0</td>\n",
       "      <td>0.876873</td>\n",
       "      <td>0.123127</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099741</td>\n",
       "      <td>0.900259</td>\n",
       "      <td>1</td>\n",
       "      <td>0.049478</td>\n",
       "      <td>0.950522</td>\n",
       "      <td>0</td>\n",
       "      <td>0.342031</td>\n",
       "      <td>0.657969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03052</th>\n",
       "      <td>0</td>\n",
       "      <td>0.778296</td>\n",
       "      <td>0.221704</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.997407</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.996930</td>\n",
       "      <td>0</td>\n",
       "      <td>0.261320</td>\n",
       "      <td>0.738680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03053</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>1</td>\n",
       "      <td>0.445072</td>\n",
       "      <td>0.554928</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034705</td>\n",
       "      <td>0.965295</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160069</td>\n",
       "      <td>0.839931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03054</th>\n",
       "      <td>1</td>\n",
       "      <td>0.042164</td>\n",
       "      <td>0.957836</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223548</td>\n",
       "      <td>0.776452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951503</td>\n",
       "      <td>0.048497</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405738</td>\n",
       "      <td>0.594262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03055</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>1</td>\n",
       "      <td>0.073155</td>\n",
       "      <td>0.926845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104059</td>\n",
       "      <td>0.895941</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059547</td>\n",
       "      <td>0.940453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03056</th>\n",
       "      <td>0</td>\n",
       "      <td>0.528469</td>\n",
       "      <td>0.471531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120917</td>\n",
       "      <td>0.879083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937300</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528895</td>\n",
       "      <td>0.471105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03057</th>\n",
       "      <td>0</td>\n",
       "      <td>0.539240</td>\n",
       "      <td>0.460760</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333281</td>\n",
       "      <td>0.666719</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387689</td>\n",
       "      <td>0.612311</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420070</td>\n",
       "      <td>0.579930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03058</th>\n",
       "      <td>1</td>\n",
       "      <td>0.114823</td>\n",
       "      <td>0.885177</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156035</td>\n",
       "      <td>0.843965</td>\n",
       "      <td>0</td>\n",
       "      <td>0.793203</td>\n",
       "      <td>0.206797</td>\n",
       "      <td>0</td>\n",
       "      <td>0.354687</td>\n",
       "      <td>0.645313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03059</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.993031</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.999302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.996940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03060</th>\n",
       "      <td>1</td>\n",
       "      <td>0.385643</td>\n",
       "      <td>0.614357</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923057</td>\n",
       "      <td>0.076943</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997232</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0</td>\n",
       "      <td>0.768644</td>\n",
       "      <td>0.231356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03061</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016177</td>\n",
       "      <td>0.983823</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012885</td>\n",
       "      <td>0.987115</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022324</td>\n",
       "      <td>0.977676</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017128</td>\n",
       "      <td>0.982872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03062</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.994302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.998067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03063</th>\n",
       "      <td>1</td>\n",
       "      <td>0.223730</td>\n",
       "      <td>0.776270</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481722</td>\n",
       "      <td>0.518278</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235352</td>\n",
       "      <td>0.764648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03064</th>\n",
       "      <td>1</td>\n",
       "      <td>0.065516</td>\n",
       "      <td>0.934484</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.999526</td>\n",
       "      <td>1</td>\n",
       "      <td>0.342055</td>\n",
       "      <td>0.657945</td>\n",
       "      <td>1</td>\n",
       "      <td>0.136015</td>\n",
       "      <td>0.863985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03065</th>\n",
       "      <td>1</td>\n",
       "      <td>0.044453</td>\n",
       "      <td>0.955547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.042667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.935245</td>\n",
       "      <td>0.064755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.645677</td>\n",
       "      <td>0.354323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03066</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997682</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999292</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998923</td>\n",
       "      <td>0.001077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03067</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.975776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086239</td>\n",
       "      <td>0.913761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040488</td>\n",
       "      <td>0.959512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03068</th>\n",
       "      <td>1</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.985052</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.993742</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008383</td>\n",
       "      <td>0.991617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03069</th>\n",
       "      <td>1</td>\n",
       "      <td>0.101833</td>\n",
       "      <td>0.898167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047374</td>\n",
       "      <td>0.952626</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022937</td>\n",
       "      <td>0.977063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.057381</td>\n",
       "      <td>0.942619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03070</th>\n",
       "      <td>0</td>\n",
       "      <td>0.904616</td>\n",
       "      <td>0.095384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703917</td>\n",
       "      <td>0.296083</td>\n",
       "      <td>0</td>\n",
       "      <td>0.856574</td>\n",
       "      <td>0.143426</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821702</td>\n",
       "      <td>0.178298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03071</th>\n",
       "      <td>0</td>\n",
       "      <td>0.959784</td>\n",
       "      <td>0.040216</td>\n",
       "      <td>0</td>\n",
       "      <td>0.877212</td>\n",
       "      <td>0.122788</td>\n",
       "      <td>0</td>\n",
       "      <td>0.882096</td>\n",
       "      <td>0.117904</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906364</td>\n",
       "      <td>0.093636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03072</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>0.988184</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.997090</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153151</td>\n",
       "      <td>0.846849</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055959</td>\n",
       "      <td>0.944041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03073</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>0.990583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.996185</td>\n",
       "      <td>1</td>\n",
       "      <td>0.102943</td>\n",
       "      <td>0.897057</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038725</td>\n",
       "      <td>0.961275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03074</th>\n",
       "      <td>1</td>\n",
       "      <td>0.040631</td>\n",
       "      <td>0.959369</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985991</td>\n",
       "      <td>0.014009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979656</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.668760</td>\n",
       "      <td>0.331240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03075</th>\n",
       "      <td>1</td>\n",
       "      <td>0.249130</td>\n",
       "      <td>0.750870</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970509</td>\n",
       "      <td>0.029491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993828</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.737822</td>\n",
       "      <td>0.262178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03076</th>\n",
       "      <td>0</td>\n",
       "      <td>0.832885</td>\n",
       "      <td>0.167115</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932467</td>\n",
       "      <td>0.067533</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943908</td>\n",
       "      <td>0.056092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.903087</td>\n",
       "      <td>0.096913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03077</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.999119</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.999635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03078</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.998658</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.997401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.928500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>0.974853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03079</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>0.989411</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.998955</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.996078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03080</th>\n",
       "      <td>1</td>\n",
       "      <td>0.039328</td>\n",
       "      <td>0.960672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013167</td>\n",
       "      <td>0.986833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03081</th>\n",
       "      <td>0</td>\n",
       "      <td>0.820939</td>\n",
       "      <td>0.179061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991206</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991978</td>\n",
       "      <td>0.008022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.934708</td>\n",
       "      <td>0.065292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3081 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         model1_class_preds  model1_probability_0  model1_probability_1  \\\n",
       "# ID                                                                      \n",
       "AP00001                   1              0.043748              0.956252   \n",
       "AP00002                   0              0.963566              0.036434   \n",
       "AP00003                   1              0.093772              0.906228   \n",
       "AP00004                   1              0.461297              0.538703   \n",
       "AP00005                   0              0.500031              0.499969   \n",
       "AP00006                   0              0.999537              0.000463   \n",
       "AP00007                   0              0.999531              0.000469   \n",
       "AP00008                   1              0.244919              0.755081   \n",
       "AP00009                   1              0.336728              0.663272   \n",
       "AP00010                   1              0.000520              0.999480   \n",
       "AP00011                   1              0.494182              0.505818   \n",
       "AP00012                   1              0.057286              0.942714   \n",
       "AP00013                   1              0.046192              0.953808   \n",
       "AP00014                   1              0.024413              0.975587   \n",
       "AP00015                   1              0.022976              0.977024   \n",
       "AP00016                   1              0.024831              0.975169   \n",
       "AP00017                   1              0.021252              0.978748   \n",
       "AP00018                   1              0.021953              0.978047   \n",
       "AP00019                   1              0.030301              0.969699   \n",
       "AP00020                   1              0.036425              0.963575   \n",
       "AP00021                   1              0.091004              0.908996   \n",
       "AP00022                   1              0.104554              0.895446   \n",
       "AP00023                   1              0.020926              0.979074   \n",
       "AP00024                   0              0.994449              0.005551   \n",
       "AP00025                   0              0.993466              0.006534   \n",
       "AP00026                   1              0.028238              0.971762   \n",
       "AP00027                   1              0.000177              0.999823   \n",
       "AP00028                   1              0.016286              0.983714   \n",
       "AP00029                   1              0.006771              0.993229   \n",
       "AP00030                   0              0.876873              0.123127   \n",
       "...                     ...                   ...                   ...   \n",
       "AP03052                   0              0.778296              0.221704   \n",
       "AP03053                   1              0.000428              0.999572   \n",
       "AP03054                   1              0.042164              0.957836   \n",
       "AP03055                   1              0.001427              0.998573   \n",
       "AP03056                   0              0.528469              0.471531   \n",
       "AP03057                   0              0.539240              0.460760   \n",
       "AP03058                   1              0.114823              0.885177   \n",
       "AP03059                   1              0.006969              0.993031   \n",
       "AP03060                   1              0.385643              0.614357   \n",
       "AP03061                   1              0.016177              0.983823   \n",
       "AP03062                   1              0.005698              0.994302   \n",
       "AP03063                   1              0.223730              0.776270   \n",
       "AP03064                   1              0.065516              0.934484   \n",
       "AP03065                   1              0.044453              0.955547   \n",
       "AP03066                   0              0.997682              0.002318   \n",
       "AP03067                   1              0.011000              0.989000   \n",
       "AP03068                   1              0.014948              0.985052   \n",
       "AP03069                   1              0.101833              0.898167   \n",
       "AP03070                   0              0.904616              0.095384   \n",
       "AP03071                   0              0.959784              0.040216   \n",
       "AP03072                   1              0.011816              0.988184   \n",
       "AP03073                   1              0.009417              0.990583   \n",
       "AP03074                   1              0.040631              0.959369   \n",
       "AP03075                   1              0.249130              0.750870   \n",
       "AP03076                   0              0.832885              0.167115   \n",
       "AP03077                   1              0.000881              0.999119   \n",
       "AP03078                   1              0.001342              0.998658   \n",
       "AP03079                   1              0.010589              0.989411   \n",
       "AP03080                   1              0.039328              0.960672   \n",
       "AP03081                   0              0.820939              0.179061   \n",
       "\n",
       "         model2_class_preds  model2_probability_0  model2_probability_1  \\\n",
       "# ID                                                                      \n",
       "AP00001                   1              0.097511              0.902489   \n",
       "AP00002                   1              0.427008              0.572992   \n",
       "AP00003                   0              0.907247              0.092753   \n",
       "AP00004                   1              0.481127              0.518873   \n",
       "AP00005                   0              0.673249              0.326751   \n",
       "AP00006                   0              0.997622              0.002378   \n",
       "AP00007                   0              0.998976              0.001024   \n",
       "AP00008                   1              0.000196              0.999804   \n",
       "AP00009                   1              0.002020              0.997980   \n",
       "AP00010                   1              0.004100              0.995900   \n",
       "AP00011                   0              0.829636              0.170364   \n",
       "AP00012                   1              0.310572              0.689428   \n",
       "AP00013                   1              0.033722              0.966278   \n",
       "AP00014                   1              0.000950              0.999050   \n",
       "AP00015                   1              0.001007              0.998993   \n",
       "AP00016                   1              0.003126              0.996874   \n",
       "AP00017                   1              0.001752              0.998248   \n",
       "AP00018                   1              0.000227              0.999773   \n",
       "AP00019                   1              0.000809              0.999191   \n",
       "AP00020                   1              0.064704              0.935296   \n",
       "AP00021                   1              0.175768              0.824232   \n",
       "AP00022                   1              0.058327              0.941673   \n",
       "AP00023                   0              0.854049              0.145951   \n",
       "AP00024                   0              0.999926              0.000074   \n",
       "AP00025                   0              0.999800              0.000200   \n",
       "AP00026                   1              0.000156              0.999844   \n",
       "AP00027                   1              0.000218              0.999782   \n",
       "AP00028                   1              0.182140              0.817860   \n",
       "AP00029                   1              0.002389              0.997611   \n",
       "AP00030                   1              0.099741              0.900259   \n",
       "...                     ...                   ...                   ...   \n",
       "AP03052                   1              0.002593              0.997407   \n",
       "AP03053                   1              0.445072              0.554928   \n",
       "AP03054                   1              0.223548              0.776452   \n",
       "AP03055                   1              0.073155              0.926845   \n",
       "AP03056                   1              0.120917              0.879083   \n",
       "AP03057                   1              0.333281              0.666719   \n",
       "AP03058                   1              0.156035              0.843965   \n",
       "AP03059                   1              0.000698              0.999302   \n",
       "AP03060                   0              0.923057              0.076943   \n",
       "AP03061                   1              0.012885              0.987115   \n",
       "AP03062                   1              0.000073              0.999927   \n",
       "AP03063                   1              0.000605              0.999395   \n",
       "AP03064                   1              0.000474              0.999526   \n",
       "AP03065                   0              0.957333              0.042667   \n",
       "AP03066                   0              0.999292              0.000708   \n",
       "AP03067                   1              0.024224              0.975776   \n",
       "AP03068                   1              0.003943              0.996057   \n",
       "AP03069                   1              0.047374              0.952626   \n",
       "AP03070                   0              0.703917              0.296083   \n",
       "AP03071                   0              0.877212              0.122788   \n",
       "AP03072                   1              0.002910              0.997090   \n",
       "AP03073                   1              0.003815              0.996185   \n",
       "AP03074                   0              0.985991              0.014009   \n",
       "AP03075                   0              0.970509              0.029491   \n",
       "AP03076                   0              0.932467              0.067533   \n",
       "AP03077                   1              0.000037              0.999963   \n",
       "AP03078                   1              0.002599              0.997401   \n",
       "AP03079                   1              0.001045              0.998955   \n",
       "AP03080                   1              0.000129              0.999871   \n",
       "AP03081                   0              0.991206              0.008794   \n",
       "\n",
       "         model3_class_preds  model3_probability_0  model3_probability_1  \\\n",
       "# ID                                                                      \n",
       "AP00001                   1              0.358041              0.641959   \n",
       "AP00002                   0              0.666258              0.333742   \n",
       "AP00003                   0              0.886021              0.113979   \n",
       "AP00004                   0              0.960292              0.039708   \n",
       "AP00005                   0              0.847562              0.152438   \n",
       "AP00006                   0              0.998543              0.001457   \n",
       "AP00007                   0              0.999075              0.000925   \n",
       "AP00008                   1              0.000505              0.999495   \n",
       "AP00009                   1              0.012001              0.987999   \n",
       "AP00010                   1              0.013449              0.986551   \n",
       "AP00011                   0              0.981536              0.018464   \n",
       "AP00012                   1              0.224292              0.775708   \n",
       "AP00013                   1              0.060100              0.939900   \n",
       "AP00014                   1              0.003758              0.996242   \n",
       "AP00015                   1              0.004124              0.995876   \n",
       "AP00016                   1              0.004383              0.995617   \n",
       "AP00017                   1              0.004299              0.995701   \n",
       "AP00018                   1              0.001207              0.998793   \n",
       "AP00019                   1              0.002235              0.997765   \n",
       "AP00020                   1              0.042117              0.957883   \n",
       "AP00021                   1              0.153925              0.846075   \n",
       "AP00022                   1              0.018432              0.981568   \n",
       "AP00023                   0              0.994496              0.005504   \n",
       "AP00024                   0              0.999407              0.000593   \n",
       "AP00025                   0              0.999245              0.000755   \n",
       "AP00026                   1              0.000057              0.999943   \n",
       "AP00027                   1              0.001327              0.998673   \n",
       "AP00028                   0              0.773661              0.226339   \n",
       "AP00029                   1              0.000709              0.999291   \n",
       "AP00030                   1              0.049478              0.950522   \n",
       "...                     ...                   ...                   ...   \n",
       "AP03052                   1              0.003070              0.996930   \n",
       "AP03053                   1              0.034705              0.965295   \n",
       "AP03054                   0              0.951503              0.048497   \n",
       "AP03055                   1              0.104059              0.895941   \n",
       "AP03056                   0              0.937300              0.062700   \n",
       "AP03057                   1              0.387689              0.612311   \n",
       "AP03058                   0              0.793203              0.206797   \n",
       "AP03059                   1              0.001514              0.998486   \n",
       "AP03060                   0              0.997232              0.002768   \n",
       "AP03061                   1              0.022324              0.977676   \n",
       "AP03062                   1              0.000028              0.999972   \n",
       "AP03063                   1              0.481722              0.518278   \n",
       "AP03064                   1              0.342055              0.657945   \n",
       "AP03065                   0              0.935245              0.064755   \n",
       "AP03066                   0              0.999795              0.000205   \n",
       "AP03067                   1              0.086239              0.913761   \n",
       "AP03068                   1              0.006258              0.993742   \n",
       "AP03069                   1              0.022937              0.977063   \n",
       "AP03070                   0              0.856574              0.143426   \n",
       "AP03071                   0              0.882096              0.117904   \n",
       "AP03072                   1              0.153151              0.846849   \n",
       "AP03073                   1              0.102943              0.897057   \n",
       "AP03074                   0              0.979656              0.020344   \n",
       "AP03075                   0              0.993828              0.006172   \n",
       "AP03076                   0              0.943908              0.056092   \n",
       "AP03077                   1              0.000177              0.999823   \n",
       "AP03078                   1              0.071500              0.928500   \n",
       "AP03079                   1              0.000132              0.999868   \n",
       "AP03080                   1              0.000043              0.999957   \n",
       "AP03081                   0              0.991978              0.008022   \n",
       "\n",
       "         consensus_class_preds  consensus_probability_0  \\\n",
       "# ID                                                      \n",
       "AP00001                      1                 0.166433   \n",
       "AP00002                      0                 0.685611   \n",
       "AP00003                      0                 0.629013   \n",
       "AP00004                      0                 0.634239   \n",
       "AP00005                      0                 0.673614   \n",
       "AP00006                      0                 0.998567   \n",
       "AP00007                      0                 0.999194   \n",
       "AP00008                      1                 0.081873   \n",
       "AP00009                      1                 0.116916   \n",
       "AP00010                      1                 0.006023   \n",
       "AP00011                      0                 0.768451   \n",
       "AP00012                      1                 0.197383   \n",
       "AP00013                      1                 0.046671   \n",
       "AP00014                      1                 0.009707   \n",
       "AP00015                      1                 0.009369   \n",
       "AP00016                      1                 0.010780   \n",
       "AP00017                      1                 0.009101   \n",
       "AP00018                      1                 0.007796   \n",
       "AP00019                      1                 0.011115   \n",
       "AP00020                      1                 0.047749   \n",
       "AP00021                      1                 0.140232   \n",
       "AP00022                      1                 0.060438   \n",
       "AP00023                      0                 0.623157   \n",
       "AP00024                      0                 0.997927   \n",
       "AP00025                      0                 0.997503   \n",
       "AP00026                      1                 0.009484   \n",
       "AP00027                      1                 0.000574   \n",
       "AP00028                      0                 0.324029   \n",
       "AP00029                      1                 0.003290   \n",
       "AP00030                      0                 0.342031   \n",
       "...                        ...                      ...   \n",
       "AP03052                      0                 0.261320   \n",
       "AP03053                      1                 0.160069   \n",
       "AP03054                      0                 0.405738   \n",
       "AP03055                      1                 0.059547   \n",
       "AP03056                      0                 0.528895   \n",
       "AP03057                      0                 0.420070   \n",
       "AP03058                      0                 0.354687   \n",
       "AP03059                      1                 0.003060   \n",
       "AP03060                      0                 0.768644   \n",
       "AP03061                      1                 0.017128   \n",
       "AP03062                      1                 0.001933   \n",
       "AP03063                      1                 0.235352   \n",
       "AP03064                      1                 0.136015   \n",
       "AP03065                      0                 0.645677   \n",
       "AP03066                      0                 0.998923   \n",
       "AP03067                      1                 0.040488   \n",
       "AP03068                      1                 0.008383   \n",
       "AP03069                      1                 0.057381   \n",
       "AP03070                      0                 0.821702   \n",
       "AP03071                      0                 0.906364   \n",
       "AP03072                      1                 0.055959   \n",
       "AP03073                      1                 0.038725   \n",
       "AP03074                      0                 0.668760   \n",
       "AP03075                      0                 0.737822   \n",
       "AP03076                      0                 0.903087   \n",
       "AP03077                      1                 0.000365   \n",
       "AP03078                      1                 0.025147   \n",
       "AP03079                      1                 0.003922   \n",
       "AP03080                      1                 0.013167   \n",
       "AP03081                      0                 0.934708   \n",
       "\n",
       "         consensus_probability_1  \n",
       "# ID                              \n",
       "AP00001                 0.833567  \n",
       "AP00002                 0.314389  \n",
       "AP00003                 0.370987  \n",
       "AP00004                 0.365761  \n",
       "AP00005                 0.326386  \n",
       "AP00006                 0.001433  \n",
       "AP00007                 0.000806  \n",
       "AP00008                 0.918127  \n",
       "AP00009                 0.883084  \n",
       "AP00010                 0.993977  \n",
       "AP00011                 0.231549  \n",
       "AP00012                 0.802617  \n",
       "AP00013                 0.953329  \n",
       "AP00014                 0.990293  \n",
       "AP00015                 0.990631  \n",
       "AP00016                 0.989220  \n",
       "AP00017                 0.990899  \n",
       "AP00018                 0.992204  \n",
       "AP00019                 0.988885  \n",
       "AP00020                 0.952251  \n",
       "AP00021                 0.859768  \n",
       "AP00022                 0.939562  \n",
       "AP00023                 0.376843  \n",
       "AP00024                 0.002073  \n",
       "AP00025                 0.002497  \n",
       "AP00026                 0.990516  \n",
       "AP00027                 0.999426  \n",
       "AP00028                 0.675971  \n",
       "AP00029                 0.996710  \n",
       "AP00030                 0.657969  \n",
       "...                          ...  \n",
       "AP03052                 0.738680  \n",
       "AP03053                 0.839931  \n",
       "AP03054                 0.594262  \n",
       "AP03055                 0.940453  \n",
       "AP03056                 0.471105  \n",
       "AP03057                 0.579930  \n",
       "AP03058                 0.645313  \n",
       "AP03059                 0.996940  \n",
       "AP03060                 0.231356  \n",
       "AP03061                 0.982872  \n",
       "AP03062                 0.998067  \n",
       "AP03063                 0.764648  \n",
       "AP03064                 0.863985  \n",
       "AP03065                 0.354323  \n",
       "AP03066                 0.001077  \n",
       "AP03067                 0.959512  \n",
       "AP03068                 0.991617  \n",
       "AP03069                 0.942619  \n",
       "AP03070                 0.178298  \n",
       "AP03071                 0.093636  \n",
       "AP03072                 0.944041  \n",
       "AP03073                 0.961275  \n",
       "AP03074                 0.331240  \n",
       "AP03075                 0.262178  \n",
       "AP03076                 0.096913  \n",
       "AP03077                 0.999635  \n",
       "AP03078                 0.974853  \n",
       "AP03079                 0.996078  \n",
       "AP03080                 0.986833  \n",
       "AP03081                 0.065292  \n",
       "\n",
       "[3081 rows x 12 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save test set results into dataframe\n",
    "# Model 1.1\n",
    "model1_hpi1.fit(X_HemoPI1_model_RFE, y_HemoPI1_model)\n",
    "class_df = pd.DataFrame(model1_hpi1.predict(X_totalAPD_hpi1_RFE))\n",
    "probs_df = pd.DataFrame(model1_hpi1.predict_proba(X_totalAPD_hpi1_RFE))\n",
    "\n",
    "model1_hpi1_apd = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model1_hpi1_apd.index = X_totalAPD_hpi1.index\n",
    "model1_hpi1_apd.columns = ['model1_class_preds', 'model1_probability_0', 'model1_probability_1']\n",
    "\n",
    "# Model 1.2\n",
    "model2_hpi1.fit(X_HemoPI1_model_trim, y_HemoPI1_model)\n",
    "class_df2 = pd.DataFrame(model2_hpi1.predict(X_totalAPD_hpi1_trim))\n",
    "probs_df2 = pd.DataFrame(model2_hpi1.predict_proba(X_totalAPD_hpi1_trim))\n",
    "\n",
    "model2_hpi1_apd = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model2_hpi1_apd.index = X_totalAPD_hpi1.index\n",
    "model2_hpi1_apd.columns = ['model2_class_preds', 'model2_probability_0', 'model2_probability_1']\n",
    "\n",
    "# Model 1.3\n",
    "model3_hpi1.fit(X_HemoPI1_model, y_HemoPI1_model)\n",
    "class_df3 = pd.DataFrame(model3_hpi1.predict(X_totalAPD_hpi1))\n",
    "probs_df3 = pd.DataFrame(model3_hpi1.predict_proba(X_totalAPD_hpi1))\n",
    "\n",
    "model3_hpi1_apd = class_df3.merge(probs_df3, how='outer', left_index=True, right_index=True)\n",
    "model3_hpi1_apd.index = X_totalAPD_hpi1.index\n",
    "model3_hpi1_apd.columns = ['model3_class_preds', 'model3_probability_0', 'model3_probability_1']\n",
    "\n",
    "# Merge model dataframes\n",
    "models_hpi1 = [model1_hpi1_apd, model2_hpi1_apd, model3_hpi1_apd]\n",
    "\n",
    "results_models_hpi1_apd = pd.concat(models_hpi1, axis=1, join='inner')\n",
    "results_models_hpi1_apd.index = model1_hpi1_apd.index\n",
    "results_models_hpi1_apd\n",
    "\n",
    "#Create consensus columns\n",
    "results_models_hpi1_apd['consensus_class_preds'] = results_models_hpi1_apd[['model1_class_preds', 'model2_class_preds', 'model3_class_preds']].mean(axis=1).astype(int)\n",
    "results_models_hpi1_apd['consensus_probability_0'] = results_models_hpi1_apd[['model1_probability_0', 'model2_probability_0', 'model3_probability_0']].mean(axis=1)\n",
    "results_models_hpi1_apd['consensus_probability_1'] = results_models_hpi1_apd[['model1_probability_1', 'model2_probability_1', 'model3_probability_1']].mean(axis=1)\n",
    "\n",
    "results_models_hpi1_apd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_models_hpi1_apd.to_csv('./Results/predictions_totalAPD_HemoPI1_topmodels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 1049, True: 2032})"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many AMPs are predicted to be haemolytic according to HemoPI-1 models?\n",
    "from collections import Counter\n",
    "\n",
    "Counter(results_models_hpi1_apd['consensus_probability_1'] > 0.5) #2188\n",
    "Counter(results_models_hpi1_apd['model1_probability_1'] > 0.5) #2386\n",
    "Counter(results_models_hpi1_apd['model2_probability_1'] > 0.5) #2152\n",
    "Counter(results_models_hpi1_apd['model3_probability_1'] > 0.5) #2032"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results showed that most AMPs are classified as hemolytic peptides (71%, 2188/3081). All 3 models agreed and in some cases they do not (36-198, 1.1-6.4%). We hypothesized that differences in results in particularly true to the outliers. Using our knowledge on sources organisms, biological activities as well as lining up the limits of our models - we are going to investigate deeper the results of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1_class_preds</th>\n",
       "      <th>model1_probability_0</th>\n",
       "      <th>model1_probability_1</th>\n",
       "      <th>model2_class_preds</th>\n",
       "      <th>model2_probability_0</th>\n",
       "      <th>model2_probability_1</th>\n",
       "      <th>model3_class_preds</th>\n",
       "      <th>model3_probability_0</th>\n",
       "      <th>model3_probability_1</th>\n",
       "      <th>consensus_class_preds</th>\n",
       "      <th>consensus_probability_0</th>\n",
       "      <th>consensus_probability_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AP00001</th>\n",
       "      <td>0</td>\n",
       "      <td>0.857053</td>\n",
       "      <td>0.142947</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575067</td>\n",
       "      <td>0.424933</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552769</td>\n",
       "      <td>0.447231</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661630</td>\n",
       "      <td>0.338370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00002</th>\n",
       "      <td>1</td>\n",
       "      <td>0.399618</td>\n",
       "      <td>0.600382</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469647</td>\n",
       "      <td>0.530353</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704230</td>\n",
       "      <td>0.295770</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524498</td>\n",
       "      <td>0.475502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00003</th>\n",
       "      <td>0</td>\n",
       "      <td>0.880166</td>\n",
       "      <td>0.119834</td>\n",
       "      <td>0</td>\n",
       "      <td>0.904689</td>\n",
       "      <td>0.095311</td>\n",
       "      <td>0</td>\n",
       "      <td>0.876661</td>\n",
       "      <td>0.123339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887172</td>\n",
       "      <td>0.112828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00004</th>\n",
       "      <td>0</td>\n",
       "      <td>0.917753</td>\n",
       "      <td>0.082247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932841</td>\n",
       "      <td>0.067159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943155</td>\n",
       "      <td>0.056845</td>\n",
       "      <td>0</td>\n",
       "      <td>0.931249</td>\n",
       "      <td>0.068751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00005</th>\n",
       "      <td>0</td>\n",
       "      <td>0.567934</td>\n",
       "      <td>0.432066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.648987</td>\n",
       "      <td>0.351013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.739267</td>\n",
       "      <td>0.260733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.652063</td>\n",
       "      <td>0.347937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00006</th>\n",
       "      <td>0</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>0.245370</td>\n",
       "      <td>1</td>\n",
       "      <td>0.408488</td>\n",
       "      <td>0.591512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.716506</td>\n",
       "      <td>0.283494</td>\n",
       "      <td>0</td>\n",
       "      <td>0.626541</td>\n",
       "      <td>0.373459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00007</th>\n",
       "      <td>1</td>\n",
       "      <td>0.496790</td>\n",
       "      <td>0.503210</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317158</td>\n",
       "      <td>0.682842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.492591</td>\n",
       "      <td>0.507409</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435513</td>\n",
       "      <td>0.564487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00008</th>\n",
       "      <td>0</td>\n",
       "      <td>0.574337</td>\n",
       "      <td>0.425663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.667192</td>\n",
       "      <td>0.332808</td>\n",
       "      <td>0</td>\n",
       "      <td>0.650120</td>\n",
       "      <td>0.349880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.630550</td>\n",
       "      <td>0.369450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00009</th>\n",
       "      <td>1</td>\n",
       "      <td>0.485306</td>\n",
       "      <td>0.514694</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661224</td>\n",
       "      <td>0.338776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.468274</td>\n",
       "      <td>0.531726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538268</td>\n",
       "      <td>0.461732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00010</th>\n",
       "      <td>0</td>\n",
       "      <td>0.720302</td>\n",
       "      <td>0.279698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879834</td>\n",
       "      <td>0.120166</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692275</td>\n",
       "      <td>0.307725</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764137</td>\n",
       "      <td>0.235863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00011</th>\n",
       "      <td>0</td>\n",
       "      <td>0.706748</td>\n",
       "      <td>0.293252</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821454</td>\n",
       "      <td>0.178546</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576159</td>\n",
       "      <td>0.423841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.701454</td>\n",
       "      <td>0.298546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00012</th>\n",
       "      <td>1</td>\n",
       "      <td>0.233994</td>\n",
       "      <td>0.766006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533399</td>\n",
       "      <td>0.466601</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325364</td>\n",
       "      <td>0.674636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364253</td>\n",
       "      <td>0.635747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00013</th>\n",
       "      <td>1</td>\n",
       "      <td>0.130996</td>\n",
       "      <td>0.869004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516568</td>\n",
       "      <td>0.483432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278350</td>\n",
       "      <td>0.721650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308638</td>\n",
       "      <td>0.691362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00014</th>\n",
       "      <td>1</td>\n",
       "      <td>0.063455</td>\n",
       "      <td>0.936545</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175849</td>\n",
       "      <td>0.824151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090782</td>\n",
       "      <td>0.909218</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110029</td>\n",
       "      <td>0.889971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00015</th>\n",
       "      <td>1</td>\n",
       "      <td>0.063290</td>\n",
       "      <td>0.936710</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>0.813363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090782</td>\n",
       "      <td>0.909218</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113570</td>\n",
       "      <td>0.886430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00016</th>\n",
       "      <td>1</td>\n",
       "      <td>0.099491</td>\n",
       "      <td>0.900509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178455</td>\n",
       "      <td>0.821545</td>\n",
       "      <td>1</td>\n",
       "      <td>0.129534</td>\n",
       "      <td>0.870466</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135826</td>\n",
       "      <td>0.864174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00017</th>\n",
       "      <td>1</td>\n",
       "      <td>0.056927</td>\n",
       "      <td>0.943073</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175849</td>\n",
       "      <td>0.824151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090782</td>\n",
       "      <td>0.909218</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107853</td>\n",
       "      <td>0.892147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00018</th>\n",
       "      <td>1</td>\n",
       "      <td>0.049326</td>\n",
       "      <td>0.950674</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147506</td>\n",
       "      <td>0.852494</td>\n",
       "      <td>1</td>\n",
       "      <td>0.068969</td>\n",
       "      <td>0.931031</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088601</td>\n",
       "      <td>0.911399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00019</th>\n",
       "      <td>1</td>\n",
       "      <td>0.239323</td>\n",
       "      <td>0.760677</td>\n",
       "      <td>1</td>\n",
       "      <td>0.242449</td>\n",
       "      <td>0.757551</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178576</td>\n",
       "      <td>0.821424</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220116</td>\n",
       "      <td>0.779884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00020</th>\n",
       "      <td>1</td>\n",
       "      <td>0.119740</td>\n",
       "      <td>0.880260</td>\n",
       "      <td>1</td>\n",
       "      <td>0.218050</td>\n",
       "      <td>0.781950</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130217</td>\n",
       "      <td>0.869783</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156002</td>\n",
       "      <td>0.843998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00021</th>\n",
       "      <td>1</td>\n",
       "      <td>0.149496</td>\n",
       "      <td>0.850504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235420</td>\n",
       "      <td>0.764580</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117406</td>\n",
       "      <td>0.882594</td>\n",
       "      <td>1</td>\n",
       "      <td>0.167441</td>\n",
       "      <td>0.832559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00022</th>\n",
       "      <td>1</td>\n",
       "      <td>0.121960</td>\n",
       "      <td>0.878040</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187701</td>\n",
       "      <td>0.812299</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119806</td>\n",
       "      <td>0.880194</td>\n",
       "      <td>1</td>\n",
       "      <td>0.143156</td>\n",
       "      <td>0.856844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00023</th>\n",
       "      <td>0</td>\n",
       "      <td>0.512234</td>\n",
       "      <td>0.487766</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852200</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.677475</td>\n",
       "      <td>0.322525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680636</td>\n",
       "      <td>0.319364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00024</th>\n",
       "      <td>0</td>\n",
       "      <td>0.981260</td>\n",
       "      <td>0.018740</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852096</td>\n",
       "      <td>0.147904</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977211</td>\n",
       "      <td>0.022789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936856</td>\n",
       "      <td>0.063144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00025</th>\n",
       "      <td>0</td>\n",
       "      <td>0.975407</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>0</td>\n",
       "      <td>0.855079</td>\n",
       "      <td>0.144921</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969686</td>\n",
       "      <td>0.030314</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933391</td>\n",
       "      <td>0.066609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00026</th>\n",
       "      <td>1</td>\n",
       "      <td>0.308948</td>\n",
       "      <td>0.691052</td>\n",
       "      <td>1</td>\n",
       "      <td>0.447266</td>\n",
       "      <td>0.552734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430802</td>\n",
       "      <td>0.569198</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395672</td>\n",
       "      <td>0.604328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00027</th>\n",
       "      <td>0</td>\n",
       "      <td>0.878292</td>\n",
       "      <td>0.121708</td>\n",
       "      <td>0</td>\n",
       "      <td>0.968717</td>\n",
       "      <td>0.031283</td>\n",
       "      <td>0</td>\n",
       "      <td>0.927131</td>\n",
       "      <td>0.072869</td>\n",
       "      <td>0</td>\n",
       "      <td>0.924713</td>\n",
       "      <td>0.075287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00028</th>\n",
       "      <td>1</td>\n",
       "      <td>0.306283</td>\n",
       "      <td>0.693717</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190406</td>\n",
       "      <td>0.809594</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137109</td>\n",
       "      <td>0.862891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211266</td>\n",
       "      <td>0.788734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00029</th>\n",
       "      <td>0</td>\n",
       "      <td>0.874520</td>\n",
       "      <td>0.125480</td>\n",
       "      <td>0</td>\n",
       "      <td>0.783572</td>\n",
       "      <td>0.216428</td>\n",
       "      <td>0</td>\n",
       "      <td>0.793759</td>\n",
       "      <td>0.206241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.182716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00030</th>\n",
       "      <td>1</td>\n",
       "      <td>0.484763</td>\n",
       "      <td>0.515237</td>\n",
       "      <td>0</td>\n",
       "      <td>0.771424</td>\n",
       "      <td>0.228576</td>\n",
       "      <td>0</td>\n",
       "      <td>0.582097</td>\n",
       "      <td>0.417903</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612761</td>\n",
       "      <td>0.387239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03052</th>\n",
       "      <td>1</td>\n",
       "      <td>0.084186</td>\n",
       "      <td>0.915814</td>\n",
       "      <td>0</td>\n",
       "      <td>0.729920</td>\n",
       "      <td>0.270080</td>\n",
       "      <td>1</td>\n",
       "      <td>0.332436</td>\n",
       "      <td>0.667564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382180</td>\n",
       "      <td>0.617820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03053</th>\n",
       "      <td>0</td>\n",
       "      <td>0.708124</td>\n",
       "      <td>0.291876</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220079</td>\n",
       "      <td>0.779921</td>\n",
       "      <td>1</td>\n",
       "      <td>0.445471</td>\n",
       "      <td>0.554529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457891</td>\n",
       "      <td>0.542109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03054</th>\n",
       "      <td>0</td>\n",
       "      <td>0.847844</td>\n",
       "      <td>0.152156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.855957</td>\n",
       "      <td>0.144043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728744</td>\n",
       "      <td>0.271256</td>\n",
       "      <td>0</td>\n",
       "      <td>0.810848</td>\n",
       "      <td>0.189152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03055</th>\n",
       "      <td>0</td>\n",
       "      <td>0.587855</td>\n",
       "      <td>0.412145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.802755</td>\n",
       "      <td>0.197245</td>\n",
       "      <td>0</td>\n",
       "      <td>0.623544</td>\n",
       "      <td>0.376456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671384</td>\n",
       "      <td>0.328616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03056</th>\n",
       "      <td>1</td>\n",
       "      <td>0.479931</td>\n",
       "      <td>0.520069</td>\n",
       "      <td>0</td>\n",
       "      <td>0.649222</td>\n",
       "      <td>0.350778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600689</td>\n",
       "      <td>0.399311</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576614</td>\n",
       "      <td>0.423386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03057</th>\n",
       "      <td>1</td>\n",
       "      <td>0.179603</td>\n",
       "      <td>0.820397</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251294</td>\n",
       "      <td>0.748706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.228350</td>\n",
       "      <td>0.771650</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219749</td>\n",
       "      <td>0.780251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03058</th>\n",
       "      <td>1</td>\n",
       "      <td>0.261648</td>\n",
       "      <td>0.738352</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620545</td>\n",
       "      <td>0.379455</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198931</td>\n",
       "      <td>0.801069</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360375</td>\n",
       "      <td>0.639625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03059</th>\n",
       "      <td>1</td>\n",
       "      <td>0.153259</td>\n",
       "      <td>0.846741</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158968</td>\n",
       "      <td>0.841032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.284511</td>\n",
       "      <td>0.715489</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198913</td>\n",
       "      <td>0.801087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03060</th>\n",
       "      <td>1</td>\n",
       "      <td>0.419772</td>\n",
       "      <td>0.580228</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211507</td>\n",
       "      <td>0.788493</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425052</td>\n",
       "      <td>0.574948</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352110</td>\n",
       "      <td>0.647890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03061</th>\n",
       "      <td>0</td>\n",
       "      <td>0.539515</td>\n",
       "      <td>0.460485</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514062</td>\n",
       "      <td>0.485938</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687205</td>\n",
       "      <td>0.312795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.580261</td>\n",
       "      <td>0.419739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03062</th>\n",
       "      <td>1</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.980947</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056970</td>\n",
       "      <td>0.943030</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043249</td>\n",
       "      <td>0.956751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039758</td>\n",
       "      <td>0.960242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03063</th>\n",
       "      <td>0</td>\n",
       "      <td>0.971125</td>\n",
       "      <td>0.028875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.966535</td>\n",
       "      <td>0.033465</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871983</td>\n",
       "      <td>0.128017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936548</td>\n",
       "      <td>0.063452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03064</th>\n",
       "      <td>0</td>\n",
       "      <td>0.905703</td>\n",
       "      <td>0.094297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.798927</td>\n",
       "      <td>0.201073</td>\n",
       "      <td>0</td>\n",
       "      <td>0.745877</td>\n",
       "      <td>0.254123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.816836</td>\n",
       "      <td>0.183164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03065</th>\n",
       "      <td>0</td>\n",
       "      <td>0.727984</td>\n",
       "      <td>0.272016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692779</td>\n",
       "      <td>0.307221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678167</td>\n",
       "      <td>0.321833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.699643</td>\n",
       "      <td>0.300357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03066</th>\n",
       "      <td>0</td>\n",
       "      <td>0.723327</td>\n",
       "      <td>0.276673</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686070</td>\n",
       "      <td>0.313930</td>\n",
       "      <td>0</td>\n",
       "      <td>0.790025</td>\n",
       "      <td>0.209975</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733141</td>\n",
       "      <td>0.266859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03067</th>\n",
       "      <td>0</td>\n",
       "      <td>0.740084</td>\n",
       "      <td>0.259916</td>\n",
       "      <td>0</td>\n",
       "      <td>0.724842</td>\n",
       "      <td>0.275158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.843229</td>\n",
       "      <td>0.156771</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769385</td>\n",
       "      <td>0.230615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03068</th>\n",
       "      <td>0</td>\n",
       "      <td>0.736819</td>\n",
       "      <td>0.263181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604903</td>\n",
       "      <td>0.395097</td>\n",
       "      <td>0</td>\n",
       "      <td>0.754065</td>\n",
       "      <td>0.245935</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.301404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03069</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581889</td>\n",
       "      <td>0.418111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.591909</td>\n",
       "      <td>0.408091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615526</td>\n",
       "      <td>0.384474</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596441</td>\n",
       "      <td>0.403559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03070</th>\n",
       "      <td>0</td>\n",
       "      <td>0.717740</td>\n",
       "      <td>0.282260</td>\n",
       "      <td>0</td>\n",
       "      <td>0.850029</td>\n",
       "      <td>0.149971</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815077</td>\n",
       "      <td>0.184923</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794282</td>\n",
       "      <td>0.205718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03071</th>\n",
       "      <td>0</td>\n",
       "      <td>0.593267</td>\n",
       "      <td>0.406733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862734</td>\n",
       "      <td>0.137266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.754629</td>\n",
       "      <td>0.245371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736877</td>\n",
       "      <td>0.263123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03072</th>\n",
       "      <td>0</td>\n",
       "      <td>0.612568</td>\n",
       "      <td>0.387432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.890099</td>\n",
       "      <td>0.109901</td>\n",
       "      <td>0</td>\n",
       "      <td>0.551739</td>\n",
       "      <td>0.448261</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684802</td>\n",
       "      <td>0.315198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03073</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066891</td>\n",
       "      <td>0.933109</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125429</td>\n",
       "      <td>0.874571</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088491</td>\n",
       "      <td>0.911509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093604</td>\n",
       "      <td>0.906396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03074</th>\n",
       "      <td>1</td>\n",
       "      <td>0.355690</td>\n",
       "      <td>0.644310</td>\n",
       "      <td>0</td>\n",
       "      <td>0.621350</td>\n",
       "      <td>0.378650</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495985</td>\n",
       "      <td>0.504015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.491008</td>\n",
       "      <td>0.508992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03075</th>\n",
       "      <td>1</td>\n",
       "      <td>0.240575</td>\n",
       "      <td>0.759425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.816995</td>\n",
       "      <td>0.183005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272852</td>\n",
       "      <td>0.727148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.443474</td>\n",
       "      <td>0.556526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03076</th>\n",
       "      <td>0</td>\n",
       "      <td>0.667350</td>\n",
       "      <td>0.332650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613916</td>\n",
       "      <td>0.386084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.673997</td>\n",
       "      <td>0.326003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.651754</td>\n",
       "      <td>0.348246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03077</th>\n",
       "      <td>1</td>\n",
       "      <td>0.254529</td>\n",
       "      <td>0.745471</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685073</td>\n",
       "      <td>0.314927</td>\n",
       "      <td>1</td>\n",
       "      <td>0.404368</td>\n",
       "      <td>0.595632</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447990</td>\n",
       "      <td>0.552010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03078</th>\n",
       "      <td>0</td>\n",
       "      <td>0.896574</td>\n",
       "      <td>0.103426</td>\n",
       "      <td>0</td>\n",
       "      <td>0.719981</td>\n",
       "      <td>0.280019</td>\n",
       "      <td>0</td>\n",
       "      <td>0.792116</td>\n",
       "      <td>0.207884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.802891</td>\n",
       "      <td>0.197109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03079</th>\n",
       "      <td>0</td>\n",
       "      <td>0.534293</td>\n",
       "      <td>0.465707</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216274</td>\n",
       "      <td>0.783726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360704</td>\n",
       "      <td>0.639296</td>\n",
       "      <td>0</td>\n",
       "      <td>0.370423</td>\n",
       "      <td>0.629577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03080</th>\n",
       "      <td>0</td>\n",
       "      <td>0.548383</td>\n",
       "      <td>0.451617</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564598</td>\n",
       "      <td>0.435402</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612377</td>\n",
       "      <td>0.387623</td>\n",
       "      <td>0</td>\n",
       "      <td>0.575120</td>\n",
       "      <td>0.424880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03081</th>\n",
       "      <td>1</td>\n",
       "      <td>0.411836</td>\n",
       "      <td>0.588164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292686</td>\n",
       "      <td>0.707314</td>\n",
       "      <td>1</td>\n",
       "      <td>0.300559</td>\n",
       "      <td>0.699441</td>\n",
       "      <td>1</td>\n",
       "      <td>0.335027</td>\n",
       "      <td>0.664973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3081 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         model1_class_preds  model1_probability_0  model1_probability_1  \\\n",
       "# ID                                                                      \n",
       "AP00001                   0              0.857053              0.142947   \n",
       "AP00002                   1              0.399618              0.600382   \n",
       "AP00003                   0              0.880166              0.119834   \n",
       "AP00004                   0              0.917753              0.082247   \n",
       "AP00005                   0              0.567934              0.432066   \n",
       "AP00006                   0              0.754630              0.245370   \n",
       "AP00007                   1              0.496790              0.503210   \n",
       "AP00008                   0              0.574337              0.425663   \n",
       "AP00009                   1              0.485306              0.514694   \n",
       "AP00010                   0              0.720302              0.279698   \n",
       "AP00011                   0              0.706748              0.293252   \n",
       "AP00012                   1              0.233994              0.766006   \n",
       "AP00013                   1              0.130996              0.869004   \n",
       "AP00014                   1              0.063455              0.936545   \n",
       "AP00015                   1              0.063290              0.936710   \n",
       "AP00016                   1              0.099491              0.900509   \n",
       "AP00017                   1              0.056927              0.943073   \n",
       "AP00018                   1              0.049326              0.950674   \n",
       "AP00019                   1              0.239323              0.760677   \n",
       "AP00020                   1              0.119740              0.880260   \n",
       "AP00021                   1              0.149496              0.850504   \n",
       "AP00022                   1              0.121960              0.878040   \n",
       "AP00023                   0              0.512234              0.487766   \n",
       "AP00024                   0              0.981260              0.018740   \n",
       "AP00025                   0              0.975407              0.024593   \n",
       "AP00026                   1              0.308948              0.691052   \n",
       "AP00027                   0              0.878292              0.121708   \n",
       "AP00028                   1              0.306283              0.693717   \n",
       "AP00029                   0              0.874520              0.125480   \n",
       "AP00030                   1              0.484763              0.515237   \n",
       "...                     ...                   ...                   ...   \n",
       "AP03052                   1              0.084186              0.915814   \n",
       "AP03053                   0              0.708124              0.291876   \n",
       "AP03054                   0              0.847844              0.152156   \n",
       "AP03055                   0              0.587855              0.412145   \n",
       "AP03056                   1              0.479931              0.520069   \n",
       "AP03057                   1              0.179603              0.820397   \n",
       "AP03058                   1              0.261648              0.738352   \n",
       "AP03059                   1              0.153259              0.846741   \n",
       "AP03060                   1              0.419772              0.580228   \n",
       "AP03061                   0              0.539515              0.460485   \n",
       "AP03062                   1              0.019053              0.980947   \n",
       "AP03063                   0              0.971125              0.028875   \n",
       "AP03064                   0              0.905703              0.094297   \n",
       "AP03065                   0              0.727984              0.272016   \n",
       "AP03066                   0              0.723327              0.276673   \n",
       "AP03067                   0              0.740084              0.259916   \n",
       "AP03068                   0              0.736819              0.263181   \n",
       "AP03069                   0              0.581889              0.418111   \n",
       "AP03070                   0              0.717740              0.282260   \n",
       "AP03071                   0              0.593267              0.406733   \n",
       "AP03072                   0              0.612568              0.387432   \n",
       "AP03073                   1              0.066891              0.933109   \n",
       "AP03074                   1              0.355690              0.644310   \n",
       "AP03075                   1              0.240575              0.759425   \n",
       "AP03076                   0              0.667350              0.332650   \n",
       "AP03077                   1              0.254529              0.745471   \n",
       "AP03078                   0              0.896574              0.103426   \n",
       "AP03079                   0              0.534293              0.465707   \n",
       "AP03080                   0              0.548383              0.451617   \n",
       "AP03081                   1              0.411836              0.588164   \n",
       "\n",
       "         model2_class_preds  model2_probability_0  model2_probability_1  \\\n",
       "# ID                                                                      \n",
       "AP00001                   0              0.575067              0.424933   \n",
       "AP00002                   1              0.469647              0.530353   \n",
       "AP00003                   0              0.904689              0.095311   \n",
       "AP00004                   0              0.932841              0.067159   \n",
       "AP00005                   0              0.648987              0.351013   \n",
       "AP00006                   1              0.408488              0.591512   \n",
       "AP00007                   1              0.317158              0.682842   \n",
       "AP00008                   0              0.667192              0.332808   \n",
       "AP00009                   0              0.661224              0.338776   \n",
       "AP00010                   0              0.879834              0.120166   \n",
       "AP00011                   0              0.821454              0.178546   \n",
       "AP00012                   0              0.533399              0.466601   \n",
       "AP00013                   0              0.516568              0.483432   \n",
       "AP00014                   1              0.175849              0.824151   \n",
       "AP00015                   1              0.186637              0.813363   \n",
       "AP00016                   1              0.178455              0.821545   \n",
       "AP00017                   1              0.175849              0.824151   \n",
       "AP00018                   1              0.147506              0.852494   \n",
       "AP00019                   1              0.242449              0.757551   \n",
       "AP00020                   1              0.218050              0.781950   \n",
       "AP00021                   1              0.235420              0.764580   \n",
       "AP00022                   1              0.187701              0.812299   \n",
       "AP00023                   0              0.852200              0.147800   \n",
       "AP00024                   0              0.852096              0.147904   \n",
       "AP00025                   0              0.855079              0.144921   \n",
       "AP00026                   1              0.447266              0.552734   \n",
       "AP00027                   0              0.968717              0.031283   \n",
       "AP00028                   1              0.190406              0.809594   \n",
       "AP00029                   0              0.783572              0.216428   \n",
       "AP00030                   0              0.771424              0.228576   \n",
       "...                     ...                   ...                   ...   \n",
       "AP03052                   0              0.729920              0.270080   \n",
       "AP03053                   1              0.220079              0.779921   \n",
       "AP03054                   0              0.855957              0.144043   \n",
       "AP03055                   0              0.802755              0.197245   \n",
       "AP03056                   0              0.649222              0.350778   \n",
       "AP03057                   1              0.251294              0.748706   \n",
       "AP03058                   0              0.620545              0.379455   \n",
       "AP03059                   1              0.158968              0.841032   \n",
       "AP03060                   1              0.211507              0.788493   \n",
       "AP03061                   0              0.514062              0.485938   \n",
       "AP03062                   1              0.056970              0.943030   \n",
       "AP03063                   0              0.966535              0.033465   \n",
       "AP03064                   0              0.798927              0.201073   \n",
       "AP03065                   0              0.692779              0.307221   \n",
       "AP03066                   0              0.686070              0.313930   \n",
       "AP03067                   0              0.724842              0.275158   \n",
       "AP03068                   0              0.604903              0.395097   \n",
       "AP03069                   0              0.591909              0.408091   \n",
       "AP03070                   0              0.850029              0.149971   \n",
       "AP03071                   0              0.862734              0.137266   \n",
       "AP03072                   0              0.890099              0.109901   \n",
       "AP03073                   1              0.125429              0.874571   \n",
       "AP03074                   0              0.621350              0.378650   \n",
       "AP03075                   0              0.816995              0.183005   \n",
       "AP03076                   0              0.613916              0.386084   \n",
       "AP03077                   0              0.685073              0.314927   \n",
       "AP03078                   0              0.719981              0.280019   \n",
       "AP03079                   1              0.216274              0.783726   \n",
       "AP03080                   0              0.564598              0.435402   \n",
       "AP03081                   1              0.292686              0.707314   \n",
       "\n",
       "         model3_class_preds  model3_probability_0  model3_probability_1  \\\n",
       "# ID                                                                      \n",
       "AP00001                   0              0.552769              0.447231   \n",
       "AP00002                   0              0.704230              0.295770   \n",
       "AP00003                   0              0.876661              0.123339   \n",
       "AP00004                   0              0.943155              0.056845   \n",
       "AP00005                   0              0.739267              0.260733   \n",
       "AP00006                   0              0.716506              0.283494   \n",
       "AP00007                   1              0.492591              0.507409   \n",
       "AP00008                   0              0.650120              0.349880   \n",
       "AP00009                   1              0.468274              0.531726   \n",
       "AP00010                   0              0.692275              0.307725   \n",
       "AP00011                   0              0.576159              0.423841   \n",
       "AP00012                   1              0.325364              0.674636   \n",
       "AP00013                   1              0.278350              0.721650   \n",
       "AP00014                   1              0.090782              0.909218   \n",
       "AP00015                   1              0.090782              0.909218   \n",
       "AP00016                   1              0.129534              0.870466   \n",
       "AP00017                   1              0.090782              0.909218   \n",
       "AP00018                   1              0.068969              0.931031   \n",
       "AP00019                   1              0.178576              0.821424   \n",
       "AP00020                   1              0.130217              0.869783   \n",
       "AP00021                   1              0.117406              0.882594   \n",
       "AP00022                   1              0.119806              0.880194   \n",
       "AP00023                   0              0.677475              0.322525   \n",
       "AP00024                   0              0.977211              0.022789   \n",
       "AP00025                   0              0.969686              0.030314   \n",
       "AP00026                   1              0.430802              0.569198   \n",
       "AP00027                   0              0.927131              0.072869   \n",
       "AP00028                   1              0.137109              0.862891   \n",
       "AP00029                   0              0.793759              0.206241   \n",
       "AP00030                   0              0.582097              0.417903   \n",
       "...                     ...                   ...                   ...   \n",
       "AP03052                   1              0.332436              0.667564   \n",
       "AP03053                   1              0.445471              0.554529   \n",
       "AP03054                   0              0.728744              0.271256   \n",
       "AP03055                   0              0.623544              0.376456   \n",
       "AP03056                   0              0.600689              0.399311   \n",
       "AP03057                   1              0.228350              0.771650   \n",
       "AP03058                   1              0.198931              0.801069   \n",
       "AP03059                   1              0.284511              0.715489   \n",
       "AP03060                   1              0.425052              0.574948   \n",
       "AP03061                   0              0.687205              0.312795   \n",
       "AP03062                   1              0.043249              0.956751   \n",
       "AP03063                   0              0.871983              0.128017   \n",
       "AP03064                   0              0.745877              0.254123   \n",
       "AP03065                   0              0.678167              0.321833   \n",
       "AP03066                   0              0.790025              0.209975   \n",
       "AP03067                   0              0.843229              0.156771   \n",
       "AP03068                   0              0.754065              0.245935   \n",
       "AP03069                   0              0.615526              0.384474   \n",
       "AP03070                   0              0.815077              0.184923   \n",
       "AP03071                   0              0.754629              0.245371   \n",
       "AP03072                   0              0.551739              0.448261   \n",
       "AP03073                   1              0.088491              0.911509   \n",
       "AP03074                   1              0.495985              0.504015   \n",
       "AP03075                   1              0.272852              0.727148   \n",
       "AP03076                   0              0.673997              0.326003   \n",
       "AP03077                   1              0.404368              0.595632   \n",
       "AP03078                   0              0.792116              0.207884   \n",
       "AP03079                   1              0.360704              0.639296   \n",
       "AP03080                   0              0.612377              0.387623   \n",
       "AP03081                   1              0.300559              0.699441   \n",
       "\n",
       "         consensus_class_preds  consensus_probability_0  \\\n",
       "# ID                                                      \n",
       "AP00001                      0                 0.661630   \n",
       "AP00002                      0                 0.524498   \n",
       "AP00003                      0                 0.887172   \n",
       "AP00004                      0                 0.931249   \n",
       "AP00005                      0                 0.652063   \n",
       "AP00006                      0                 0.626541   \n",
       "AP00007                      1                 0.435513   \n",
       "AP00008                      0                 0.630550   \n",
       "AP00009                      0                 0.538268   \n",
       "AP00010                      0                 0.764137   \n",
       "AP00011                      0                 0.701454   \n",
       "AP00012                      0                 0.364253   \n",
       "AP00013                      0                 0.308638   \n",
       "AP00014                      1                 0.110029   \n",
       "AP00015                      1                 0.113570   \n",
       "AP00016                      1                 0.135826   \n",
       "AP00017                      1                 0.107853   \n",
       "AP00018                      1                 0.088601   \n",
       "AP00019                      1                 0.220116   \n",
       "AP00020                      1                 0.156002   \n",
       "AP00021                      1                 0.167441   \n",
       "AP00022                      1                 0.143156   \n",
       "AP00023                      0                 0.680636   \n",
       "AP00024                      0                 0.936856   \n",
       "AP00025                      0                 0.933391   \n",
       "AP00026                      1                 0.395672   \n",
       "AP00027                      0                 0.924713   \n",
       "AP00028                      1                 0.211266   \n",
       "AP00029                      0                 0.817284   \n",
       "AP00030                      0                 0.612761   \n",
       "...                        ...                      ...   \n",
       "AP03052                      0                 0.382180   \n",
       "AP03053                      0                 0.457891   \n",
       "AP03054                      0                 0.810848   \n",
       "AP03055                      0                 0.671384   \n",
       "AP03056                      0                 0.576614   \n",
       "AP03057                      1                 0.219749   \n",
       "AP03058                      0                 0.360375   \n",
       "AP03059                      1                 0.198913   \n",
       "AP03060                      1                 0.352110   \n",
       "AP03061                      0                 0.580261   \n",
       "AP03062                      1                 0.039758   \n",
       "AP03063                      0                 0.936548   \n",
       "AP03064                      0                 0.816836   \n",
       "AP03065                      0                 0.699643   \n",
       "AP03066                      0                 0.733141   \n",
       "AP03067                      0                 0.769385   \n",
       "AP03068                      0                 0.698596   \n",
       "AP03069                      0                 0.596441   \n",
       "AP03070                      0                 0.794282   \n",
       "AP03071                      0                 0.736877   \n",
       "AP03072                      0                 0.684802   \n",
       "AP03073                      1                 0.093604   \n",
       "AP03074                      0                 0.491008   \n",
       "AP03075                      0                 0.443474   \n",
       "AP03076                      0                 0.651754   \n",
       "AP03077                      0                 0.447990   \n",
       "AP03078                      0                 0.802891   \n",
       "AP03079                      0                 0.370423   \n",
       "AP03080                      0                 0.575120   \n",
       "AP03081                      1                 0.335027   \n",
       "\n",
       "         consensus_probability_1  \n",
       "# ID                              \n",
       "AP00001                 0.338370  \n",
       "AP00002                 0.475502  \n",
       "AP00003                 0.112828  \n",
       "AP00004                 0.068751  \n",
       "AP00005                 0.347937  \n",
       "AP00006                 0.373459  \n",
       "AP00007                 0.564487  \n",
       "AP00008                 0.369450  \n",
       "AP00009                 0.461732  \n",
       "AP00010                 0.235863  \n",
       "AP00011                 0.298546  \n",
       "AP00012                 0.635747  \n",
       "AP00013                 0.691362  \n",
       "AP00014                 0.889971  \n",
       "AP00015                 0.886430  \n",
       "AP00016                 0.864174  \n",
       "AP00017                 0.892147  \n",
       "AP00018                 0.911399  \n",
       "AP00019                 0.779884  \n",
       "AP00020                 0.843998  \n",
       "AP00021                 0.832559  \n",
       "AP00022                 0.856844  \n",
       "AP00023                 0.319364  \n",
       "AP00024                 0.063144  \n",
       "AP00025                 0.066609  \n",
       "AP00026                 0.604328  \n",
       "AP00027                 0.075287  \n",
       "AP00028                 0.788734  \n",
       "AP00029                 0.182716  \n",
       "AP00030                 0.387239  \n",
       "...                          ...  \n",
       "AP03052                 0.617820  \n",
       "AP03053                 0.542109  \n",
       "AP03054                 0.189152  \n",
       "AP03055                 0.328616  \n",
       "AP03056                 0.423386  \n",
       "AP03057                 0.780251  \n",
       "AP03058                 0.639625  \n",
       "AP03059                 0.801087  \n",
       "AP03060                 0.647890  \n",
       "AP03061                 0.419739  \n",
       "AP03062                 0.960242  \n",
       "AP03063                 0.063452  \n",
       "AP03064                 0.183164  \n",
       "AP03065                 0.300357  \n",
       "AP03066                 0.266859  \n",
       "AP03067                 0.230615  \n",
       "AP03068                 0.301404  \n",
       "AP03069                 0.403559  \n",
       "AP03070                 0.205718  \n",
       "AP03071                 0.263123  \n",
       "AP03072                 0.315198  \n",
       "AP03073                 0.906396  \n",
       "AP03074                 0.508992  \n",
       "AP03075                 0.556526  \n",
       "AP03076                 0.348246  \n",
       "AP03077                 0.552010  \n",
       "AP03078                 0.197109  \n",
       "AP03079                 0.629577  \n",
       "AP03080                 0.424880  \n",
       "AP03081                 0.664973  \n",
       "\n",
       "[3081 rows x 12 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save test set results into dataframe\n",
    "# Model 2.1\n",
    "model1_hpi2.fit(X_HemoPI2_model, y_HemoPI2_model)\n",
    "class_df = pd.DataFrame(model1_hpi2.predict(X_totalAPD_hpi2))\n",
    "probs_df = pd.DataFrame(model1_hpi2.predict_proba(X_totalAPD_hpi2))\n",
    "\n",
    "model1_hpi2_apd = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model1_hpi2_apd.index = X_totalAPD_hpi2.index\n",
    "model1_hpi2_apd.columns = ['model1_class_preds', 'model1_probability_0', 'model1_probability_1']\n",
    "\n",
    "# Model 2.2\n",
    "model2_hpi2.fit(X_HemoPI2_model_RFE, y_HemoPI2_model)\n",
    "class_df2 = pd.DataFrame(model2_hpi2.predict(X_totalAPD_hpi2_RFE))\n",
    "probs_df2 = pd.DataFrame(model2_hpi2.predict_proba(X_totalAPD_hpi2_RFE))\n",
    "\n",
    "model2_hpi2_apd = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model2_hpi2_apd.index = X_totalAPD_hpi2.index\n",
    "model2_hpi2_apd.columns = ['model2_class_preds', 'model2_probability_0', 'model2_probability_1']\n",
    "\n",
    "# Model 2.3\n",
    "model3_hpi2.fit(X_HemoPI2_model, y_HemoPI2_model)\n",
    "class_df3 = pd.DataFrame(model3_hpi2.predict(X_totalAPD_hpi2))\n",
    "probs_df3 = pd.DataFrame(model3_hpi2.predict_proba(X_totalAPD_hpi2))\n",
    "\n",
    "model3_hpi2_apd = class_df3.merge(probs_df3, how='outer', left_index=True, right_index=True)\n",
    "model3_hpi2_apd.index = X_totalAPD_hpi2.index\n",
    "model3_hpi2_apd.columns = ['model3_class_preds', 'model3_probability_0', 'model3_probability_1']\n",
    "\n",
    "# Merge model dataframes\n",
    "models_hpi2 = [model1_hpi2_apd, model2_hpi2_apd, model3_hpi2_apd]\n",
    "\n",
    "results_models_hpi2_apd = pd.concat(models_hpi2, axis=1, join='inner')\n",
    "results_models_hpi2_apd.index = model1_hpi2_apd.index\n",
    "results_models_hpi2_apd\n",
    "\n",
    "#Create consensus columns\n",
    "results_models_hpi2_apd['consensus_class_preds'] = results_models_hpi2_apd[['model1_class_preds', 'model2_class_preds', 'model3_class_preds']].mean(axis=1).astype(int)\n",
    "results_models_hpi2_apd['consensus_probability_0'] = results_models_hpi2_apd[['model1_probability_0', 'model2_probability_0', 'model3_probability_0']].mean(axis=1)\n",
    "results_models_hpi2_apd['consensus_probability_1'] = results_models_hpi2_apd[['model1_probability_1', 'model2_probability_1', 'model3_probability_1']].mean(axis=1)\n",
    "\n",
    "results_models_hpi2_apd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_models_hpi2_apd.to_csv('./Results/predictions_totalAPD_HemoPI2_topmodels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 1554, True: 1527})"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many AMPs are haemolytic peptides at low concentration according to HemoPI-2 models?\n",
    "Counter(results_models_hpi2_apd['consensus_probability_1'] > 0.5) #1527\n",
    "Counter(results_models_hpi2_apd['model1_probability_1'] > 0.5) #1555\n",
    "Counter(results_models_hpi2_apd['model2_probability_1'] > 0.5) #1431\n",
    "Counter(results_models_hpi2_apd['model3_probability_1'] > 0.5) #1621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1_class_preds</th>\n",
       "      <th>model1_probability_0</th>\n",
       "      <th>model1_probability_1</th>\n",
       "      <th>model2_class_preds</th>\n",
       "      <th>model2_probability_0</th>\n",
       "      <th>model2_probability_1</th>\n",
       "      <th>model3_class_preds</th>\n",
       "      <th>model3_probability_0</th>\n",
       "      <th>model3_probability_1</th>\n",
       "      <th>consensus_class_preds</th>\n",
       "      <th>consensus_probability_0</th>\n",
       "      <th>consensus_probability_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AP00001</th>\n",
       "      <td>1</td>\n",
       "      <td>0.074352</td>\n",
       "      <td>0.925648</td>\n",
       "      <td>1</td>\n",
       "      <td>0.403449</td>\n",
       "      <td>0.596551</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599244</td>\n",
       "      <td>0.400756</td>\n",
       "      <td>0</td>\n",
       "      <td>0.359015</td>\n",
       "      <td>0.640985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00002</th>\n",
       "      <td>0</td>\n",
       "      <td>0.952451</td>\n",
       "      <td>0.047549</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977810</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941865</td>\n",
       "      <td>0.058135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957375</td>\n",
       "      <td>0.042625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00003</th>\n",
       "      <td>0</td>\n",
       "      <td>0.853471</td>\n",
       "      <td>0.146529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689280</td>\n",
       "      <td>0.310720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700958</td>\n",
       "      <td>0.299042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.747903</td>\n",
       "      <td>0.252097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00004</th>\n",
       "      <td>0</td>\n",
       "      <td>0.912958</td>\n",
       "      <td>0.087042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833931</td>\n",
       "      <td>0.166069</td>\n",
       "      <td>1</td>\n",
       "      <td>0.284512</td>\n",
       "      <td>0.715488</td>\n",
       "      <td>0</td>\n",
       "      <td>0.677134</td>\n",
       "      <td>0.322866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00005</th>\n",
       "      <td>1</td>\n",
       "      <td>0.204457</td>\n",
       "      <td>0.795543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044695</td>\n",
       "      <td>0.955305</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078984</td>\n",
       "      <td>0.921016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109379</td>\n",
       "      <td>0.890621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00006</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988438</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995416</td>\n",
       "      <td>0.004584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00007</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999367</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993736</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>0.002345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00008</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.999536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.998835</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063394</td>\n",
       "      <td>0.936606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021674</td>\n",
       "      <td>0.978326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00009</th>\n",
       "      <td>0</td>\n",
       "      <td>0.924783</td>\n",
       "      <td>0.075217</td>\n",
       "      <td>0</td>\n",
       "      <td>0.928984</td>\n",
       "      <td>0.071016</td>\n",
       "      <td>0</td>\n",
       "      <td>0.743096</td>\n",
       "      <td>0.256904</td>\n",
       "      <td>0</td>\n",
       "      <td>0.865621</td>\n",
       "      <td>0.134379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00010</th>\n",
       "      <td>0</td>\n",
       "      <td>0.996280</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.964701</td>\n",
       "      <td>0.035299</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948146</td>\n",
       "      <td>0.051854</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969709</td>\n",
       "      <td>0.030291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00011</th>\n",
       "      <td>0</td>\n",
       "      <td>0.735118</td>\n",
       "      <td>0.264882</td>\n",
       "      <td>0</td>\n",
       "      <td>0.769731</td>\n",
       "      <td>0.230269</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680532</td>\n",
       "      <td>0.319468</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728460</td>\n",
       "      <td>0.271540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00012</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581094</td>\n",
       "      <td>0.418906</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366157</td>\n",
       "      <td>0.633843</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071929</td>\n",
       "      <td>0.928071</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339727</td>\n",
       "      <td>0.660273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00013</th>\n",
       "      <td>0</td>\n",
       "      <td>0.511723</td>\n",
       "      <td>0.488277</td>\n",
       "      <td>1</td>\n",
       "      <td>0.321801</td>\n",
       "      <td>0.678199</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055779</td>\n",
       "      <td>0.944221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296434</td>\n",
       "      <td>0.703566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00014</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015633</td>\n",
       "      <td>0.984367</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.987621</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200957</td>\n",
       "      <td>0.799043</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076323</td>\n",
       "      <td>0.923677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00015</th>\n",
       "      <td>1</td>\n",
       "      <td>0.019194</td>\n",
       "      <td>0.980806</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>0.991527</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221842</td>\n",
       "      <td>0.778158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083170</td>\n",
       "      <td>0.916830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00016</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.990862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.972023</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104350</td>\n",
       "      <td>0.895650</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047155</td>\n",
       "      <td>0.952845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00017</th>\n",
       "      <td>1</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>0.985735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032189</td>\n",
       "      <td>0.967811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.183950</td>\n",
       "      <td>0.816050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076801</td>\n",
       "      <td>0.923199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00018</th>\n",
       "      <td>1</td>\n",
       "      <td>0.014818</td>\n",
       "      <td>0.985182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.996388</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060140</td>\n",
       "      <td>0.939860</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026190</td>\n",
       "      <td>0.973810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00019</th>\n",
       "      <td>1</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.992821</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.995080</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016132</td>\n",
       "      <td>0.983868</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.990589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00020</th>\n",
       "      <td>1</td>\n",
       "      <td>0.073652</td>\n",
       "      <td>0.926348</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123856</td>\n",
       "      <td>0.876144</td>\n",
       "      <td>1</td>\n",
       "      <td>0.237551</td>\n",
       "      <td>0.762449</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145020</td>\n",
       "      <td>0.854980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00021</th>\n",
       "      <td>1</td>\n",
       "      <td>0.110420</td>\n",
       "      <td>0.889580</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084610</td>\n",
       "      <td>0.915390</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244786</td>\n",
       "      <td>0.755214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146606</td>\n",
       "      <td>0.853394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00022</th>\n",
       "      <td>1</td>\n",
       "      <td>0.039148</td>\n",
       "      <td>0.960852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109847</td>\n",
       "      <td>0.890153</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150839</td>\n",
       "      <td>0.849161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099945</td>\n",
       "      <td>0.900055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00023</th>\n",
       "      <td>0</td>\n",
       "      <td>0.951977</td>\n",
       "      <td>0.048023</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620215</td>\n",
       "      <td>0.379785</td>\n",
       "      <td>0</td>\n",
       "      <td>0.574305</td>\n",
       "      <td>0.425695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.715499</td>\n",
       "      <td>0.284501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00024</th>\n",
       "      <td>0</td>\n",
       "      <td>0.745355</td>\n",
       "      <td>0.254645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936286</td>\n",
       "      <td>0.063714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704196</td>\n",
       "      <td>0.295804</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795279</td>\n",
       "      <td>0.204721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00025</th>\n",
       "      <td>0</td>\n",
       "      <td>0.854243</td>\n",
       "      <td>0.145757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.911482</td>\n",
       "      <td>0.088518</td>\n",
       "      <td>0</td>\n",
       "      <td>0.864654</td>\n",
       "      <td>0.135346</td>\n",
       "      <td>0</td>\n",
       "      <td>0.876793</td>\n",
       "      <td>0.123207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00026</th>\n",
       "      <td>1</td>\n",
       "      <td>0.042697</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248197</td>\n",
       "      <td>0.751803</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370818</td>\n",
       "      <td>0.629182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.220570</td>\n",
       "      <td>0.779430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00027</th>\n",
       "      <td>0</td>\n",
       "      <td>0.973533</td>\n",
       "      <td>0.026467</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767114</td>\n",
       "      <td>0.232886</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883479</td>\n",
       "      <td>0.116521</td>\n",
       "      <td>0</td>\n",
       "      <td>0.874708</td>\n",
       "      <td>0.125292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00028</th>\n",
       "      <td>1</td>\n",
       "      <td>0.132573</td>\n",
       "      <td>0.867427</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>0.989377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066412</td>\n",
       "      <td>0.933588</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069869</td>\n",
       "      <td>0.930131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00029</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999544</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>0.007573</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997261</td>\n",
       "      <td>0.002739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00030</th>\n",
       "      <td>0</td>\n",
       "      <td>0.890228</td>\n",
       "      <td>0.109772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969027</td>\n",
       "      <td>0.030973</td>\n",
       "      <td>0</td>\n",
       "      <td>0.975916</td>\n",
       "      <td>0.024084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945057</td>\n",
       "      <td>0.054943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03052</th>\n",
       "      <td>0</td>\n",
       "      <td>0.964212</td>\n",
       "      <td>0.035788</td>\n",
       "      <td>0</td>\n",
       "      <td>0.925945</td>\n",
       "      <td>0.074055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892389</td>\n",
       "      <td>0.107611</td>\n",
       "      <td>0</td>\n",
       "      <td>0.927515</td>\n",
       "      <td>0.072485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03053</th>\n",
       "      <td>1</td>\n",
       "      <td>0.391887</td>\n",
       "      <td>0.608113</td>\n",
       "      <td>0</td>\n",
       "      <td>0.896445</td>\n",
       "      <td>0.103555</td>\n",
       "      <td>0</td>\n",
       "      <td>0.841281</td>\n",
       "      <td>0.158719</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709871</td>\n",
       "      <td>0.290129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03054</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998231</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998580</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989879</td>\n",
       "      <td>0.010121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03055</th>\n",
       "      <td>0</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.040641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983575</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937236</td>\n",
       "      <td>0.062764</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960057</td>\n",
       "      <td>0.039943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03056</th>\n",
       "      <td>1</td>\n",
       "      <td>0.181439</td>\n",
       "      <td>0.818561</td>\n",
       "      <td>1</td>\n",
       "      <td>0.335168</td>\n",
       "      <td>0.664832</td>\n",
       "      <td>1</td>\n",
       "      <td>0.105439</td>\n",
       "      <td>0.894561</td>\n",
       "      <td>1</td>\n",
       "      <td>0.207349</td>\n",
       "      <td>0.792651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03057</th>\n",
       "      <td>1</td>\n",
       "      <td>0.006036</td>\n",
       "      <td>0.993964</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066607</td>\n",
       "      <td>0.933393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240179</td>\n",
       "      <td>0.759821</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104274</td>\n",
       "      <td>0.895726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03058</th>\n",
       "      <td>1</td>\n",
       "      <td>0.313631</td>\n",
       "      <td>0.686369</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402183</td>\n",
       "      <td>0.597817</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032104</td>\n",
       "      <td>0.967896</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249306</td>\n",
       "      <td>0.750694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03059</th>\n",
       "      <td>1</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.962900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056516</td>\n",
       "      <td>0.943484</td>\n",
       "      <td>1</td>\n",
       "      <td>0.134285</td>\n",
       "      <td>0.865715</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075967</td>\n",
       "      <td>0.924033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03060</th>\n",
       "      <td>1</td>\n",
       "      <td>0.043986</td>\n",
       "      <td>0.956014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.260441</td>\n",
       "      <td>0.739559</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087789</td>\n",
       "      <td>0.912211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130739</td>\n",
       "      <td>0.869261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03061</th>\n",
       "      <td>0</td>\n",
       "      <td>0.995972</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993230</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956865</td>\n",
       "      <td>0.043135</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982022</td>\n",
       "      <td>0.017978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03062</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.998616</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.999466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03063</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997528</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0</td>\n",
       "      <td>0.935635</td>\n",
       "      <td>0.064365</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933996</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955720</td>\n",
       "      <td>0.044280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03064</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990933</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.934379</td>\n",
       "      <td>0.065621</td>\n",
       "      <td>0</td>\n",
       "      <td>0.885213</td>\n",
       "      <td>0.114787</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.063158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03065</th>\n",
       "      <td>0</td>\n",
       "      <td>0.983506</td>\n",
       "      <td>0.016494</td>\n",
       "      <td>0</td>\n",
       "      <td>0.934664</td>\n",
       "      <td>0.065336</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985458</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967876</td>\n",
       "      <td>0.032124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03066</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997027</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989308</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995085</td>\n",
       "      <td>0.004915</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993807</td>\n",
       "      <td>0.006193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03067</th>\n",
       "      <td>0</td>\n",
       "      <td>0.951300</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.991839</td>\n",
       "      <td>0.008161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980602</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974580</td>\n",
       "      <td>0.025420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03068</th>\n",
       "      <td>0</td>\n",
       "      <td>0.504183</td>\n",
       "      <td>0.495817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.802308</td>\n",
       "      <td>0.197692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902570</td>\n",
       "      <td>0.097430</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736354</td>\n",
       "      <td>0.263646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03069</th>\n",
       "      <td>1</td>\n",
       "      <td>0.472009</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418951</td>\n",
       "      <td>0.581049</td>\n",
       "      <td>1</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.526100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454953</td>\n",
       "      <td>0.545047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03070</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999559</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997492</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995184</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997412</td>\n",
       "      <td>0.002588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03071</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991766</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967257</td>\n",
       "      <td>0.032743</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984937</td>\n",
       "      <td>0.015063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03072</th>\n",
       "      <td>0</td>\n",
       "      <td>0.982211</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.968920</td>\n",
       "      <td>0.031080</td>\n",
       "      <td>0</td>\n",
       "      <td>0.819315</td>\n",
       "      <td>0.180685</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923482</td>\n",
       "      <td>0.076518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03073</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.997592</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010721</td>\n",
       "      <td>0.989279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004442</td>\n",
       "      <td>0.995558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03074</th>\n",
       "      <td>0</td>\n",
       "      <td>0.845288</td>\n",
       "      <td>0.154712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639745</td>\n",
       "      <td>0.360255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.362841</td>\n",
       "      <td>0.637159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615958</td>\n",
       "      <td>0.384042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03075</th>\n",
       "      <td>1</td>\n",
       "      <td>0.380344</td>\n",
       "      <td>0.619656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294834</td>\n",
       "      <td>0.705166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.202558</td>\n",
       "      <td>0.797442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292579</td>\n",
       "      <td>0.707421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03076</th>\n",
       "      <td>0</td>\n",
       "      <td>0.653440</td>\n",
       "      <td>0.346560</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045013</td>\n",
       "      <td>0.954987</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333339</td>\n",
       "      <td>0.666661</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343931</td>\n",
       "      <td>0.656069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03077</th>\n",
       "      <td>1</td>\n",
       "      <td>0.446062</td>\n",
       "      <td>0.553938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.286210</td>\n",
       "      <td>0.713790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654221</td>\n",
       "      <td>0.345779</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462164</td>\n",
       "      <td>0.537836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03078</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990713</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>0</td>\n",
       "      <td>0.978501</td>\n",
       "      <td>0.021499</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941475</td>\n",
       "      <td>0.058525</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970230</td>\n",
       "      <td>0.029770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03079</th>\n",
       "      <td>1</td>\n",
       "      <td>0.431379</td>\n",
       "      <td>0.568621</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122321</td>\n",
       "      <td>0.877679</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191511</td>\n",
       "      <td>0.808489</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248404</td>\n",
       "      <td>0.751596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03080</th>\n",
       "      <td>1</td>\n",
       "      <td>0.067320</td>\n",
       "      <td>0.932680</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.911300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349673</td>\n",
       "      <td>0.650327</td>\n",
       "      <td>1</td>\n",
       "      <td>0.168564</td>\n",
       "      <td>0.831436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP03081</th>\n",
       "      <td>1</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>0.916993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243664</td>\n",
       "      <td>0.756336</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084328</td>\n",
       "      <td>0.915672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.863000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3081 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         model1_class_preds  model1_probability_0  model1_probability_1  \\\n",
       "# ID                                                                      \n",
       "AP00001                   1              0.074352              0.925648   \n",
       "AP00002                   0              0.952451              0.047549   \n",
       "AP00003                   0              0.853471              0.146529   \n",
       "AP00004                   0              0.912958              0.087042   \n",
       "AP00005                   1              0.204457              0.795543   \n",
       "AP00006                   0              0.999504              0.000496   \n",
       "AP00007                   0              0.999863              0.000137   \n",
       "AP00008                   1              0.000464              0.999536   \n",
       "AP00009                   0              0.924783              0.075217   \n",
       "AP00010                   0              0.996280              0.003720   \n",
       "AP00011                   0              0.735118              0.264882   \n",
       "AP00012                   0              0.581094              0.418906   \n",
       "AP00013                   0              0.511723              0.488277   \n",
       "AP00014                   1              0.015633              0.984367   \n",
       "AP00015                   1              0.019194              0.980806   \n",
       "AP00016                   1              0.009138              0.990862   \n",
       "AP00017                   1              0.014265              0.985735   \n",
       "AP00018                   1              0.014818              0.985182   \n",
       "AP00019                   1              0.007179              0.992821   \n",
       "AP00020                   1              0.073652              0.926348   \n",
       "AP00021                   1              0.110420              0.889580   \n",
       "AP00022                   1              0.039148              0.960852   \n",
       "AP00023                   0              0.951977              0.048023   \n",
       "AP00024                   0              0.745355              0.254645   \n",
       "AP00025                   0              0.854243              0.145757   \n",
       "AP00026                   1              0.042697              0.957303   \n",
       "AP00027                   0              0.973533              0.026467   \n",
       "AP00028                   1              0.132573              0.867427   \n",
       "AP00029                   0              0.999810              0.000190   \n",
       "AP00030                   0              0.890228              0.109772   \n",
       "...                     ...                   ...                   ...   \n",
       "AP03052                   0              0.964212              0.035788   \n",
       "AP03053                   1              0.391887              0.608113   \n",
       "AP03054                   0              0.998231              0.001769   \n",
       "AP03055                   0              0.959359              0.040641   \n",
       "AP03056                   1              0.181439              0.818561   \n",
       "AP03057                   1              0.006036              0.993964   \n",
       "AP03058                   1              0.313631              0.686369   \n",
       "AP03059                   1              0.037100              0.962900   \n",
       "AP03060                   1              0.043986              0.956014   \n",
       "AP03061                   0              0.995972              0.004028   \n",
       "AP03062                   1              0.000034              0.999966   \n",
       "AP03063                   0              0.997528              0.002472   \n",
       "AP03064                   0              0.990933              0.009067   \n",
       "AP03065                   0              0.983506              0.016494   \n",
       "AP03066                   0              0.997027              0.002973   \n",
       "AP03067                   0              0.951300              0.048700   \n",
       "AP03068                   0              0.504183              0.495817   \n",
       "AP03069                   1              0.472009              0.527991   \n",
       "AP03070                   0              0.999559              0.000441   \n",
       "AP03071                   0              0.991766              0.008234   \n",
       "AP03072                   0              0.982211              0.017789   \n",
       "AP03073                   1              0.000197              0.999803   \n",
       "AP03074                   0              0.845288              0.154712   \n",
       "AP03075                   1              0.380344              0.619656   \n",
       "AP03076                   0              0.653440              0.346560   \n",
       "AP03077                   1              0.446062              0.553938   \n",
       "AP03078                   0              0.990713              0.009287   \n",
       "AP03079                   1              0.431379              0.568621   \n",
       "AP03080                   1              0.067320              0.932680   \n",
       "AP03081                   1              0.083007              0.916993   \n",
       "\n",
       "         model2_class_preds  model2_probability_0  model2_probability_1  \\\n",
       "# ID                                                                      \n",
       "AP00001                   1              0.403449              0.596551   \n",
       "AP00002                   0              0.977810              0.022190   \n",
       "AP00003                   0              0.689280              0.310720   \n",
       "AP00004                   0              0.833931              0.166069   \n",
       "AP00005                   1              0.044695              0.955305   \n",
       "AP00006                   0              0.998305              0.001695   \n",
       "AP00007                   0              0.999367              0.000633   \n",
       "AP00008                   1              0.001165              0.998835   \n",
       "AP00009                   0              0.928984              0.071016   \n",
       "AP00010                   0              0.964701              0.035299   \n",
       "AP00011                   0              0.769731              0.230269   \n",
       "AP00012                   1              0.366157              0.633843   \n",
       "AP00013                   1              0.321801              0.678199   \n",
       "AP00014                   1              0.012379              0.987621   \n",
       "AP00015                   1              0.008473              0.991527   \n",
       "AP00016                   1              0.027977              0.972023   \n",
       "AP00017                   1              0.032189              0.967811   \n",
       "AP00018                   1              0.003612              0.996388   \n",
       "AP00019                   1              0.004920              0.995080   \n",
       "AP00020                   1              0.123856              0.876144   \n",
       "AP00021                   1              0.084610              0.915390   \n",
       "AP00022                   1              0.109847              0.890153   \n",
       "AP00023                   0              0.620215              0.379785   \n",
       "AP00024                   0              0.936286              0.063714   \n",
       "AP00025                   0              0.911482              0.088518   \n",
       "AP00026                   1              0.248197              0.751803   \n",
       "AP00027                   0              0.767114              0.232886   \n",
       "AP00028                   1              0.010623              0.989377   \n",
       "AP00029                   0              0.999544              0.000456   \n",
       "AP00030                   0              0.969027              0.030973   \n",
       "...                     ...                   ...                   ...   \n",
       "AP03052                   0              0.925945              0.074055   \n",
       "AP03053                   0              0.896445              0.103555   \n",
       "AP03054                   0              0.998580              0.001420   \n",
       "AP03055                   0              0.983575              0.016425   \n",
       "AP03056                   1              0.335168              0.664832   \n",
       "AP03057                   1              0.066607              0.933393   \n",
       "AP03058                   1              0.402183              0.597817   \n",
       "AP03059                   1              0.056516              0.943484   \n",
       "AP03060                   1              0.260441              0.739559   \n",
       "AP03061                   0              0.993230              0.006770   \n",
       "AP03062                   1              0.000185              0.999815   \n",
       "AP03063                   0              0.935635              0.064365   \n",
       "AP03064                   0              0.934379              0.065621   \n",
       "AP03065                   0              0.934664              0.065336   \n",
       "AP03066                   0              0.989308              0.010692   \n",
       "AP03067                   0              0.991839              0.008161   \n",
       "AP03068                   0              0.802308              0.197692   \n",
       "AP03069                   1              0.418951              0.581049   \n",
       "AP03070                   0              0.997492              0.002508   \n",
       "AP03071                   0              0.995789              0.004211   \n",
       "AP03072                   0              0.968920              0.031080   \n",
       "AP03073                   1              0.002408              0.997592   \n",
       "AP03074                   0              0.639745              0.360255   \n",
       "AP03075                   1              0.294834              0.705166   \n",
       "AP03076                   1              0.045013              0.954987   \n",
       "AP03077                   1              0.286210              0.713790   \n",
       "AP03078                   0              0.978501              0.021499   \n",
       "AP03079                   1              0.122321              0.877679   \n",
       "AP03080                   1              0.088700              0.911300   \n",
       "AP03081                   1              0.243664              0.756336   \n",
       "\n",
       "         model3_class_preds  model3_probability_0  model3_probability_1  \\\n",
       "# ID                                                                      \n",
       "AP00001                   0              0.599244              0.400756   \n",
       "AP00002                   0              0.941865              0.058135   \n",
       "AP00003                   0              0.700958              0.299042   \n",
       "AP00004                   1              0.284512              0.715488   \n",
       "AP00005                   1              0.078984              0.921016   \n",
       "AP00006                   0              0.988438              0.011562   \n",
       "AP00007                   0              0.993736              0.006264   \n",
       "AP00008                   1              0.063394              0.936606   \n",
       "AP00009                   0              0.743096              0.256904   \n",
       "AP00010                   0              0.948146              0.051854   \n",
       "AP00011                   0              0.680532              0.319468   \n",
       "AP00012                   1              0.071929              0.928071   \n",
       "AP00013                   1              0.055779              0.944221   \n",
       "AP00014                   1              0.200957              0.799043   \n",
       "AP00015                   1              0.221842              0.778158   \n",
       "AP00016                   1              0.104350              0.895650   \n",
       "AP00017                   1              0.183950              0.816050   \n",
       "AP00018                   1              0.060140              0.939860   \n",
       "AP00019                   1              0.016132              0.983868   \n",
       "AP00020                   1              0.237551              0.762449   \n",
       "AP00021                   1              0.244786              0.755214   \n",
       "AP00022                   1              0.150839              0.849161   \n",
       "AP00023                   0              0.574305              0.425695   \n",
       "AP00024                   0              0.704196              0.295804   \n",
       "AP00025                   0              0.864654              0.135346   \n",
       "AP00026                   1              0.370818              0.629182   \n",
       "AP00027                   0              0.883479              0.116521   \n",
       "AP00028                   1              0.066412              0.933588   \n",
       "AP00029                   0              0.992427              0.007573   \n",
       "AP00030                   0              0.975916              0.024084   \n",
       "...                     ...                   ...                   ...   \n",
       "AP03052                   0              0.892389              0.107611   \n",
       "AP03053                   0              0.841281              0.158719   \n",
       "AP03054                   0              0.972826              0.027174   \n",
       "AP03055                   0              0.937236              0.062764   \n",
       "AP03056                   1              0.105439              0.894561   \n",
       "AP03057                   1              0.240179              0.759821   \n",
       "AP03058                   1              0.032104              0.967896   \n",
       "AP03059                   1              0.134285              0.865715   \n",
       "AP03060                   1              0.087789              0.912211   \n",
       "AP03061                   0              0.956865              0.043135   \n",
       "AP03062                   1              0.001384              0.998616   \n",
       "AP03063                   0              0.933996              0.066004   \n",
       "AP03064                   0              0.885213              0.114787   \n",
       "AP03065                   0              0.985458              0.014542   \n",
       "AP03066                   0              0.995085              0.004915   \n",
       "AP03067                   0              0.980602              0.019398   \n",
       "AP03068                   0              0.902570              0.097430   \n",
       "AP03069                   1              0.473900              0.526100   \n",
       "AP03070                   0              0.995184              0.004816   \n",
       "AP03071                   0              0.967257              0.032743   \n",
       "AP03072                   0              0.819315              0.180685   \n",
       "AP03073                   1              0.010721              0.989279   \n",
       "AP03074                   1              0.362841              0.637159   \n",
       "AP03075                   1              0.202558              0.797442   \n",
       "AP03076                   1              0.333339              0.666661   \n",
       "AP03077                   0              0.654221              0.345779   \n",
       "AP03078                   0              0.941475              0.058525   \n",
       "AP03079                   1              0.191511              0.808489   \n",
       "AP03080                   1              0.349673              0.650327   \n",
       "AP03081                   1              0.084328              0.915672   \n",
       "\n",
       "         consensus_class_preds  consensus_probability_0  \\\n",
       "# ID                                                      \n",
       "AP00001                      0                 0.359015   \n",
       "AP00002                      0                 0.957375   \n",
       "AP00003                      0                 0.747903   \n",
       "AP00004                      0                 0.677134   \n",
       "AP00005                      1                 0.109379   \n",
       "AP00006                      0                 0.995416   \n",
       "AP00007                      0                 0.997655   \n",
       "AP00008                      1                 0.021674   \n",
       "AP00009                      0                 0.865621   \n",
       "AP00010                      0                 0.969709   \n",
       "AP00011                      0                 0.728460   \n",
       "AP00012                      0                 0.339727   \n",
       "AP00013                      0                 0.296434   \n",
       "AP00014                      1                 0.076323   \n",
       "AP00015                      1                 0.083170   \n",
       "AP00016                      1                 0.047155   \n",
       "AP00017                      1                 0.076801   \n",
       "AP00018                      1                 0.026190   \n",
       "AP00019                      1                 0.009411   \n",
       "AP00020                      1                 0.145020   \n",
       "AP00021                      1                 0.146606   \n",
       "AP00022                      1                 0.099945   \n",
       "AP00023                      0                 0.715499   \n",
       "AP00024                      0                 0.795279   \n",
       "AP00025                      0                 0.876793   \n",
       "AP00026                      1                 0.220570   \n",
       "AP00027                      0                 0.874708   \n",
       "AP00028                      1                 0.069869   \n",
       "AP00029                      0                 0.997261   \n",
       "AP00030                      0                 0.945057   \n",
       "...                        ...                      ...   \n",
       "AP03052                      0                 0.927515   \n",
       "AP03053                      0                 0.709871   \n",
       "AP03054                      0                 0.989879   \n",
       "AP03055                      0                 0.960057   \n",
       "AP03056                      1                 0.207349   \n",
       "AP03057                      1                 0.104274   \n",
       "AP03058                      1                 0.249306   \n",
       "AP03059                      1                 0.075967   \n",
       "AP03060                      1                 0.130739   \n",
       "AP03061                      0                 0.982022   \n",
       "AP03062                      1                 0.000534   \n",
       "AP03063                      0                 0.955720   \n",
       "AP03064                      0                 0.936842   \n",
       "AP03065                      0                 0.967876   \n",
       "AP03066                      0                 0.993807   \n",
       "AP03067                      0                 0.974580   \n",
       "AP03068                      0                 0.736354   \n",
       "AP03069                      1                 0.454953   \n",
       "AP03070                      0                 0.997412   \n",
       "AP03071                      0                 0.984937   \n",
       "AP03072                      0                 0.923482   \n",
       "AP03073                      1                 0.004442   \n",
       "AP03074                      0                 0.615958   \n",
       "AP03075                      1                 0.292579   \n",
       "AP03076                      0                 0.343931   \n",
       "AP03077                      0                 0.462164   \n",
       "AP03078                      0                 0.970230   \n",
       "AP03079                      1                 0.248404   \n",
       "AP03080                      1                 0.168564   \n",
       "AP03081                      1                 0.137000   \n",
       "\n",
       "         consensus_probability_1  \n",
       "# ID                              \n",
       "AP00001                 0.640985  \n",
       "AP00002                 0.042625  \n",
       "AP00003                 0.252097  \n",
       "AP00004                 0.322866  \n",
       "AP00005                 0.890621  \n",
       "AP00006                 0.004584  \n",
       "AP00007                 0.002345  \n",
       "AP00008                 0.978326  \n",
       "AP00009                 0.134379  \n",
       "AP00010                 0.030291  \n",
       "AP00011                 0.271540  \n",
       "AP00012                 0.660273  \n",
       "AP00013                 0.703566  \n",
       "AP00014                 0.923677  \n",
       "AP00015                 0.916830  \n",
       "AP00016                 0.952845  \n",
       "AP00017                 0.923199  \n",
       "AP00018                 0.973810  \n",
       "AP00019                 0.990589  \n",
       "AP00020                 0.854980  \n",
       "AP00021                 0.853394  \n",
       "AP00022                 0.900055  \n",
       "AP00023                 0.284501  \n",
       "AP00024                 0.204721  \n",
       "AP00025                 0.123207  \n",
       "AP00026                 0.779430  \n",
       "AP00027                 0.125292  \n",
       "AP00028                 0.930131  \n",
       "AP00029                 0.002739  \n",
       "AP00030                 0.054943  \n",
       "...                          ...  \n",
       "AP03052                 0.072485  \n",
       "AP03053                 0.290129  \n",
       "AP03054                 0.010121  \n",
       "AP03055                 0.039943  \n",
       "AP03056                 0.792651  \n",
       "AP03057                 0.895726  \n",
       "AP03058                 0.750694  \n",
       "AP03059                 0.924033  \n",
       "AP03060                 0.869261  \n",
       "AP03061                 0.017978  \n",
       "AP03062                 0.999466  \n",
       "AP03063                 0.044280  \n",
       "AP03064                 0.063158  \n",
       "AP03065                 0.032124  \n",
       "AP03066                 0.006193  \n",
       "AP03067                 0.025420  \n",
       "AP03068                 0.263646  \n",
       "AP03069                 0.545047  \n",
       "AP03070                 0.002588  \n",
       "AP03071                 0.015063  \n",
       "AP03072                 0.076518  \n",
       "AP03073                 0.995558  \n",
       "AP03074                 0.384042  \n",
       "AP03075                 0.707421  \n",
       "AP03076                 0.656069  \n",
       "AP03077                 0.537836  \n",
       "AP03078                 0.029770  \n",
       "AP03079                 0.751596  \n",
       "AP03080                 0.831436  \n",
       "AP03081                 0.863000  \n",
       "\n",
       "[3081 rows x 12 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save test set results into dataframe\n",
    "# Model 3.1\n",
    "model1_hpi3.fit(X_HemoPI3_model, y_HemoPI3_model)\n",
    "class_df = pd.DataFrame(model1_hpi3.predict(X_totalAPD_hpi3))\n",
    "probs_df = pd.DataFrame(model1_hpi3.predict_proba(X_totalAPD_hpi3))\n",
    "\n",
    "model1_hpi3_apd = class_df.merge(probs_df, how='outer', left_index=True, right_index=True)\n",
    "model1_hpi3_apd.index = X_totalAPD_hpi3.index\n",
    "model1_hpi3_apd.columns = ['model1_class_preds', 'model1_probability_0', 'model1_probability_1']\n",
    "\n",
    "# Model 3.2\n",
    "model2_hpi3.fit(X_HemoPI3_model_RFE, y_HemoPI3_model)\n",
    "class_df2 = pd.DataFrame(model2_hpi3.predict(X_totalAPD_hpi3_RFE))\n",
    "probs_df2 = pd.DataFrame(model2_hpi3.predict_proba(X_totalAPD_hpi3_RFE))\n",
    "\n",
    "model2_hpi3_apd = class_df2.merge(probs_df2, how='outer', left_index=True, right_index=True)\n",
    "model2_hpi3_apd.index = X_totalAPD_hpi3.index\n",
    "model2_hpi3_apd.columns = ['model2_class_preds', 'model2_probability_0', 'model2_probability_1']\n",
    "\n",
    "# Model 3.3\n",
    "model3_hpi3.fit(X_HemoPI3_model_trim, y_HemoPI3_model)\n",
    "class_df3 = pd.DataFrame(model3_hpi3.predict(X_totalAPD_hpi3_trim))\n",
    "probs_df3 = pd.DataFrame(model3_hpi3.predict_proba(X_totalAPD_hpi3_trim))\n",
    "\n",
    "model3_hpi3_apd = class_df3.merge(probs_df3, how='outer', left_index=True, right_index=True)\n",
    "model3_hpi3_apd.index = X_totalAPD_hpi3.index\n",
    "model3_hpi3_apd.columns = ['model3_class_preds', 'model3_probability_0', 'model3_probability_1']\n",
    "\n",
    "# Merge model dataframes\n",
    "models_hpi3 = [model1_hpi3_apd, model2_hpi3_apd, model3_hpi3_apd]\n",
    "\n",
    "results_models_hpi3_apd = pd.concat(models_hpi3, axis=1, join='inner')\n",
    "results_models_hpi3_apd.index = model1_hpi3_apd.index\n",
    "results_models_hpi3_apd\n",
    "\n",
    "#Create consensus columns\n",
    "results_models_hpi3_apd['consensus_class_preds'] = results_models_hpi3_apd[['model1_class_preds', 'model2_class_preds', 'model3_class_preds']].mean(axis=1).astype(int)\n",
    "results_models_hpi3_apd['consensus_probability_0'] = results_models_hpi3_apd[['model1_probability_0', 'model2_probability_0', 'model3_probability_0']].mean(axis=1)\n",
    "results_models_hpi3_apd['consensus_probability_1'] = results_models_hpi3_apd[['model1_probability_1', 'model2_probability_1', 'model3_probability_1']].mean(axis=1)\n",
    "\n",
    "results_models_hpi3_apd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_models_hpi3_apd.to_csv('./Results/predictions_totalAPD_HemoPI3_topmodels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 1274, True: 1807})"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many AMPs are haemolytic peptides at high concentration according to HemoPI-3 models?\n",
    "#Counter(results_models_hpi3_apd['consensus_probability_1'] > 0.5) #1794\n",
    "#Counter(results_models_hpi3_apd['model1_probability_1'] > 0.5) #1767\n",
    "#Counter(results_models_hpi3_apd['model2_probability_1'] > 0.5) #1818\n",
    "Counter(results_models_hpi3_apd['model3_probability_1'] > 0.5) #1807"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalAPD_seq = total_APD.Sequence\n",
    "\n",
    "# Model datasets indices and sequences\n",
    "## HemoPI1\n",
    "HemoPI1_model = pd.read_csv('./Data/HemoPI1_model.csv', index_col=0)\n",
    "HemoPI1_validation = pd.read_csv('./Data/HemoPI1_validation.csv', index_col=0)\n",
    "HemoPI1_idx = pd.concat([HemoPI1_model, HemoPI1_validation]).index\n",
    "HemoPI1_seq = pd.concat([HemoPI1_model, HemoPI1_validation])['Sequence']\n",
    "\n",
    "## HemoPI2\n",
    "HemoPI2_model = pd.read_csv('./Data/HemoPI2_model.csv', index_col=0)\n",
    "HemoPI2_validation = pd.read_csv('./Data/HemoPI2_validation.csv', index_col=0)\n",
    "HemoPI2_idx = pd.concat([HemoPI2_model, HemoPI2_validation]).index\n",
    "HemoPI2_seq = pd.concat([HemoPI2_model, HemoPI2_validation])['Sequence']\n",
    "\n",
    "## HemoPI3\n",
    "HemoPI3_model = pd.read_csv('./Data/HemoPI3_model.csv', index_col=0)\n",
    "HemoPI3_validation = pd.read_csv('./Data/HemoPI3_validation.csv', index_col=0)\n",
    "HemoPI3_idx = pd.concat([HemoPI3_model, HemoPI3_validation]).index\n",
    "HemoPI3_seq = pd.concat([HemoPI3_model, HemoPI3_validation])['Sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 'AMPs peptides from total APD are found in HemoPI1 dataset')\n",
      "(229, 'AMPs peptides from total APD are found in HemoPI2 dataset')\n",
      "(476, 'AMPs peptides from total APD are found in HemoPI3 dataset')\n"
     ]
    }
   ],
   "source": [
    "### Find matching sequences between truly haemolytic AMPs and all 4 haemolytic datasets for modelling (HemoPI1, HemoPI2, HemoPI3 and HDBAASP)\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2)) \n",
    "\n",
    "print(len(intersection(totalAPD_seq, HemoPI1_seq)), 'AMPs peptides from total APD are found in HemoPI1 dataset')\n",
    "print(len(intersection(totalAPD_seq, HemoPI2_seq)), 'AMPs peptides from total APD are found in HemoPI2 dataset')\n",
    "print(len(intersection(totalAPD_seq, HemoPI3_seq)), 'AMPs peptides from total APD are found in HemoPI3 dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions for 317 true haemolytic AMPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name/Class</th>\n",
       "      <th>Source</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Length</th>\n",
       "      <th>Net charge</th>\n",
       "      <th>Hydrophobic residue %</th>\n",
       "      <th>Boman Index (kcal/mol)</th>\n",
       "      <th>3D Structure</th>\n",
       "      <th>Method</th>\n",
       "      <th>SwissProt ID</th>\n",
       "      <th>...</th>\n",
       "      <th>antiparasitic</th>\n",
       "      <th>Anti-MRSA</th>\n",
       "      <th>EnzymeInhibitor</th>\n",
       "      <th>Chemotactic</th>\n",
       "      <th>Insecticidal</th>\n",
       "      <th>Antioxidant</th>\n",
       "      <th>Spermicidal</th>\n",
       "      <th>Hemolytic</th>\n",
       "      <th>ToBeUpdated</th>\n",
       "      <th>ToBeTested</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APD ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AP00011</th>\n",
       "      <td>Bactericidin B-2 (insects,  arthropods, invert...</td>\n",
       "      <td>Tobacco hornworm Manduca sexta</td>\n",
       "      <td>WNPFKELERAGQRVRDAVISAAPAVATVGQAAAIARG</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>1.46</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P14662</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00032</th>\n",
       "      <td>Bactericidin B-3 (insects, arthropods, inverte...</td>\n",
       "      <td>Tobacco hornworm,  Manduca sexta</td>\n",
       "      <td>WNPFKELERAGQRVRDAIISAGPAVATVGQAAAIARG</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>1.46</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P14663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00033</th>\n",
       "      <td>Bactericidin B-4 (insects,  arthropods, invert...</td>\n",
       "      <td>Tobacco hornworm,  Manduca sexta</td>\n",
       "      <td>WNPFKELERAGQRVRDAIISAAPAVATVGQAAAIARG</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>1.43</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P14664</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00034</th>\n",
       "      <td>Bactericidin B-5P (insects,  arthropods, inver...</td>\n",
       "      <td>Tobacco hornworm,  Manduca sexta</td>\n",
       "      <td>WNPFKELERAGQRVRDAVISAAAVATVGQAAAIARG</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P14665</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP00049</th>\n",
       "      <td>Bombinin (UCLL1; toad, amphibians, animals)</td>\n",
       "      <td>skin, Yellow-bellied toad, Bombina variegata L...</td>\n",
       "      <td>GIGALSAKGALKGLAKGLAEHFAN</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P01505</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name/Class  \\\n",
       "APD ID                                                       \n",
       "AP00011  Bactericidin B-2 (insects,  arthropods, invert...   \n",
       "AP00032  Bactericidin B-3 (insects, arthropods, inverte...   \n",
       "AP00033  Bactericidin B-4 (insects,  arthropods, invert...   \n",
       "AP00034  Bactericidin B-5P (insects,  arthropods, inver...   \n",
       "AP00049        Bombinin (UCLL1; toad, amphibians, animals)   \n",
       "\n",
       "                                                    Source  \\\n",
       "APD ID                                                       \n",
       "AP00011                     Tobacco hornworm Manduca sexta   \n",
       "AP00032                   Tobacco hornworm,  Manduca sexta   \n",
       "AP00033                   Tobacco hornworm,  Manduca sexta   \n",
       "AP00034                   Tobacco hornworm,  Manduca sexta   \n",
       "AP00049  skin, Yellow-bellied toad, Bombina variegata L...   \n",
       "\n",
       "                                      Sequence  Length  Net charge  \\\n",
       "APD ID                                                               \n",
       "AP00011  WNPFKELERAGQRVRDAVISAAPAVATVGQAAAIARG      37           2   \n",
       "AP00032  WNPFKELERAGQRVRDAIISAGPAVATVGQAAAIARG      37           2   \n",
       "AP00033  WNPFKELERAGQRVRDAIISAAPAVATVGQAAAIARG      37           2   \n",
       "AP00034   WNPFKELERAGQRVRDAVISAAAVATVGQAAAIARG      36           2   \n",
       "AP00049               GIGALSAKGALKGLAKGLAEHFAN      24           3   \n",
       "\n",
       "         Hydrophobic residue %  Boman Index (kcal/mol) 3D Structure Method  \\\n",
       "APD ID                                                                       \n",
       "AP00011                     51                    1.46     Unknown     NaN   \n",
       "AP00032                     48                    1.46     Unknown     NaN   \n",
       "AP00033                     51                    1.43     Unknown     NaN   \n",
       "AP00034                     52                    1.50     Unknown     NaN   \n",
       "AP00049                     50                   -0.20     Unknown     NaN   \n",
       "\n",
       "              SwissProt ID     ...     antiparasitic Anti-MRSA  \\\n",
       "APD ID                         ...                               \n",
       "AP00011            P14662      ...                 0         0   \n",
       "AP00032            P14663      ...                 0         0   \n",
       "AP00033            P14664      ...                 0         0   \n",
       "AP00034            P14665      ...                 0         0   \n",
       "AP00049            P01505      ...                 0         0   \n",
       "\n",
       "        EnzymeInhibitor Chemotactic Insecticidal Antioxidant  Spermicidal  \\\n",
       "APD ID                                                                      \n",
       "AP00011               0           0            0           0            0   \n",
       "AP00032               0           0            0           0            0   \n",
       "AP00033               0           0            0           0            0   \n",
       "AP00034               0           0            0           0            0   \n",
       "AP00049               0           0            0           0            0   \n",
       "\n",
       "         Hemolytic  ToBeUpdated  ToBeTested  \n",
       "APD ID                                       \n",
       "AP00011          1            0           0  \n",
       "AP00032          1            0           0  \n",
       "AP00033          1            0           0  \n",
       "AP00034          1            0           0  \n",
       "AP00049          1            0           0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# While webscraping the APD database, we selected 317 out of 3081 AMPs identified as haemolytic peptides.\n",
    "haemolytic_APD = pd.read_csv('./Data/hemolytic_APD.csv', index_col=0)\n",
    "haemolytic_APD.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fasta_converter(database):\n",
    "    '''Use the indices of the database and the column 'Sequence' to create a fasta file'''\n",
    "    ofile = open('/Users/fabienplisson/Desktop/MODELS/Data/haemolytic_APD_HAMPs.fasta', \"w\")\n",
    "\n",
    "    for i in range(len(database.Sequence)):\n",
    "\n",
    "        ofile.write(\">\" + database.index[i] + \"\\n\" +database.Sequence[i] + \"\\n\")\n",
    "        \n",
    "    ofile.close()\n",
    "\n",
    "fasta_converter(haemolytic_APD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AP00011', 'AP00032', 'AP00033', 'AP00034', 'AP00049', 'AP00055',\n",
       "       'AP00056', 'AP00057', 'AP00058', 'AP00060', 'AP00063', 'AP00066',\n",
       "       'AP00067', 'AP00068', 'AP00069', 'AP00070', 'AP00071', 'AP00072',\n",
       "       'AP00073', 'AP00074', 'AP00075', 'AP00076', 'AP00077', 'AP00078',\n",
       "       'AP00079', 'AP00080', 'AP00082', 'AP00084', 'AP00101', 'AP00136',\n",
       "       'AP00146', 'AP00150', 'AP00152', 'AP00155', 'AP00160', 'AP00191',\n",
       "       'AP00200', 'AP00201', 'AP00214', 'AP00228', 'AP00234', 'AP00236',\n",
       "       'AP00237', 'AP00238', 'AP00301', 'AP00310', 'AP00313', 'AP00339',\n",
       "       'AP00340', 'AP00341', 'AP00366', 'AP00367', 'AP00374', 'AP00385',\n",
       "       'AP00386', 'AP00387', 'AP00388', 'AP00389', 'AP00390', 'AP00391',\n",
       "       'AP00414', 'AP00415', 'AP00416', 'AP00417', 'AP00427', 'AP00430',\n",
       "       'AP00456', 'AP00459', 'AP00461', 'AP00473', 'AP00474', 'AP00476',\n",
       "       'AP00485', 'AP00493', 'AP00494', 'AP00502', 'AP00522', 'AP00535',\n",
       "       'AP00543', 'AP00544', 'AP00545', 'AP00548', 'AP00556', 'AP00562',\n",
       "       'AP00567', 'AP00569', 'AP00580', 'AP00588', 'AP00593', 'AP00597',\n",
       "       'AP00601', 'AP00602', 'AP00603', 'AP00627', 'AP00660', 'AP00694',\n",
       "       'AP00728', 'AP00729', 'AP00730', 'AP00737', 'AP00738', 'AP00739',\n",
       "       'AP00740', 'AP00772', 'AP00773', 'AP00774', 'AP00775', 'AP00776',\n",
       "       'AP00793', 'AP00794', 'AP00819', 'AP00823', 'AP00858', 'AP00862',\n",
       "       'AP00866', 'AP00873', 'AP00878', 'AP00885', 'AP00887', 'AP00890',\n",
       "       'AP00894', 'AP00898', 'AP00957', 'AP00958', 'AP00961', 'AP00966',\n",
       "       'AP00969', 'AP00973', 'AP01010', 'AP01011', 'AP01016', 'AP01030',\n",
       "       'AP01047', 'AP01049', 'AP01055', 'AP01077', 'AP01080', 'AP01081',\n",
       "       'AP01108', 'AP01135', 'AP01149', 'AP01176', 'AP01223', 'AP01250',\n",
       "       'AP01251', 'AP01252', 'AP01253', 'AP01254', 'AP01257', 'AP01264',\n",
       "       'AP01265', 'AP01268', 'AP01277', 'AP01295', 'AP01297', 'AP01303',\n",
       "       'AP01308', 'AP01309', 'AP01310', 'AP01311', 'AP01314', 'AP01331',\n",
       "       'AP01332', 'AP01333', 'AP01340', 'AP01341', 'AP01345', 'AP01346',\n",
       "       'AP01349', 'AP01385', 'AP01412', 'AP01413', 'AP01414', 'AP01415',\n",
       "       'AP01416', 'AP01417', 'AP01436', 'AP01437', 'AP01438', 'AP01439',\n",
       "       'AP01440', 'AP01449', 'AP01450', 'AP01451', 'AP01452', 'AP01509',\n",
       "       'AP01510', 'AP01512', 'AP01521', 'AP01544', 'AP01545', 'AP01596',\n",
       "       'AP01640', 'AP01641', 'AP01650', 'AP01717', 'AP01726', 'AP01731',\n",
       "       'AP01736', 'AP01737', 'AP01739', 'AP01740', 'AP01743', 'AP01744',\n",
       "       'AP01753', 'AP01774', 'AP01776', 'AP01777', 'AP01804', 'AP01806',\n",
       "       'AP01807', 'AP01808', 'AP01809', 'AP01810', 'AP01811', 'AP01812',\n",
       "       'AP01813', 'AP01915', 'AP01917', 'AP01922', 'AP01923', 'AP01944',\n",
       "       'AP01948', 'AP01951', 'AP01952', 'AP01953', 'AP01954', 'AP01980',\n",
       "       'AP01986', 'AP01988', 'AP01989', 'AP01990', 'AP01992', 'AP01999',\n",
       "       'AP02000', 'AP02020', 'AP02041', 'AP02057', 'AP02058', 'AP02060',\n",
       "       'AP02061', 'AP02062', 'AP02063', 'AP02064', 'AP02098', 'AP02099',\n",
       "       'AP02104', 'AP02105', 'AP02114', 'AP02115', 'AP02118', 'AP02134',\n",
       "       'AP02135', 'AP02172', 'AP02173', 'AP02177', 'AP02179', 'AP02197',\n",
       "       'AP02217', 'AP02228', 'AP02229', 'AP02243', 'AP02272', 'AP02274',\n",
       "       'AP02275', 'AP02278', 'AP02279', 'AP02280', 'AP02281', 'AP02282',\n",
       "       'AP02283', 'AP02284', 'AP02285', 'AP02286', 'AP02288', 'AP02289',\n",
       "       'AP02290', 'AP02291', 'AP02292', 'AP02293', 'AP02294', 'AP02295',\n",
       "       'AP02304', 'AP02309', 'AP02318', 'AP02319', 'AP02355', 'AP02356',\n",
       "       'AP02357', 'AP02358', 'AP02459', 'AP02460', 'AP02461', 'AP02462',\n",
       "       'AP02463', 'AP02464', 'AP02465', 'AP02467', 'AP02468', 'AP02469',\n",
       "       'AP02472', 'AP02474', 'AP02531', 'AP02560', 'AP02561', 'AP02562',\n",
       "       'AP02563', 'AP02603', 'AP02689', 'AP02690', 'AP02692', 'AP02710',\n",
       "       'AP02802', 'AP02880', 'AP02881', 'AP03029', 'AP03041'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use APD ID to match with APD inliers and outliers\n",
    "haemolytic_APD_idx = haemolytic_APD.index.values\n",
    "haemolytic_APD_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Subset predictions results from total APD\n",
    "results_models_hpi1_hamp = results_models_hpi1_apd.loc[haemolytic_APD_idx]\n",
    "results_models_hpi1_hamp.to_csv('./Results/predictions_HAMP_HemoPI1_topmodels.csv')\n",
    "\n",
    "results_models_hpi2_hamp = results_models_hpi2_apd.loc[haemolytic_APD_idx]\n",
    "results_models_hpi2_hamp.to_csv('./Results/predictions_HAMP_HemoPI2_topmodels.csv')\n",
    "\n",
    "results_models_hpi3_hamp = results_models_hpi3_apd.loc[haemolytic_APD_idx]\n",
    "results_models_hpi3_hamp.to_csv('./Results/predictions_HAMP_HemoPI3_topmodels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 63 Haemolytic APD peptides are found in HemoPI1 dataset\n",
    "- 67 Haemolytic APD peptides are found in HemoPI2 dataset\n",
    "- 147 Haemolytic APD peptides are found in HemoPI3 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "Considering the performances of Gradient Boosted Trees, we decided to test XGBoost classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already satisfied: xgboost in /Users/fabienplisson/anaconda/envs/my-rdkit-env/lib/python2.7/site-packages (0.82)\n",
      "Requirement already satisfied: numpy in /Users/fabienplisson/anaconda/envs/my-rdkit-env/lib/python2.7/site-packages (from xgboost) (1.15.4)\n",
      "Requirement already satisfied: scipy in /Users/fabienplisson/anaconda/envs/my-rdkit-env/lib/python2.7/site-packages (from xgboost) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "models = []\n",
    "#models.append(('xgb', XGBClassifier(random_state=seed, eta=objective='binary:logistic')))\n",
    "models.append(('xgb', XGBClassifier(random_state=seed, colsample_bytree=0.8, eta=0.1, max_depth=10, min_child_weight=1, subsample=0.7, tree_method='hist', objective='binary:logistic', n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(objective='binary:logistic', eval_metric='error', seed=seed)\n",
    "\n",
    "def xgbc_param_selection(X, y, fold):\n",
    "    param_grid = {\n",
    "        'eta': [0.01, 0.05, 0.1, 0.15, 0.2, 0.3],\n",
    "        'min_child_weight': [0.2, 0.4, 0.6, 0.8, 1],\n",
    "        'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'tree_method': ['auto', 'exact', 'approx', 'hist']}\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=xgbc, param_grid=param_grid, cv=fold)\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb: Accuracy Score 95.37% (2.49%)\n",
      "Optimal number of features : 24\n",
      "\n",
      "xgb: Accuracy 95.36%\n",
      "xgb: Precision-Recall 93.30%\n",
      "xgb: Matthews Coefficient 90.72%\n",
      "xgb: Cohen Kappa Score 90.72%\n",
      "xgb: ROC AUC Score 95.36%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.95      0.95      0.95       442\n",
      "     high 1       0.95      0.95      0.95       442\n",
      "\n",
      "avg / total       0.95      0.95      0.95       884\n",
      "\n",
      "xgb: Accuracy 90.45%\n",
      "xgb: Precision-Recall 86.74%\n",
      "xgb: Matthews Coefficient 80.91%\n",
      "xgb: Cohen Kappa Score 80.91%\n",
      "xgb: ROC AUC Score 90.45%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.90      0.91      0.90       110\n",
      "     high 1       0.91      0.90      0.90       110\n",
      "\n",
      "avg / total       0.90      0.90      0.90       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "# MC (0.75)\n",
    "#corr_matrix1 = norm_HemoPI1_model.corr()\n",
    "#upper = corr_matrix1.where(np.triu(np.ones(corr_matrix1.shape), k=1).astype(np.bool))\n",
    "#to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "#X_HemoPI1_model_trim = norm_HemoPI1_model.drop(norm_HemoPI1_model[to_drop], axis=1)\n",
    "#X_HemoPI1_val_trim = norm_HemoPI1_validation.drop(norm_HemoPI1_validation[to_drop], axis=1)\n",
    "\n",
    "for name, model in models:\n",
    "    \n",
    "    # RFECV\n",
    "    rfecv_model = RFECV(model, step=1, cv=kfold)\n",
    "    rfecv = rfecv_model.fit(X_HemoPI1_model, y_HemoPI1_model)\n",
    "    X_HemoPI1_model_RFE = rfecv.transform(X_HemoPI1_model)\n",
    "    X_HemoPI1_val_RFE = rfecv.transform(X_HemoPI1_validation)\n",
    "    \n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI1_model_RFE, y_HemoPI1_model, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (rfecv.n_features_))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI1_model_RFE, y_HemoPI1_model, cv=kfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_model, cv_preds)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI1_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI1_val_RFE, y_HemoPI1_validation, cv=kfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI1_validation, cv_preds2)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI1_validation, cv_preds2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-2 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both model and validation datasets (HemoPI-2 and HemoPI-3) are not balanced. We need to take that unbalance into consideration with 10-fold stratified cross-validation while computing binary classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "models = []\n",
    "#models.append(('xgb', XGBClassifier(random_state=seed, eta=objective='binary:logistic')))\n",
    "models.append(('xgb', XGBClassifier(random_state=seed, colsample_bytree=0.8, eta=0.1, max_depth=14, min_child_weight=1, subsample=0.7, tree_method='hist', objective='binary:logistic', n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb: Accuracy Score 79.07% (3.73%)\n",
      "Optimal number of features : 34\n",
      "\n",
      "xgb: Accuracy 79.06%\n",
      "xgb: Precision-Recall 75.29%\n",
      "xgb: Matthews Coefficient 57.69%\n",
      "xgb: Cohen Kappa Score 57.65%\n",
      "xgb: ROC AUC Score 78.72%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.78      0.75      0.77       370\n",
      "     high 1       0.80      0.83      0.81       442\n",
      "\n",
      "avg / total       0.79      0.79      0.79       812\n",
      "\n",
      "xgb: Accuracy 70.30%\n",
      "xgb: Precision-Recall 67.23%\n",
      "xgb: Matthews Coefficient 39.82%\n",
      "xgb: Cohen Kappa Score 39.69%\n",
      "xgb: ROC AUC Score 69.70%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.69      0.63      0.66        92\n",
      "     high 1       0.71      0.76      0.74       110\n",
      "\n",
      "avg / total       0.70      0.70      0.70       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "# MC (0.75)\n",
    "#corr_matrix2 = norm_HemoPI2_model.corr()\n",
    "#upper = corr_matrix2.where(np.triu(np.ones(corr_matrix2.shape), k=1).astype(np.bool))\n",
    "#to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "#X_HemoPI2_model_trim = norm_HemoPI2_model.drop(norm_HemoPI2_model[to_drop], axis=1)\n",
    "#X_HemoPI2_val_trim = norm_HemoPI2_validation.drop(norm_HemoPI2_validation[to_drop], axis=1)\n",
    "\n",
    "for name, model in models:\n",
    "    \n",
    "    # RFECV\n",
    "    rfecv_model = RFECV(model, step=1, cv=skfold)\n",
    "    rfecv = rfecv_model.fit(X_HemoPI2_model, y_HemoPI2_model)\n",
    "    X_HemoPI2_model_RFE = rfecv.transform(X_HemoPI2_model)\n",
    "    X_HemoPI2_val_RFE = rfecv.transform(X_HemoPI2_validation)\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI2_model_RFE, y_HemoPI2_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (rfecv.n_features_))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI2_model_RFE, y_HemoPI2_model, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_model, cv_preds)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI2_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI2_val_RFE, y_HemoPI2_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI2_validation, cv_preds2)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI2_validation, cv_preds2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HemoPI-3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=42\n",
    "models = []\n",
    "#models.append(('xgb', XGBClassifier(random_state=seed, eta=objective='binary:logistic')))\n",
    "models.append(('xgb', XGBClassifier(random_state=seed, colsample_bytree=0.8, eta=0.1, max_depth=10, min_child_weight=0.4, subsample=0.7, tree_method='hist', objective='binary:logistic')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb: Accuracy Score 78.19% (2.81%)\n",
      "Optimal number of features : 21\n",
      "\n",
      "xgb: Accuracy 78.20%\n",
      "xgb: Precision-Recall 74.30%\n",
      "xgb: Matthews Coefficient 55.89%\n",
      "xgb: Cohen Kappa Score 55.77%\n",
      "xgb: ROC AUC Score 77.73%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.78      0.73      0.75       590\n",
      "     high 1       0.78      0.83      0.81       708\n",
      "\n",
      "avg / total       0.78      0.78      0.78      1298\n",
      "\n",
      "xgb: Accuracy 70.15%\n",
      "xgb: Precision-Recall 67.59%\n",
      "xgb: Matthews Coefficient 39.80%\n",
      "xgb: Cohen Kappa Score 39.80%\n",
      "xgb: ROC AUC Score 69.89%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      low 0       0.67      0.67      0.67       148\n",
      "     high 1       0.72      0.73      0.73       177\n",
      "\n",
      "avg / total       0.70      0.70      0.70       325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "# MC (0.75)\n",
    "#corr_matrix3 = norm_HemoPI3_model.corr()\n",
    "#upper = corr_matrix3.where(np.triu(np.ones(corr_matrix3.shape), k=1).astype(np.bool))\n",
    "#to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "#X_HemoPI3_model_trim = norm_HemoPI3_model.drop(norm_HemoPI3_model[to_drop], axis=1)\n",
    "#X_HemoPI3_val_trim = norm_HemoPI3_validation.drop(norm_HemoPI3_validation[to_drop], axis=1)\n",
    "\n",
    "for name, model in models:\n",
    "    \n",
    "    # RFECV\n",
    "    rfecv_model = RFECV(model, step=1, cv=skfold)\n",
    "    rfecv = rfecv_model.fit(X_HemoPI3_model, y_HemoPI3_model)\n",
    "    X_HemoPI3_model_RFE = rfecv.transform(X_HemoPI3_model)\n",
    "    X_HemoPI3_val_RFE = rfecv.transform(X_HemoPI3_validation)\n",
    "    \n",
    "    # Scores means and std deviations\n",
    "    cv_scores = model_selection.cross_val_score(model, X_HemoPI3_model_RFE, y_HemoPI3_model, cv=skfold, scoring='accuracy')\n",
    "    results.append(cv_scores)\n",
    "    names.append(name)\n",
    "    print(\"%s: Accuracy Score %0.2f%% (%0.2f%%)\" % (name, 100*cv_scores.mean(), 100*cv_scores.std()))\n",
    "    print(\"Optimal number of features : %d\" % (rfecv.n_features_))\n",
    "    print(\"\")\n",
    "    \n",
    "    # Predictions Model Set\n",
    "    cv_preds = model_selection.cross_val_predict(model, X_HemoPI3_model_RFE, y_HemoPI3_model, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_model, cv_preds)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_model, cv_preds)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI3_model, cv_preds, target_names=target_names))\n",
    "    \n",
    "    # Predictions Validation Set\n",
    "    cv_preds2 = model_selection.cross_val_predict(model, X_HemoPI3_val_RFE, y_HemoPI3_validation, cv=skfold)\n",
    "    print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_HemoPI3_validation, cv_preds2)))\n",
    "    target_names = ['low 0', 'high 1']\n",
    "    print(classification_report(y_HemoPI3_validation, cv_preds2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [my-rdkit-env]",
   "language": "python",
   "name": "Python [my-rdkit-env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
